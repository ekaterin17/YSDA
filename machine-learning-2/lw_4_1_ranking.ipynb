{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 4. Часть 1. Ранжирование.\n",
    "\n",
    "\n",
    "\n",
    "Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете так же должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 7 баллов. Сдавать задание после указанного в lk срока сдачи нельзя. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, нам необходима ссылка на источник).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Знакомство с данными\n",
    "\n",
    "### Ранжирование организаций по пользовательскому запросу\n",
    "\n",
    "Что мы обычно делаем, когда нам нужно найти определённое место, но не знаем его местоположения? Используем поиск на картах.\n",
    "\n",
    "В этой лабораторной работе вам будет необходимо построить небольшую поисковую систему, позволяющую отранжировать организации по запросу пользователя.\n",
    "\n",
    "Для обучения вам даны 2000 запросов и более 13 тысяч найденных по ним организаций. Для каждой пары \"запрос — организация\" была посчитана релевантность, по которой и происходит ранжирование."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 балла) Задание 1.** Загрузите [данные](https://disk.yandex.ru/d/Bf3P4H8FDYe7-g) о запросах и их релевантности (*train.csv*), а также информацию об организациях (*train_org_information.json*) и рубриках (*train_rubric_information.json*)\n",
    "\n",
    "Для дальнейших экспериментов необходимо посчитать небольшой набор базовых факторов. С использованием информации о запросах и организациях, посчитайте факторы, которые на ваш взгляд будут полезными для предсказания релевантности.\n",
    "\n",
    "Примерами текстовых факторов могут служить:\n",
    " - кол-во слов в запросе и названии организации;\n",
    " - пословные/N-граммные пересечения слов запроса и названия организации (также можно использовать синонимы названия организации и адрес организации): кол-во слов в пересечении, [мера Жаккара](https://en.wikipedia.org/wiki/Jaccard_index) и пр.;\n",
    " - кол-во различных синонимичных названий организации (поле *names* в описании организации);\n",
    " - One-hot-encoded язык запроса.\n",
    " \n",
    "По информации о географическом положении:\n",
    " - факт совпадения региона, где задавался запрос и региона организации;\n",
    " - координаты показанной области;\n",
    " - размеры показанной области;\n",
    " - меры, характеризующие близость координат организации к показанному окну: расстояние до центра области и другие.\n",
    " \n",
    "Факторы, описывающие организацию:\n",
    " - one-hot-encoding фактор cтраны или региона организации (важно: не используйте one-hot-encoding факторы, в которых больше 10 значений; если в факторе слишком много значений, ограничьтесь, например, только самыми популярными категориями)\n",
    " - кол-во рабочих дней в неделе и общая продолжительность работы (поле *work_intervals* в описании организации)\n",
    " - кол-во рубрик (поле *rubrics* в описании организации)\n",
    " \n",
    "![](https://miro.medium.com/max/1500/0*FwubnnoNlt6Coo9j.png)\n",
    "\n",
    "В этом задании не нужно использовать многомерные представления текстовой информации (tfidf и прочие embeddings) и информацию о кликах (*train_clicks_information.json*). Придумывать сверхсложные факторы тоже необязательно.\n",
    "\n",
    "Вы можете реализовать описанные выше факторы и/или придумать свои. Но зачастую такие простые признаки могут приносить наибольшую пользу.\n",
    "\n",
    "В итоге у вас должно получиться от 15 до 50 факторов, характеризующих запрос и организацию и покрывающих основные источники данных (кроме кликов). Это наш основной датасет, который будет использоваться в экспериментах.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import langdetect\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>region</th>\n",
       "      <th>org_name</th>\n",
       "      <th>org_id</th>\n",
       "      <th>window_center</th>\n",
       "      <th>window_size</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>суд, Украина, Днепропетровская область, Днепро...</td>\n",
       "      <td>21775</td>\n",
       "      <td>Суд Жовтневого району міста Дніпропетровськ</td>\n",
       "      <td>1021049127</td>\n",
       "      <td>34.613119,48.506531</td>\n",
       "      <td>0.025928,0.017380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>суд, Украина, Днепропетровская область, Днепро...</td>\n",
       "      <td>21775</td>\n",
       "      <td>Дніпропетровський окружний адміністративний суд</td>\n",
       "      <td>1602348889</td>\n",
       "      <td>34.613119,48.506531</td>\n",
       "      <td>0.025928,0.017380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>суд, Украина, Днепропетровская область, Днепро...</td>\n",
       "      <td>21775</td>\n",
       "      <td>Бабушкінський районний суд</td>\n",
       "      <td>1105837793</td>\n",
       "      <td>34.613119,48.506531</td>\n",
       "      <td>0.025928,0.017380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>суд, Украина, Днепропетровская область, Днепро...</td>\n",
       "      <td>21775</td>\n",
       "      <td>Красногвардійський районний суд</td>\n",
       "      <td>1066267658</td>\n",
       "      <td>34.613119,48.506531</td>\n",
       "      <td>0.025928,0.017380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>суд, Украина, Днепропетровская область, Днепро...</td>\n",
       "      <td>21775</td>\n",
       "      <td>Жовтневий суд</td>\n",
       "      <td>1661586235</td>\n",
       "      <td>34.613119,48.506531</td>\n",
       "      <td>0.025928,0.017380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                              query  region  \\\n",
       "0        11  суд, Украина, Днепропетровская область, Днепро...   21775   \n",
       "1        11  суд, Украина, Днепропетровская область, Днепро...   21775   \n",
       "2        11  суд, Украина, Днепропетровская область, Днепро...   21775   \n",
       "3        11  суд, Украина, Днепропетровская область, Днепро...   21775   \n",
       "4        11  суд, Украина, Днепропетровская область, Днепро...   21775   \n",
       "\n",
       "                                          org_name      org_id  \\\n",
       "0      Суд Жовтневого району міста Дніпропетровськ  1021049127   \n",
       "1  Дніпропетровський окружний адміністративний суд  1602348889   \n",
       "2                       Бабушкінський районний суд  1105837793   \n",
       "3                  Красногвардійський районний суд  1066267658   \n",
       "4                                    Жовтневий суд  1661586235   \n",
       "\n",
       "         window_center        window_size  relevance  \n",
       "0  34.613119,48.506531  0.025928,0.017380        0.0  \n",
       "1  34.613119,48.506531  0.025928,0.017380        0.0  \n",
       "2  34.613119,48.506531  0.025928,0.017380        0.0  \n",
       "3  34.613119,48.506531  0.025928,0.017380        0.0  \n",
       "4  34.613119,48.506531  0.025928,0.017380        0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./train.csv')\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число строк: 29274\n",
      "Число столбцов: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Число строк: {}\\nЧисло столбцов: {}\".format(*train_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число уникальных query_id: 2000\n"
     ]
    }
   ],
   "source": [
    "unique_query_id = np.unique(train_data.query_id.values)\n",
    "print(\"Число уникальных query_id:\", len(unique_query_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на несколько строк в train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_id : 11\n",
      "query : суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "region : 21775\n",
      "org_name : Дніпропетровський окружний адміністративний суд\n",
      "org_id : 1380543593\n",
      "window_center : 34.613119,48.506531\n",
      "window_size : 0.025928,0.017380\n",
      "relevance : 0.0\n",
      "\n",
      "query_id : 94\n",
      "query : банкоматы\n",
      "region : 143\n",
      "org_name : Надра Банк, банкомат\n",
      "org_id : 1207964833\n",
      "window_center : 30.636340,50.422901\n",
      "window_size : 0.098170,0.036736\n",
      "relevance : 0.14\n",
      "\n",
      "query_id : 116\n",
      "query : Аптеки\n",
      "region : 143\n",
      "org_name : Аптека Фармація\n",
      "org_id : 1180197860\n",
      "window_center : 30.417718,50.428612\n",
      "window_size : 0.025748,0.026062\n",
      "relevance : 0.14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [11, 124, 200]:\n",
    "    for col, data in zip(train_data.columns, train_data.iloc[i].values):\n",
    "        print(col, \":\", data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь посмотрим на query_id=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Суд Жовтневого району міста Дніпропетровськ\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Дніпропетровський окружний адміністративний суд\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Бабушкінський районний суд\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Красногвардійський районний суд\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Жовтневий суд\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Ленінський районний суд міста Дніпропетровськ\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Апеляційний суд Дніпропетровської області\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Нижньодніпровський районний суд міста Дніпропетровська\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Ленінський районний суд м. Дніпропетровська\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Суд Індустріального району\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Вільногірський міський суд\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Дніпропетровський окружний адміністративний суд\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Третейський суд Верітас\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Господарський суд Дніпропетровської області\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Дніпропетровський апеляційний господарський суд\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Дніпропетровський апеляційний адміністративний суд\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Солонянський Районний суд\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Індустріальний районний суд м. Дніпропетровська\n",
      "relevance 0.0\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Заводський суд\n",
      "relevance 0.61\n",
      "\n",
      "query: суд, Украина, Днепропетровская область, Днепродзержинский городской совет\n",
      "org_name Дніпровський районний суд\n",
      "relevance 0.61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, row in train_data[train_data.query_id == 11].iterrows():\n",
    "    print(\"query:\", row.query)\n",
    "    print(\"org_name\", row.org_name)\n",
    "    print(\"relevance\", row.relevance)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>work_intervals</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1255014404</th>\n",
       "      <td>[{'value': {'locale': 'en', 'value': 'Bely Bok...</td>\n",
       "      <td>[20277, 20679, 21237]</td>\n",
       "      <td>[{'time_minutes_begin': 540, 'day': 'everyday'...</td>\n",
       "      <td>{'region_code': 'RU', 'formatted': {'locale': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111883782</th>\n",
       "      <td>[{'value': {'locale': 'en', 'value': 'Vyborgsk...</td>\n",
       "      <td>[30723]</td>\n",
       "      <td>[{'time_minutes_begin': 510, 'day': 'saturday'...</td>\n",
       "      <td>{'region_code': 'RU', 'formatted': {'locale': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39713767434</th>\n",
       "      <td>[{'value': {'locale': 'en', 'value': 'Sberbank...</td>\n",
       "      <td>[30348]</td>\n",
       "      <td>[{'time_minutes_begin': 570, 'day': 'saturday'...</td>\n",
       "      <td>{'region_code': 'RU', 'formatted': {'locale': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336016908</th>\n",
       "      <td>[{'value': {'locale': 'en', 'value': 'Filial b...</td>\n",
       "      <td>[30057, 30111, 30114]</td>\n",
       "      <td>[{'time_minutes_begin': 480, 'day': 'saturday'...</td>\n",
       "      <td>{'region_code': 'RU', 'formatted': {'locale': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149331116064</th>\n",
       "      <td>[{'value': {'locale': 'ru', 'value': 'Школа'}}]</td>\n",
       "      <td>[30723]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'region_code': 'RU', 'formatted': {'locale': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          names  \\\n",
       "1255014404    [{'value': {'locale': 'en', 'value': 'Bely Bok...   \n",
       "1111883782    [{'value': {'locale': 'en', 'value': 'Vyborgsk...   \n",
       "39713767434   [{'value': {'locale': 'en', 'value': 'Sberbank...   \n",
       "1336016908    [{'value': {'locale': 'en', 'value': 'Filial b...   \n",
       "149331116064    [{'value': {'locale': 'ru', 'value': 'Школа'}}]   \n",
       "\n",
       "                            rubrics  \\\n",
       "1255014404    [20277, 20679, 21237]   \n",
       "1111883782                  [30723]   \n",
       "39713767434                 [30348]   \n",
       "1336016908    [30057, 30111, 30114]   \n",
       "149331116064                [30723]   \n",
       "\n",
       "                                                 work_intervals  \\\n",
       "1255014404    [{'time_minutes_begin': 540, 'day': 'everyday'...   \n",
       "1111883782    [{'time_minutes_begin': 510, 'day': 'saturday'...   \n",
       "39713767434   [{'time_minutes_begin': 570, 'day': 'saturday'...   \n",
       "1336016908    [{'time_minutes_begin': 480, 'day': 'saturday'...   \n",
       "149331116064                                                 []   \n",
       "\n",
       "                                                        address  \n",
       "1255014404    {'region_code': 'RU', 'formatted': {'locale': ...  \n",
       "1111883782    {'region_code': 'RU', 'formatted': {'locale': ...  \n",
       "39713767434   {'region_code': 'RU', 'formatted': {'locale': ...  \n",
       "1336016908    {'region_code': 'RU', 'formatted': {'locale': ...  \n",
       "149331116064  {'region_code': 'RU', 'formatted': {'locale': ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_org = './train_org_information.json'\n",
    "org_data = pd.read_json(path_to_org, orient='index', convert_axes=False, convert_dates=False)\n",
    "org_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_org, 'r') as read_file:\n",
    "    train_org_json = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'value': {'locale': 'en', 'value': 'Bely Boks'}},\n",
       " {'value': {'locale': 'ru', 'value': 'Белый бокс'}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_data.names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'time_minutes_begin': 540, 'day': 'everyday', 'time_minutes_end': 1260}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_data.work_intervals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'region_code': 'RU',\n",
       " 'formatted': {'locale': 'ru',\n",
       "  'value': 'Россия, Санкт-Петербург, Кронштадтская улица, 19'},\n",
       " 'pos': {'type': 'Point', 'coordinates': [30.257127, 59.865881]},\n",
       " 'geo_id': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_data.address[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>phrases</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273147906</th>\n",
       "      <td>[{'locale': 'ru', 'value': 'велосипед парковка...</td>\n",
       "      <td>[{'locale': 'de', 'value': 'Parkplatz für Fahr...</td>\n",
       "      <td>[{'value': {'locale': 'tr', 'value': 'Bisiklet...</td>\n",
       "      <td>[{'locale': 'en', 'value': 'Bicycle stand'}, {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30723</th>\n",
       "      <td>[{'locale': 'tr', 'value': 'liseler, ortaokul,...</td>\n",
       "      <td>[{'locale': 'de', 'value': 'Bildungseinrichtun...</td>\n",
       "      <td>[{'value': {'locale': 'tr', 'value': 'Çocuklar...</td>\n",
       "      <td>[{'locale': 'de', 'value': 'Allgemeinbildende ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30724</th>\n",
       "      <td>[{'locale': 'tr', 'value': 'arastırma, bilim, ...</td>\n",
       "      <td>[{'locale': 'tr', 'value': 'Bilim Arastırma En...</td>\n",
       "      <td>[{'value': {'locale': 'tr', 'value': 'Bilim ar...</td>\n",
       "      <td>[{'locale': 'tr', 'value': 'Bilim Araştırma En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30725</th>\n",
       "      <td>[{'locale': 'tr', 'value': 'eğitim kontrol'}]</td>\n",
       "      <td>[{'locale': 'en', 'value': 'Board of Education...</td>\n",
       "      <td>[{'value': {'locale': 'tr', 'value': 'Eğitim k...</td>\n",
       "      <td>[{'locale': 'it', 'value': 'Amministrazione de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30731</th>\n",
       "      <td>[{'locale': 'ru', 'value': 'Новые технологии -...</td>\n",
       "      <td>[{'locale': 'en', 'value': 'implementation of ...</td>\n",
       "      <td>[{'value': {'locale': 'tr', 'value': 'Nanotekn...</td>\n",
       "      <td>[{'locale': 'de', 'value': 'Innovative Technol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    keywords  \\\n",
       "273147906  [{'locale': 'ru', 'value': 'велосипед парковка...   \n",
       "30723      [{'locale': 'tr', 'value': 'liseler, ortaokul,...   \n",
       "30724      [{'locale': 'tr', 'value': 'arastırma, bilim, ...   \n",
       "30725          [{'locale': 'tr', 'value': 'eğitim kontrol'}]   \n",
       "30731      [{'locale': 'ru', 'value': 'Новые технологии -...   \n",
       "\n",
       "                                                     phrases  \\\n",
       "273147906  [{'locale': 'de', 'value': 'Parkplatz für Fahr...   \n",
       "30723      [{'locale': 'de', 'value': 'Bildungseinrichtun...   \n",
       "30724      [{'locale': 'tr', 'value': 'Bilim Arastırma En...   \n",
       "30725      [{'locale': 'en', 'value': 'Board of Education...   \n",
       "30731      [{'locale': 'en', 'value': 'implementation of ...   \n",
       "\n",
       "                                                descriptions  \\\n",
       "273147906  [{'value': {'locale': 'tr', 'value': 'Bisiklet...   \n",
       "30723      [{'value': {'locale': 'tr', 'value': 'Çocuklar...   \n",
       "30724      [{'value': {'locale': 'tr', 'value': 'Bilim ar...   \n",
       "30725      [{'value': {'locale': 'tr', 'value': 'Eğitim k...   \n",
       "30731      [{'value': {'locale': 'tr', 'value': 'Nanotekn...   \n",
       "\n",
       "                                                       names  \n",
       "273147906  [{'locale': 'en', 'value': 'Bicycle stand'}, {...  \n",
       "30723      [{'locale': 'de', 'value': 'Allgemeinbildende ...  \n",
       "30724      [{'locale': 'tr', 'value': 'Bilim Araştırma En...  \n",
       "30725      [{'locale': 'it', 'value': 'Amministrazione de...  \n",
       "30731      [{'locale': 'de', 'value': 'Innovative Technol...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_rubric = './train_rubric_information.json'\n",
    "rubric_data = pd.read_json(path_to_rubric, orient='index', convert_axes=False, convert_dates=False)\n",
    "rubric_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_rubric, 'r') as read_file:\n",
    "    train_rubric_json = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'locale': 'tr',\n",
       "  'value': 'liseler, ortaokul, liseleri, özel, ilköğretim, okul, orta, kurumları, ilkokul, düz, öğretim, kurumlari, fen, okullar, okulları, eğitim, ogretim, genel, okulu, ortaokullar, ilk'},\n",
       " {'locale': 'ru',\n",
       "  'value': 'Школы общеобразовательные средняя экстернат вечерняя сш начальная детская'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubric_data.keywords[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'locale': 'de', 'value': 'Bildungseinrichtung'},\n",
       " {'locale': 'de', 'value': 'Gesamtschulen'},\n",
       " {'locale': 'de', 'value': 'Grundschule'},\n",
       " {'locale': 'en', 'value': 'K-12 education'},\n",
       " {'locale': 'en', 'value': 'K-12 school'},\n",
       " {'locale': 'de', 'value': 'Lehranstalt'},\n",
       " {'locale': 'en', 'value': 'Middle Schools'},\n",
       " {'locale': 'de', 'value': 'Mittelschule'},\n",
       " {'locale': 'tr', 'value': 'Ortaokul'},\n",
       " {'locale': 'en', 'value': 'Primary Secondary Schools'},\n",
       " {'locale': 'en', 'value': 'Public Schools'},\n",
       " {'locale': 'de', 'value': 'Schule'},\n",
       " {'locale': 'de', 'value': 'Unterrichtsanstalt'},\n",
       " {'locale': 'de', 'value': 'allgemein bildende Schulen'},\n",
       " {'locale': 'en', 'value': \"children's school\"},\n",
       " {'locale': 'en', 'value': 'distance education'},\n",
       " {'locale': 'tr', 'value': 'düz liseler'},\n",
       " {'locale': 'fr', 'value': 'enseignement secondaire'},\n",
       " {'locale': 'en', 'value': 'evening schools'},\n",
       " {'locale': 'fr', 'value': 'externat'},\n",
       " {'locale': 'tr', 'value': 'fen liseleri'},\n",
       " {'locale': 'tr', 'value': 'genel liseler'},\n",
       " {'locale': 'en', 'value': 'high school'},\n",
       " {'locale': 'en', 'value': 'high schools'},\n",
       " {'locale': 'tr', 'value': 'liseler'},\n",
       " {'locale': 'en', 'value': 'middle school'},\n",
       " {'locale': 'en', 'value': 'night school'},\n",
       " {'locale': 'tr', 'value': 'okul'},\n",
       " {'locale': 'tr', 'value': 'okullar'},\n",
       " {'locale': 'tr', 'value': 'orta ogretim kurumlari'},\n",
       " {'locale': 'tr', 'value': 'orta öğretim kurumları'},\n",
       " {'locale': 'tr', 'value': 'ortaokul'},\n",
       " {'locale': 'tr', 'value': 'ortaokullar'},\n",
       " {'locale': 'tr', 'value': 'ortaöğretim'},\n",
       " {'locale': 'fr', 'value': 'où étudier'},\n",
       " {'locale': 'en', 'value': 'primary school'},\n",
       " {'locale': 'en', 'value': 'primary schools'},\n",
       " {'locale': 'fr', 'value': 'secondaire'},\n",
       " {'locale': 'en', 'value': 'secondary schools'},\n",
       " {'locale': 'en', 'value': 'where to study'},\n",
       " {'locale': 'fr', 'value': 'école primaire'},\n",
       " {'locale': 'fr', 'value': 'écoles primaires'},\n",
       " {'locale': 'fr', 'value': \"établissement d'enseignement général\"},\n",
       " {'locale': 'fr', 'value': \"établissements d'enseignement général\"},\n",
       " {'locale': 'ru', 'value': 'МБОУ СОШ'},\n",
       " {'locale': 'ru', 'value': 'вечерние школы'},\n",
       " {'locale': 'ru', 'value': 'вечерняя школа'},\n",
       " {'locale': 'uk', 'value': 'вечірня школа'},\n",
       " {'locale': 'uk', 'value': 'вечірні школи'},\n",
       " {'locale': 'ru', 'value': 'детская школа'},\n",
       " {'locale': 'uk', 'value': 'дитяча школа'},\n",
       " {'locale': 'uk', 'value': 'загальноосвітня школа'},\n",
       " {'locale': 'uk', 'value': 'загальноосвітні школи'},\n",
       " {'locale': 'ru', 'value': 'куда пойти учиться'},\n",
       " {'locale': 'ru', 'value': 'начальная школа'},\n",
       " {'locale': 'ru', 'value': 'начальные школы'},\n",
       " {'locale': 'ru', 'value': 'общеобразовательная школа'},\n",
       " {'locale': 'ru', 'value': 'общеобразовательные школы'},\n",
       " {'locale': 'uk', 'value': 'початкова школа'},\n",
       " {'locale': 'uk', 'value': 'початкові школи'},\n",
       " {'locale': 'uk', 'value': 'середня загальноосвітня школа'},\n",
       " {'locale': 'uk', 'value': 'середня школа'},\n",
       " {'locale': 'uk', 'value': 'середні школи'},\n",
       " {'locale': 'ru', 'value': 'средние школы'},\n",
       " {'locale': 'ru', 'value': 'средняя общеобразовательная школа'},\n",
       " {'locale': 'ru', 'value': 'средняя школа'},\n",
       " {'locale': 'ru', 'value': 'сш'},\n",
       " {'locale': 'uk', 'value': 'сш'},\n",
       " {'locale': 'ru', 'value': 'школа'},\n",
       " {'locale': 'uk', 'value': 'школа'},\n",
       " {'locale': 'uk', 'value': 'школи'},\n",
       " {'locale': 'uk', 'value': 'школи екстернат'},\n",
       " {'locale': 'uk', 'value': 'школи загальноосвітні'},\n",
       " {'locale': 'ru', 'value': 'школы'},\n",
       " {'locale': 'ru', 'value': 'школы общеобразовательные'},\n",
       " {'locale': 'ru', 'value': 'школы экстернат'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubric_data.phrases[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'value': {'locale': 'tr',\n",
       "   'value': 'Çocuklara orta eğitimi veren eğitim kurumları. Adı \"Eğitim merkezi\" olarak belirtilmişse kurumun ortaokul mu anaokulu mu olduğunu sormak gerek. Hem ortaokul hem de anaokuluysa her iki kategori seçmek gerek.\\n\\nBenzer kategoriler: Lise, Kolejler, Liseler, Sanatoryum okulu, Özel Okullar, Yatılı okul.'}},\n",
       " {'value': {'locale': 'ru',\n",
       "   'value': 'Образовательные учреждения, дающие общее среднее образование детям. Если в названии указано Центр образования, то нужно уточнить, школа это или детский сад. Если и школа, и детский сад, ставим обе рубрики. Название оформляется следующим образом: Центр Образования № 1811; Центр Образования № 1811 Начальная школа; Центр Образования № 1811 Дошкольное отделение.\\n\\nПохожие рубрики: Гимназия, Колледж, Лицей, Школа санаторного типа, Частная школа, Школа-интернат.'}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubric_data.descriptions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'locale': 'de', 'value': 'Allgemeinbildende Schule'},\n",
       " {'locale': 'tr', 'value': 'Ortaokullar'},\n",
       " {'locale': 'en', 'value': 'School'},\n",
       " {'locale': 'it', 'value': \"Scuola d'insegnamento generale\"},\n",
       " {'locale': 'fr', 'value': 'École secondaire'},\n",
       " {'locale': 'kk', 'value': 'Жалпы білім беретін мектеп'},\n",
       " {'locale': 'uk', 'value': 'Загальноосвітня школа'},\n",
       " {'locale': 'ru', 'value': 'Общеобразовательная школа'},\n",
       " {'locale': 'uz', 'value': 'Умумтаълим мактаби'},\n",
       " {'locale': 'hy', 'value': 'Հանրակրթական դպրոց'},\n",
       " {'locale': 'fa', 'value': 'مدرسه جامع'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubric_data.names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordsFromString(x) -> str:\n",
    "    return re.sub(r\"[^A-Za-zА-Яа-я]+\", ' ', x).lower().split()\n",
    "\n",
    "def getIntersectionWordsCount(x) -> int:\n",
    "    return len(set(getWordsFromString(x[0])) & set(getWordsFromString(x[1])))\n",
    "\n",
    "def getSynonymousNamesCount(x) -> int:\n",
    "    node = train_org_json.get(str(x))\n",
    "    if node is not None:\n",
    "        return len(node[\"names\"])\n",
    "    return 0\n",
    "\n",
    "def getEncodedLangs():\n",
    "    langs = train_data['query'].apply(lambda x: langdetect.detect(x))\n",
    "    sortedLangs = [lang for lang, _ in Counter(langs).most_common()]\n",
    "    langsEncoder = OneHotEncoder(sparse=False).fit(langs.values.reshape(-1,1))\n",
    "    encodedLangs = langsEncoder.transform(langs.values.reshape(-1,1))\n",
    "    langsIdx = [np.where(langsEncoder.categories_[0] == lang)[0][0] for lang in sortedLangs[:10]]\n",
    "    \n",
    "    newEncodedLangs = np.zeros((encodedLangs.shape[0], 11))\n",
    "    for i, idx in enumerate(langsIdx):\n",
    "        newEncodedLangs[:, i] = encodedLangs[:, idx]\n",
    "    for row in newEncodedLangs:\n",
    "        if row.sum() == 0:\n",
    "            row[-1] = 1\n",
    "    return newEncodedLangs\n",
    "\n",
    "def getRubricsCount(x) -> int:\n",
    "    node = train_org_json.get(str(x))\n",
    "    if node is not None:\n",
    "        return len(node[\"rubrics\"])\n",
    "    return 0\n",
    "\n",
    "def getWorkTime(x) -> int:\n",
    "    node = train_org_json.get(str(x))\n",
    "    if node is not None:\n",
    "        work_interval_sum = 0\n",
    "        for work_interval in node[\"work_intervals\"]:\n",
    "            work_interval_sum += work_interval[\"time_minutes_end\"] - work_interval[\"time_minutes_begin\"]\n",
    "        if len(node[\"work_intervals\"]) != 0:\n",
    "            return work_interval_sum / len(node[\"work_intervals\"])\n",
    "    return 0\n",
    "\n",
    "def getDaysCount(x):\n",
    "    node = train_org_json.get(str(x))\n",
    "    if node is not None:\n",
    "        daysCount = 0\n",
    "        for work_interval in node[\"work_intervals\"]:\n",
    "            day = work_interval[\"day\"]\n",
    "            if day == \"everyday\":\n",
    "                daysCount = max(daysCount, 7)\n",
    "            elif day == \"weekdays\":\n",
    "                daysCount = max(daysCount, 5)\n",
    "            elif day == \"weekend\":\n",
    "                daysCount = max(daysCount, 2)\n",
    "            elif day in [\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\"]:\n",
    "                daysCount = 1\n",
    "            else:\n",
    "                daysCount = 0\n",
    "        return daysCount\n",
    "    return 0\n",
    "\n",
    "def getRegionCode(x) -> str:\n",
    "    node = train_org_json.get(str(x))\n",
    "    if node is not None:\n",
    "        return node[\"address\"][\"region_code\"]\n",
    "    return 0\n",
    "\n",
    "def getEncodedRegionCode():\n",
    "    regionCodes = train_data[\"org_id\"].apply(getRegionCode).values\n",
    "    sortedRegionCodes = [code for code, _ in Counter(regionCodes).most_common()[:10]]\n",
    "    codesEncoder = OneHotEncoder(sparse=False).fit(regionCodes.reshape(-1,1))\n",
    "    encodedCodes = codesEncoder.transform(regionCodes.reshape(-1,1))\n",
    "    codesIdx = [np.where(codesEncoder.categories_[0] == code)[0][0] for code in sortedRegionCodes[:10]]\n",
    "    \n",
    "    newEncodedCodes = np.zeros((encodedCodes.shape[0], 11))\n",
    "    for i, idx in enumerate(codesIdx):\n",
    "        newEncodedCodes[:, i] = encodedCodes[:, idx]\n",
    "    for row in newEncodedCodes:\n",
    "        if row.sum() == 0:\n",
    "            row[-1] = 1\n",
    "    return newEncodedCodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['query_id'] = train_data['query_id']\n",
    "df['query_words_count'] = train_data['query'].apply(lambda query: len(getWordsFromString(query)))\n",
    "df['org_name_words_count'] = train_data['org_name'].apply(lambda name: len(getWordsFromString(name)))\n",
    "df['intersection_words_count'] = train_data[['query', 'org_name']].apply(getIntersectionWordsCount, axis=1)\n",
    "df['jaccard_score'] = df['intersection_words_count'] / (df['query_words_count'] + df['org_name_words_count'] - df['intersection_words_count'])\n",
    "df['synonymous_names_count'] = train_data['org_id'].apply(getSynonymousNamesCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rubrics_count'] = train_data['org_id'].apply(getRubricsCount)\n",
    "df['worktime'] = train_data['org_id'].apply(getWorkTime)\n",
    "df['workdays_count'] = train_data['org_id'].apply(getDaysCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"relevance\"] = train_data[\"relevance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_words_count</th>\n",
       "      <th>org_name_words_count</th>\n",
       "      <th>intersection_words_count</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>synonymous_names_count</th>\n",
       "      <th>rubrics_count</th>\n",
       "      <th>worktime</th>\n",
       "      <th>workdays_count</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>480.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  query_words_count  org_name_words_count  \\\n",
       "0        11                  7                     7   \n",
       "1        11                  7                     7   \n",
       "2        11                  7                     4   \n",
       "3        11                  7                     4   \n",
       "4        11                  7                     2   \n",
       "\n",
       "   intersection_words_count  jaccard_score  synonymous_names_count  \\\n",
       "0                         1       0.076923                       5   \n",
       "1                         1       0.076923                       5   \n",
       "2                         1       0.100000                       7   \n",
       "3                         1       0.100000                       7   \n",
       "4                         1       0.125000                       3   \n",
       "\n",
       "   rubrics_count  worktime  workdays_count  relevance  \n",
       "0              1     240.0               1        0.0  \n",
       "1              1     540.0               5        0.0  \n",
       "2              1     480.0               5        0.0  \n",
       "3              1     240.0               1        0.0  \n",
       "4              1     540.0               5        0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ранжирование\n",
    "\n",
    "![](http://i.imgur.com/2QnD2nF.jpg)\n",
    "\n",
    "Задачу поискового ранжирования можно описать следующим образом: имеется множество документов $d \\in D$ и множество запросов $q \\in Q$. Требуется оценить *степень релевантности* документа по отношению к запросу: $(q, d) \\mapsto r$, относительно которой будет производиться ранжирование. Для восстановления этой зависимости используются методы машинного обучения. Обычно используется три типа:\n",
    " - признаки запроса $q$, например: мешок слов текста запроса, его длина, ...\n",
    " - документа $d$, например: значение PageRank, мешок слов, доменное имя, ...\n",
    " - пары $(q, d)$, например: число вхождений фразы из запроса $q$ в документе $d$, ...\n",
    "\n",
    "Одна из отличительных особенностей задачи ранжирования от классических задач машинного обучения заключается в том, что качество результата зависит не от предсказанных оценок релевантности, а от порядка следования документов в рамках конкретного запроса, т.е. важно не абсолютное значение релевантности (его достаточно трудно формализовать в виде числа), а то, более или менее релевантен документ, относительно других документов.\n",
    "### Подходы к решению задачи ранжирования\n",
    "Существуют 3 основных подхода, различие между которыми в используемой функции потерь:\n",
    "  \n",
    "1. **Pointwise подход**. В этом случае рассматривается *один объект* (в случае поискового ранжирования - конкретный документ) и функция потерь считается только по нему. Любой стандартный классификатор или регрессор может решать pointwise задачу ранжирования, обучившись предсказывать значение таргета. Итоговое ранжирование получается после сортировки документов к одному запросу по предсказанию такой модели.\n",
    "2. **Pairwise подход**. В рамках данной модели функция потерь вычисляется по *паре объектов*. Другими словами, функция потерь штрафует модель, если отражированная этой моделью пара документов оказалась в неправильном порядке.\n",
    "3. **Listwise подход**. Этот подход использует все объекты для вычисления функции потерь, стараясь явно оптимизировать правильный порядок.\n",
    "\n",
    "### Оценка качества\n",
    "\n",
    "Для оценивания качества ранжирования найденных документов в поиске используются асессорские оценки. Само оценивание происходит на скрытых от обучения запросах $Queries$. Для этого традиционно используется метрика *DCG* ([Discounted Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)) и ее нормализованный вариант — *nDCG*, всегда принимающий значения от 0 до 1.\n",
    "Для одного запроса DCG считается следующим образом:\n",
    "$$ DCG = \\sum_{i=1}^P\\frac{(2^{rel_i} - 1)}{\\log_2(i+1)}, $$\n",
    "\n",
    "где $P$ — число документов в поисковой выдаче, $rel_i$ — релевантность (асессорская оценка) документа, находящегося на i-той позиции.\n",
    "\n",
    "*IDCG* — идеальное (наибольшее из возможных) значение *DCG*, может быть получено путем ранжирования документов по убыванию асессорских оценок.\n",
    "\n",
    "Итоговая формула для расчета *nDCG*:\n",
    "\n",
    "$$nDCG = \\frac{DCG}{IDCG} \\in [0, 1].$$\n",
    "\n",
    "Чтобы оценить значение *nDCG* на выборке $Queries$ ($nDCG_{Queries}$) размера $N$, необходимо усреднить значение *nDCG* по всем запросам  выборки:\n",
    "$$nDCG_{Queries} = \\frac{1}{N}\\sum_{q \\in Queries}nDCG(q).$$\n",
    "\n",
    "Пример реализации метрик ранжирование на python можно найти [здесь](https://gist.github.com/mblondel/7337391)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках нашей задачи «документом» будет являться организация.\n",
    "\n",
    "Разбейте обучающую выборку на обучение и контроль в соотношении 70 / 30. Обратите внимание, что разбивать необходимо множество запросов, а не строчки датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "gss = GroupShuffleSplit(test_size=.30, n_splits=1, random_state = 457).split(df, groups=df['query_id'])\n",
    "\n",
    "X_train_inds, X_test_inds = next(gss)\n",
    "\n",
    "new_train_data = df.iloc[X_train_inds]\n",
    "X_train = new_train_data.loc[:, ~new_train_data.columns.isin(['relevance'])]\n",
    "y_train = new_train_data.loc[:, new_train_data.columns.isin(['query_id', 'relevance'])]\n",
    "\n",
    "groups = train_data.groupby('query_id').size().to_frame('size')['size'].to_numpy()\n",
    "\n",
    "new_test_data = df.iloc[X_test_inds]\n",
    "\n",
    "X_test = new_test_data.loc[:, ~new_test_data.columns.isin(['relevance'])]\n",
    "y_test = new_test_data.loc[:, new_test_data.columns.isin(['query_id', 'relevance'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20510, 9), (8764, 9))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_words_count</th>\n",
       "      <th>org_name_words_count</th>\n",
       "      <th>intersection_words_count</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>synonymous_names_count</th>\n",
       "      <th>rubrics_count</th>\n",
       "      <th>worktime</th>\n",
       "      <th>workdays_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>480.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  query_words_count  org_name_words_count  \\\n",
       "0        11                  7                     7   \n",
       "1        11                  7                     7   \n",
       "2        11                  7                     4   \n",
       "3        11                  7                     4   \n",
       "4        11                  7                     2   \n",
       "\n",
       "   intersection_words_count  jaccard_score  synonymous_names_count  \\\n",
       "0                         1       0.076923                       5   \n",
       "1                         1       0.076923                       5   \n",
       "2                         1       0.100000                       7   \n",
       "3                         1       0.100000                       7   \n",
       "4                         1       0.125000                       3   \n",
       "\n",
       "   rubrics_count  worktime  workdays_count  \n",
       "0              1     240.0               1  \n",
       "1              1     540.0               5  \n",
       "2              1     480.0               5  \n",
       "3              1     240.0               1  \n",
       "4              1     540.0               5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  relevance\n",
       "0        11        0.0\n",
       "1        11        0.0\n",
       "2        11        0.0\n",
       "3        11        0.0\n",
       "4        11        0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_words_count</th>\n",
       "      <th>org_name_words_count</th>\n",
       "      <th>intersection_words_count</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>synonymous_names_count</th>\n",
       "      <th>rubrics_count</th>\n",
       "      <th>worktime</th>\n",
       "      <th>workdays_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>780.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id  query_words_count  org_name_words_count  \\\n",
       "147       116                  1                     4   \n",
       "\n",
       "     intersection_words_count  jaccard_score  synonymous_names_count  \\\n",
       "147                         0            0.0                       6   \n",
       "\n",
       "     rubrics_count  worktime  workdays_count  \n",
       "147              1     780.0               7  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>116</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id  relevance\n",
       "147       116       0.14"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Далее рассмотрим несколько подходов предсказания релевантности. Для оценивания качества моделей используйте метрику nDCG на контроле. В случае подбора гиперпараметров используйте кросс-валидацию по 5 блокам, где разбиение должно быть по запросам, а не строчкам датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ранжируем с XGBoost и CatBoost\n",
    "\n",
    "XGBoost имеет несколько функций потерь для решения задачи ранжирования:\n",
    "1. **reg:linear** — данную функцию потерь можно использовать для решения задачи ранжирование *pointwise* подходом.\n",
    "2. **rank:pairwise** — в качестве *pairwise* модели в XGBoost реализован [RankNet](http://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf), в котором минимизируется гладкий функционал качества ранжирования: $$ Obj = \\sum_{i \\prec j} \\mathcal{L}\\left(a(x_j) - a(x_i)\\right) \\rightarrow min $$ $$ \\mathcal{L}(M) = log(1 + e^{-M}), $$ где $ a(x) $ - функция ранжирования. Суммирование ведется по всем парам объектов, для которых определено отношение порядка, например, для пар документов, показанных по одному запросу. Таким образом функция потерь штрафует за то, что пара объектов неправильно упорядочена.\n",
    "3. **rank:map, rank:ndcg** — реализация [LambdaRank](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf) для двух метрик: [MAP](https://en.wikipedia.org/wiki/Information_retrieval#Mean_average_precision) и **nDCG**. Известно, что для того, чтобы оптимизировать негладкий функционал, такой как **nDCG**,  нужно домножить градиент функционала $ Obj(a) $ на значение $\\Delta NDCG_{ij} $ — изменение значения функционала качества при замене $x_i$ на $ x_j$.  Поскольку для вычисления метрик необходимы все объекты выборки, то эти две ранжирующие функции потерь являются представителями класса *listwise* моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализованные в CatBoost ранжирующие функции потерь можной найти [здесь](https://catboost.ai/docs/concepts/loss-functions-ranking.html#groupwise-metrics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 балла) Задание 2.** Попробуйте различные функции потерь (регрессионные и ранжирующие) для моделей XGBoost и CatBoost. Настройте основные параметры моделей (глубина, кол-во деревьев, глубина, скорость обучения, регуляризация).  \n",
    "Сравните построенные модели с точки зрения метрики nDCG на контроле и проанализируйте полученные результаты:\n",
    "  - какая модель работает лучше всего для данной задачи? \n",
    "  - в чем достоинства/недостатки каждой? \n",
    "  - сравните модели между собой: \n",
    "   - получается ли сравнимое качество линейного pointwise подхода с остальными моделями? \n",
    "   - заметна ли разница в качестве при использовании бустинга с разными функциями потерь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Перед обучением разобьем обучающую выборку на 5 фолдов для подбора параметров моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "val_gss = GroupShuffleSplit(n_splits=n_folds, test_size=0.2, random_state=457)\n",
    "\n",
    "fold_indexes = []\n",
    "for train_idx, test_idx in val_gss.split(new_train_data, groups=new_train_data['query_id']):\n",
    "    fold_indexes.append({'train_idx': train_idx, 'test_idx': test_idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train_idx': array([    0,     1,     2, ..., 20507, 20508, 20509]),\n",
       "  'test_idx': array([  250,   251,   252, ..., 20495, 20496, 20497])},\n",
       " {'train_idx': array([    0,     1,     2, ..., 20507, 20508, 20509]),\n",
       "  'test_idx': array([   91,    92,    93, ..., 20495, 20496, 20497])},\n",
       " {'train_idx': array([    0,     1,     2, ..., 20495, 20496, 20497]),\n",
       "  'test_idx': array([   91,    92,    93, ..., 20507, 20508, 20509])},\n",
       " {'train_idx': array([    0,     1,     2, ..., 20507, 20508, 20509]),\n",
       "  'test_idx': array([   20,    21,    22, ..., 20345, 20346, 20347])},\n",
       " {'train_idx': array([   20,    21,    22, ..., 20507, 20508, 20509]),\n",
       "  'test_idx': array([    0,     1,     2, ..., 20345, 20346, 20347])}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_i_fold(X, i):\n",
    "    X_val_train = X.iloc[fold_indexes[i]['train_idx']].loc[:, ~X.columns.isin(['relevance'])]\n",
    "    y_val_train = X.iloc[fold_indexes[i]['train_idx']].loc[:, X.columns.isin(['query_id','relevance'])]\n",
    "    \n",
    "    X_val_test = X.iloc[fold_indexes[i]['test_idx']].loc[:, ~X.columns.isin(['relevance'])]\n",
    "    y_val_test = X.iloc[fold_indexes[i]['test_idx']].loc[:, X.columns.isin(['query_id','relevance'])]\n",
    "    return (X_val_train, y_val_train), (X_val_test, y_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_val_0, y_val_0), (X_val_1, y_val_1) = get_i_fold(new_train_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_words_count</th>\n",
       "      <th>org_name_words_count</th>\n",
       "      <th>intersection_words_count</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>synonymous_names_count</th>\n",
       "      <th>rubrics_count</th>\n",
       "      <th>worktime</th>\n",
       "      <th>workdays_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>480.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  query_words_count  org_name_words_count  \\\n",
       "0        11                  7                     7   \n",
       "1        11                  7                     7   \n",
       "2        11                  7                     4   \n",
       "3        11                  7                     4   \n",
       "4        11                  7                     2   \n",
       "\n",
       "   intersection_words_count  jaccard_score  synonymous_names_count  \\\n",
       "0                         1       0.076923                       5   \n",
       "1                         1       0.076923                       5   \n",
       "2                         1       0.100000                       7   \n",
       "3                         1       0.100000                       7   \n",
       "4                         1       0.125000                       3   \n",
       "\n",
       "   rubrics_count  worktime  workdays_count  \n",
       "0              1     240.0               1  \n",
       "1              1     540.0               5  \n",
       "2              1     480.0               5  \n",
       "3              1     240.0               1  \n",
       "4              1     540.0               5  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  relevance\n",
       "0        11        0.0\n",
       "1        11        0.0\n",
       "2        11        0.0\n",
       "3        11        0.0\n",
       "4        11        0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_words_count</th>\n",
       "      <th>org_name_words_count</th>\n",
       "      <th>intersection_words_count</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>synonymous_names_count</th>\n",
       "      <th>rubrics_count</th>\n",
       "      <th>worktime</th>\n",
       "      <th>workdays_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id  query_words_count  org_name_words_count  \\\n",
       "362       216                  1                     2   \n",
       "363       216                  1                     2   \n",
       "364       216                  1                     2   \n",
       "365       216                  1                     2   \n",
       "366       216                  1                     2   \n",
       "\n",
       "     intersection_words_count  jaccard_score  synonymous_names_count  \\\n",
       "362                         1            0.5                       6   \n",
       "363                         1            0.5                       5   \n",
       "364                         1            0.5                       5   \n",
       "365                         1            0.5                       5   \n",
       "366                         1            0.5                       6   \n",
       "\n",
       "     rubrics_count  worktime  workdays_count  \n",
       "362              1    1440.0               7  \n",
       "363              1       0.0               0  \n",
       "364              1    1440.0               7  \n",
       "365              1    1440.0               7  \n",
       "366              1    1440.0               7  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>216</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>216</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>216</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>216</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>216</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id  relevance\n",
       "362       216       0.14\n",
       "363       216       0.14\n",
       "364       216       0.14\n",
       "365       216       0.14\n",
       "366       216       0.14"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Напишем функцию, вычисляющую метрику nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCG(y_true, y_pred, k=10):\n",
    "    order = np.argsort(y_pred)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2) + 1e-6\n",
    "    return np.sum(gains / discounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nDCG(y_true, y_pred, k=10):\n",
    "    best = DCG(y_true, y_true, k) + 1e-6\n",
    "    actual = DCG(y_true, y_pred, k)\n",
    "    return actual / best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nDCG_query(y_true_group, y_pred_group):\n",
    "    scores = []\n",
    "    for query_id in y_pred_group.index.values:\n",
    "        scores.append(nDCG(y_true_group[query_id], y_pred_group[query_id]))\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Напишем функцию, которая делает кросс-валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, df):\n",
    "    return model.predict(df.loc[:, ~df.columns.isin(['query_id'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_scores(model):\n",
    "    ndcg_score = []\n",
    "    for i in range(n_folds):\n",
    "        (X_val_train, y_val_train), (X_val_test, y_val_test) = get_i_fold(new_train_data, i)\n",
    "        model.fit(X_val_train.loc[:, ~X_val_train.columns.isin(['query_id'])], y_val_train.relevance, verbose=True)\n",
    "\n",
    "        predictions = (X_val_test.groupby('query_id').apply(lambda x: predict(model, x)))\n",
    "        ndcg_score.append(nDCG_query(y_val_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions))\n",
    "    return ndcg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_words_count</th>\n",
       "      <th>org_name_words_count</th>\n",
       "      <th>intersection_words_count</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>synonymous_names_count</th>\n",
       "      <th>rubrics_count</th>\n",
       "      <th>worktime</th>\n",
       "      <th>workdays_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_words_count  org_name_words_count  intersection_words_count  \\\n",
       "0                  7                     7                         1   \n",
       "\n",
       "   jaccard_score  synonymous_names_count  rubrics_count  worktime  \\\n",
       "0       0.076923                       5              1     240.0   \n",
       "\n",
       "   workdays_count  \n",
       "0               1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[:, ~X_train.columns.isin(['query_id'])].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  relevance\n",
       "0        11        0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reg:linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=32,\n",
       "             num_parallel_tree=1, objective='reg:linear', predictor='auto',\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             subsample=1, tree_method='exact', validate_parameters=1,\n",
       "             verbosity=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(objective='reg:linear')\n",
    "model.fit(X_train.loc[:, ~X_train.columns.isin(['query_id'])], y_train.relevance, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (X_test.groupby('query_id').apply(lambda x: predict(model, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query_id\n",
       "116      [0.11655478, 0.11695577, 0.12280623, 0.1249737...\n",
       "198      [0.084806465, 0.11102717, 0.12001192, 0.120767...\n",
       "202      [0.118985526, 0.11377729, 0.14943244, 0.120745...\n",
       "232      [0.11378162, 0.1161177, 0.119079664, 0.1300364...\n",
       "259      [0.07688985, 0.11349801, 0.122818634, 0.11719,...\n",
       "                               ...                        \n",
       "35959    [0.008444955, 0.02298762, 0.0485556, 0.0084449...\n",
       "36170    [0.052228518, 0.06538302, 0.020245967, 0.24301...\n",
       "36282    [0.023292601, 0.039437298, 0.024750715, 0.0195...\n",
       "36304    [0.06281152, 0.0698221, 0.078189336, 0.1415823...\n",
       "36337    [0.081715316, 0.08090903, 0.06880772, 0.111690...\n",
       "Length: 600, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query_id\n",
       "116      [0.14, 0.14, 0.14, 0.14, 0.14, 0.14, 0.14, 0.1...\n",
       "198      [0.07, 0.07, 0.07, 0.14, 0.14, 0.14, 0.14, 0.1...\n",
       "202      [0.07, 0.07, 0.07, 0.07, 0.07, 0.14, 0.14, 0.1...\n",
       "232      [0.0, 0.07, 0.14, 0.14, 0.14, 0.14, 0.14, 0.14...\n",
       "259      [0.0, 0.0, 0.07, 0.14, 0.14, 0.14, 0.14, 0.14,...\n",
       "                               ...                        \n",
       "35959    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "36170       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45]\n",
       "36282    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "36304    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "36337    [0.0, 0.0, 0.0, 0.01, 0.01, 0.02, 0.02, 0.04, ...\n",
       "Length: 600, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.groupby('query_id').apply(lambda x: list(x.relevance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6768208329927655"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nDCG_query(y_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь начнем подбирать гиперпараметры по кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1, mean nDCG on cv = 0.6773071233403879\n",
      "max_depth = 2, mean nDCG on cv = 0.6876887644200441\n",
      "max_depth = 3, mean nDCG on cv = 0.6789186465196557\n",
      "max_depth = 4, mean nDCG on cv = 0.675239519995399\n",
      "max_depth = 5, mean nDCG on cv = 0.6718224501855453\n",
      "max_depth = 6, mean nDCG on cv = 0.6697230091058549\n",
      "max_depth = 7, mean nDCG on cv = 0.6600284378245252\n",
      "max_depth = 8, mean nDCG on cv = 0.6595982976146908\n"
     ]
    }
   ],
   "source": [
    "#Максимальная глубина\n",
    "max_depths = [1,2,3,4,5,6,7,8]\n",
    "for depth in max_depths:\n",
    "    model = xgb.XGBRegressor(\n",
    "                objective='reg:linear',\n",
    "                max_depth=depth,\n",
    "                verbosity=0\n",
    "            )\n",
    "    \n",
    "    print(\"max_depth = {}, mean nDCG on cv = {}\".format(depth, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.001, mean nDCG on cv = 0.901595693660804\n",
      "lr = 0.01, mean nDCG on cv = 0.8429928931952151\n",
      "lr = 0.1, mean nDCG on cv = 0.6925664402847149\n",
      "lr = 1, mean nDCG on cv = 0.6736485400355299\n"
     ]
    }
   ],
   "source": [
    "#Скорость обучения\n",
    "lrs = [1e-3, 1e-2, 1e-1, 1]\n",
    "for lr in lrs:\n",
    "    model = xgb.XGBRegressor(\n",
    "                objective='reg:linear',\n",
    "                learning_rate=lr,\n",
    "                max_depth=2,\n",
    "                verbosity=0\n",
    "            )\n",
    "    \n",
    "    print(\"lr = {}, mean nDCG on cv = {}\".format(lr, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10, mean nDCG on cv = 0.9028176034883838\n",
      "n_estimators = 25, mean nDCG on cv = 0.9020395133143995\n",
      "n_estimators = 50, mean nDCG on cv = 0.9020395133143995\n",
      "n_estimators = 75, mean nDCG on cv = 0.901595693660804\n",
      "n_estimators = 100, mean nDCG on cv = 0.901595693660804\n"
     ]
    }
   ],
   "source": [
    "#Число деревьев\n",
    "n_estimators = [10, 25, 50, 75, 100]\n",
    "for n in n_estimators:\n",
    "    model = xgb.XGBRegressor(\n",
    "                objective='reg:linear',\n",
    "                n_estimators=n,\n",
    "                learning_rate=1e-3,\n",
    "                max_depth=2,\n",
    "                verbosity=0\n",
    "            )\n",
    "    \n",
    "    print(\"n_estimators = {}, mean nDCG on cv = {}\".format(n, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.0001, lambda = 0.0001, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.0001, lambda = 0.001, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.0001, lambda = 0.01, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.0001, lambda = 0.1, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.0001, lambda = 1, mean nDCG on cv = 0.9028176034883838\n",
      "alpha = 0.001, lambda = 0.0001, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.001, lambda = 0.001, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.001, lambda = 0.01, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.001, lambda = 0.1, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.001, lambda = 1, mean nDCG on cv = 0.9028176034883838\n",
      "alpha = 0.01, lambda = 0.0001, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.01, lambda = 0.001, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.01, lambda = 0.01, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.01, lambda = 0.1, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.01, lambda = 1, mean nDCG on cv = 0.9028176034883838\n",
      "alpha = 0.1, lambda = 0.0001, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.1, lambda = 0.001, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.1, lambda = 0.01, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.1, lambda = 0.1, mean nDCG on cv = 0.9020395133143995\n",
      "alpha = 0.1, lambda = 1, mean nDCG on cv = 0.9028176034883838\n",
      "alpha = 1, lambda = 0.0001, mean nDCG on cv = 0.9038274646330962\n",
      "alpha = 1, lambda = 0.001, mean nDCG on cv = 0.9038274646330962\n",
      "alpha = 1, lambda = 0.01, mean nDCG on cv = 0.9038274646330962\n",
      "alpha = 1, lambda = 0.1, mean nDCG on cv = 0.9038274646330962\n",
      "alpha = 1, lambda = 1, mean nDCG on cv = 0.9038274646330962\n"
     ]
    }
   ],
   "source": [
    "#Регуляризация\n",
    "reg_alpha = [1e-4, 1e-3, 1e-2, 1e-1, 1] # for L1 regularization\n",
    "reg_lambda = [1e-4, 1e-3, 1e-2, 1e-1, 1] # for L2 regularization\n",
    "for alpha in reg_alpha:\n",
    "    for lamb in reg_lambda:\n",
    "        model = xgb.XGBRegressor(\n",
    "                    objective='reg:linear',\n",
    "                    n_estimators=10,\n",
    "                    learning_rate=1e-3, \n",
    "                    max_depth=2,\n",
    "                    reg_alpha=alpha,\n",
    "                    reg_lambda=lamb,\n",
    "                    verbosity=0\n",
    "                )\n",
    "        \n",
    "        print(\"alpha = {}, lambda = {}, mean nDCG on cv = {}\".format(alpha, lamb, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получившиеся параметры: n_estimators=10, learning_rate=1e-3, max_depth=2, reg_alpha=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG sore for XGBoost with reg:linear: 0.8993894282924212\n"
     ]
    }
   ],
   "source": [
    "xgb_linear = xgb.XGBRegressor(\n",
    "                objective='reg:linear',\n",
    "                n_estimators=n,\n",
    "                learning_rate=1e-3, \n",
    "                max_depth=2,\n",
    "                reg_alpha=1,\n",
    "                verbosity=0\n",
    "            )\n",
    "\n",
    "xgb_linear.fit(X_train.loc[:, ~X_train.columns.isin(['query_id'])], y_train.relevance, verbose=0)\n",
    "\n",
    "predictions = (X_test.groupby('query_id').apply(lambda x: predict(xgb_linear, x)))\n",
    "xgb_linear_ndcg = nDCG_query(y_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions)\n",
    "print('nDCG sore for XGBoost with reg:linear:', xgb_linear_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем ещё раз оптимизировать макс глубину"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1, mean nDCG on cv = 0.9060168475669513\n",
      "max_depth = 2, mean nDCG on cv = 0.9038274646330962\n",
      "max_depth = 3, mean nDCG on cv = 0.8734368758929337\n",
      "max_depth = 4, mean nDCG on cv = 0.8730923119869953\n",
      "max_depth = 5, mean nDCG on cv = 0.8731084344844907\n",
      "max_depth = 6, mean nDCG on cv = 0.8731084344844907\n",
      "max_depth = 7, mean nDCG on cv = 0.8731084344844907\n",
      "max_depth = 8, mean nDCG on cv = 0.8731084344844907\n"
     ]
    }
   ],
   "source": [
    "#Максимальная глубина\n",
    "max_depths = [1,2,3,4,5,6,7,8]\n",
    "for depth in max_depths:\n",
    "    model = xgb.XGBRegressor(\n",
    "                objective='reg:linear',\n",
    "                n_estimators=10,\n",
    "                learning_rate=1e-3, \n",
    "                max_depth=depth,\n",
    "                reg_alpha=1,\n",
    "                verbosity=0\n",
    "            )\n",
    "    print(\"max_depth = {}, mean nDCG on cv = {}\".format(depth, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG sore for XGBoost with reg:linear: 0.9113383867102114\n"
     ]
    }
   ],
   "source": [
    "xgb_linear = xgb.XGBRegressor(\n",
    "                objective='reg:linear',\n",
    "                n_estimators=10,\n",
    "                learning_rate=1e-3, \n",
    "                max_depth=1,\n",
    "                reg_alpha=1,\n",
    "                verbosity=0\n",
    "            )\n",
    "xgb_linear.fit(X_train.loc[:, ~X_train.columns.isin(['query_id'])], y_train.relevance, verbose=0)\n",
    "\n",
    "predictions = (X_test.groupby('query_id').apply(lambda x: predict(xgb_linear, x)))\n",
    "xgb_linear_ndcg = nDCG_query(y_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions)\n",
    "print('nDCG sore for XGBoost with reg:linear:', xgb_linear_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Огонь 🔥🔥🔥, получили больший скор с параметрами n_estimators=10, learning_rate=1e-3, max_depth=1, reg_alpha=1. Финальный nDCG для XGBoost с функцией потерь reg:linear равен 0.9113383867102114. Сделаем подбор гиперпараметров для остальных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rank:pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_scores(model):\n",
    "    ndcg_score = []\n",
    "    for i in range(n_folds):\n",
    "        (X_val_train, y_val_train), (X_val_test, y_val_test) = get_i_fold(new_train_data, i)\n",
    "        model.fit(X_val_train.loc[:, ~X_val_train.columns.isin(['query_id'])],\n",
    "                  y_val_train.relevance,\n",
    "                  group=X_val_train.groupby('query_id').size().to_frame('size')['size'].to_numpy(),\n",
    "                  verbose=True)\n",
    "\n",
    "        predictions = (X_val_test.groupby('query_id').apply(lambda x: predict(model, x)))\n",
    "        ndcg_score.append(nDCG_query(y_val_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions))\n",
    "    return ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1, mean nDCG on cv = 0.7318310095134807\n",
      "max_depth = 2, mean nDCG on cv = 0.7236469307379579\n",
      "max_depth = 3, mean nDCG on cv = 0.721403280135212\n",
      "max_depth = 4, mean nDCG on cv = 0.7120017800867692\n",
      "max_depth = 5, mean nDCG on cv = 0.6992698258062948\n",
      "max_depth = 6, mean nDCG on cv = 0.6945165769062985\n",
      "max_depth = 7, mean nDCG on cv = 0.6855018194556739\n",
      "max_depth = 8, mean nDCG on cv = 0.6754270186166655\n"
     ]
    }
   ],
   "source": [
    "#Максимальная глубина\n",
    "max_depths = [1,2,3,4,5,6,7,8]\n",
    "for depth in max_depths:\n",
    "    model = xgb.XGBRanker(\n",
    "                objective='rank:pairwise',\n",
    "                max_depth=depth\n",
    "            )\n",
    "    \n",
    "    print(\"max_depth = {}, mean nDCG on cv = {}\".format(depth, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.001, mean nDCG on cv = 0.805722399468667\n",
      "lr = 0.01, mean nDCG on cv = 0.7943976926073789\n",
      "lr = 0.1, mean nDCG on cv = 0.7512384755843294\n",
      "lr = 1, mean nDCG on cv = 0.7183302160140588\n"
     ]
    }
   ],
   "source": [
    "#Скорость обучения\n",
    "lrs = [1e-3, 1e-2, 1e-1, 1]\n",
    "for lr in lrs:\n",
    "    model = xgb.XGBRanker(\n",
    "                objective='rank:pairwise',\n",
    "                learning_rate=lrб\n",
    "                max_depth=1\n",
    "            )\n",
    "    \n",
    "    print(\"lr = {}, mean nDCG on cv = {}\".format(lr, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 5, mean nDCG on cv = 0.8298192203072512\n",
      "n_estimators = 10, mean nDCG on cv = 0.8192309947376692\n",
      "n_estimators = 25, mean nDCG on cv = 0.8118661885529284\n",
      "n_estimators = 50, mean nDCG on cv = 0.8060290045171883\n",
      "n_estimators = 75, mean nDCG on cv = 0.805722399468667\n",
      "n_estimators = 100, mean nDCG on cv = 0.805722399468667\n"
     ]
    }
   ],
   "source": [
    "#Число деревьев\n",
    "n_estimators = [5, 10, 25, 50, 75, 100]\n",
    "for n in n_estimators:\n",
    "    model = xgb.XGBRanker(\n",
    "                objective='rank:pairwise',\n",
    "                n_estimators=n,\n",
    "                learning_rate=1e-3,\n",
    "                max_depth=1,\n",
    "                verbosity=0\n",
    "            )\n",
    "    \n",
    "    print(\"n_estimators = {}, mean nDCG on cv = {}\".format(n, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.0001, lambda = 0.0001, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.0001, lambda = 0.001, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.0001, lambda = 0.01, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.0001, lambda = 0.1, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.0001, lambda = 1, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.001, lambda = 0.0001, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.001, lambda = 0.001, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.001, lambda = 0.01, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.001, lambda = 0.1, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.001, lambda = 1, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.01, lambda = 0.0001, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.01, lambda = 0.001, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.01, lambda = 0.01, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.01, lambda = 0.1, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.01, lambda = 1, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.1, lambda = 0.0001, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.1, lambda = 0.001, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.1, lambda = 0.01, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.1, lambda = 0.1, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 0.1, lambda = 1, mean nDCG on cv = 0.8298192203072512\n",
      "alpha = 1, lambda = 0.0001, mean nDCG on cv = 0.8320152840551158\n",
      "alpha = 1, lambda = 0.001, mean nDCG on cv = 0.8320152840551158\n",
      "alpha = 1, lambda = 0.01, mean nDCG on cv = 0.8320152840551158\n",
      "alpha = 1, lambda = 0.1, mean nDCG on cv = 0.8320152840551158\n",
      "alpha = 1, lambda = 1, mean nDCG on cv = 0.8320152840551158\n"
     ]
    }
   ],
   "source": [
    "#Регуляризация\n",
    "reg_alpha = [1e-4, 1e-3, 1e-2, 1e-1, 1] # for L1 regularization\n",
    "reg_lambda = [1e-4, 1e-3, 1e-2, 1e-1, 1] # for L2 regularization\n",
    "for alpha in reg_alpha:\n",
    "    for lamb in reg_lambda:\n",
    "        model = xgb.XGBRanker(\n",
    "                    objective='rank:pairwise',\n",
    "                    n_estimators=5,\n",
    "                    learning_rate=1e-3,\n",
    "                    max_depth=1,\n",
    "                    reg_alpha=alpha,\n",
    "                    reg_lambda=lamb,\n",
    "                    verbosity=0\n",
    "                )\n",
    "        \n",
    "        print(\"alpha = {}, lambda = {}, mean nDCG on cv = {}\".format(alpha, lamb, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG sore for XGBoost with rank:pairwise: 0.831457281077564\n"
     ]
    }
   ],
   "source": [
    "xgb_pairwise = xgb.XGBRanker(\n",
    "                    objective='rank:pairwise',\n",
    "                    n_estimators=5,\n",
    "                    learning_rate=1e-3,\n",
    "                    max_depth=1,\n",
    "                    reg_alpha=1,\n",
    "                    verbosity=0\n",
    "                )\n",
    "\n",
    "xgb_pairwise.fit(X_train.loc[:, ~X_train.columns.isin(['query_id'])],\n",
    "                 y_train.relevance,\n",
    "                 group=X_train.groupby('query_id').size().to_frame('size')['size'].to_numpy(),\n",
    "                 verbose=0)\n",
    "\n",
    "predictions = (X_test.groupby('query_id').apply(lambda x: predict(xgb_pairwise, x)))\n",
    "xgb_pairwise_ndcg = nDCG_query(y_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions)\n",
    "print('nDCG sore for XGBoost with rank:pairwise:', xgb_pairwise_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rank:map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1, mean nDCG on cv = 0.7252811898248768\n",
      "max_depth = 2, mean nDCG on cv = 0.7204651021293488\n",
      "max_depth = 3, mean nDCG on cv = 0.7168937165585063\n",
      "max_depth = 4, mean nDCG on cv = 0.708219748791444\n",
      "max_depth = 5, mean nDCG on cv = 0.706482853570288\n",
      "max_depth = 6, mean nDCG on cv = 0.6943518604016933\n",
      "max_depth = 7, mean nDCG on cv = 0.6905578011245271\n",
      "max_depth = 8, mean nDCG on cv = 0.6831534026369166\n"
     ]
    }
   ],
   "source": [
    "#Максимальная глубина\n",
    "max_depths = [1,2,3,4,5,6,7,8]\n",
    "for depth in max_depths:\n",
    "    model = xgb.XGBRanker(\n",
    "                objective='rank:map',\n",
    "                max_depth=depth\n",
    "            )\n",
    "    \n",
    "    print(\"max_depth = {}, mean nDCG on cv = {}\".format(depth, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.001, mean nDCG on cv = 0.8394773144097186\n",
      "lr = 0.01, mean nDCG on cv = 0.8394773144097186\n",
      "lr = 0.1, mean nDCG on cv = 0.7398893270801723\n",
      "lr = 1, mean nDCG on cv = 0.7177144774666341\n"
     ]
    }
   ],
   "source": [
    "#Скорость обучения\n",
    "lrs = [1e-3, 1e-2, 1e-1, 1]\n",
    "for lr in lrs:\n",
    "    model = xgb.XGBRanker(\n",
    "                objective='rank:map',\n",
    "                learning_rate=lr,\n",
    "                max_depth=1\n",
    "            )\n",
    "    \n",
    "    print(\"lr = {}, mean nDCG on cv = {}\".format(lr, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 5, mean nDCG on cv = 0.8394773144097186\n",
      "n_estimators = 10, mean nDCG on cv = 0.8394773144097186\n",
      "n_estimators = 25, mean nDCG on cv = 0.8394773144097186\n",
      "n_estimators = 50, mean nDCG on cv = 0.8394773144097186\n",
      "n_estimators = 75, mean nDCG on cv = 0.8394773144097186\n",
      "n_estimators = 100, mean nDCG on cv = 0.8394773144097186\n"
     ]
    }
   ],
   "source": [
    "#Число деревьев\n",
    "n_estimators = [5, 10, 25, 50, 75, 100]\n",
    "for n in n_estimators:\n",
    "    model = xgb.XGBRanker(\n",
    "                objective='rank:map',\n",
    "                n_estimators=n,\n",
    "                learning_rate=1e-3,\n",
    "                max_depth=1,\n",
    "                verbosity=0\n",
    "            )\n",
    "    print(\"n_estimators = {}, mean nDCG on cv = {}\".format(n, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.001, lambda = 0.001, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 0.001, lambda = 0.01, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 0.001, lambda = 0.1, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 0.001, lambda = 1, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 0.01, lambda = 0.001, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 0.01, lambda = 0.01, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 0.01, lambda = 0.1, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 0.01, lambda = 1, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 0.1, lambda = 0.001, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 0.1, lambda = 0.01, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 0.1, lambda = 0.1, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 0.1, lambda = 1, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 1, lambda = 0.001, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 1, lambda = 0.01, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 1, lambda = 0.1, mean nDCG on cv = 0.8394773144097186\n",
      "alpha = 1, lambda = 1, mean nDCG on cv = 0.8394773144097186\n"
     ]
    }
   ],
   "source": [
    "#Регуляризация\n",
    "reg_alpha = [1e-3, 1e-2, 1e-1, 1] # for L1 regularization\n",
    "reg_lambda = [1e-3, 1e-2, 1e-1, 1] # for L2 regularization\n",
    "for alpha in reg_alpha:\n",
    "    for lamb in reg_lambda:\n",
    "        model = xgb.XGBRanker(objective='rank:map',\n",
    "                              n_estimators=5,\n",
    "                              learning_rate=1e-3,\n",
    "                              max_depth=1,\n",
    "                              reg_alpha=alpha,\n",
    "                              reg_lambda=lamb,\n",
    "                              verbosity=0)\n",
    "        \n",
    "        print(\"alpha = {}, lambda = {}, mean nDCG on cv = {}\".format(alpha, lamb, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG sore for XGBoost with rank:map: 0.8562445567109971\n"
     ]
    }
   ],
   "source": [
    "xgb_map = xgb.XGBRanker(\n",
    "                objective='rank:map',\n",
    "                n_estimators=5,\n",
    "                learning_rate=1e-3,\n",
    "                max_depth=1,\n",
    "                verbosity=0\n",
    "            )\n",
    "\n",
    "xgb_map.fit(X_train.loc[:, ~X_train.columns.isin(['query_id'])],\n",
    "            y_train.relevance,\n",
    "            group=X_train.groupby('query_id').size().to_frame('size')['size'].to_numpy(),\n",
    "            verbose=0)\n",
    "\n",
    "predictions = (X_test.groupby('query_id').apply(lambda x: predict(xgb_map, x)))\n",
    "xgb_map_ndcg = nDCG_query(y_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions)\n",
    "print('nDCG sore for XGBoost with rank:map:', xgb_map_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rank:ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1, mean nDCG on cv = 0.9060168475669513\n",
      "max_depth = 2, mean nDCG on cv = 0.9060168475669513\n",
      "max_depth = 3, mean nDCG on cv = 0.9060168475669513\n",
      "max_depth = 4, mean nDCG on cv = 0.9060168475669513\n",
      "max_depth = 5, mean nDCG on cv = 0.9060168475669513\n",
      "max_depth = 6, mean nDCG on cv = 0.9060168475669513\n",
      "max_depth = 7, mean nDCG on cv = 0.9060168475669513\n",
      "max_depth = 8, mean nDCG on cv = 0.9060168475669513\n",
      "max_depth = 9, mean nDCG on cv = 0.9060168475669513\n",
      "max_depth = 10, mean nDCG on cv = 0.9060168475669513\n"
     ]
    }
   ],
   "source": [
    "#Максимальная глубина\n",
    "max_depths = [1,2,3,4,5,6,7,8,9,10]\n",
    "for depth in max_depths:\n",
    "    model = xgb.XGBRanker(\n",
    "                objective='rank:ndcg',\n",
    "                max_depth=depth\n",
    "            )\n",
    "\n",
    "    print(\"max_depth = {}, mean nDCG on cv = {}\".format(depth, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.001, mean nDCG on cv = 0.9060168475669513\n",
      "lr = 0.01, mean nDCG on cv = 0.9060168475669513\n",
      "lr = 0.1, mean nDCG on cv = 0.9060168475669513\n",
      "lr = 1, mean nDCG on cv = 0.9060168475669513\n"
     ]
    }
   ],
   "source": [
    "#Скорость обучения\n",
    "lrs = [1e-3, 1e-2, 1e-1, 1]\n",
    "for lr in lrs:\n",
    "    model = xgb.XGBRanker(\n",
    "                objective='rank:ndcg',\n",
    "                learning_rate=lr,\n",
    "                max_depth=1\n",
    "            )\n",
    "    \n",
    "    print(\"lr = {}, mean nDCG on cv = {}\".format(lr, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 1, mean nDCG on cv = 0.9060168475669513\n",
      "n_estimators = 2, mean nDCG on cv = 0.9060168475669513\n",
      "n_estimators = 3, mean nDCG on cv = 0.9060168475669513\n",
      "n_estimators = 5, mean nDCG on cv = 0.9060168475669513\n",
      "n_estimators = 10, mean nDCG on cv = 0.9060168475669513\n",
      "n_estimators = 25, mean nDCG on cv = 0.9060168475669513\n",
      "n_estimators = 50, mean nDCG on cv = 0.9060168475669513\n",
      "n_estimators = 75, mean nDCG on cv = 0.9060168475669513\n",
      "n_estimators = 100, mean nDCG on cv = 0.9060168475669513\n"
     ]
    }
   ],
   "source": [
    "#Число деревьев\n",
    "n_estimators = [1, 2, 3, 5, 10, 25, 50, 75, 100]\n",
    "for n in n_estimators:\n",
    "    model = xgb.XGBRanker(\n",
    "                objective='rank:ndcg',\n",
    "                n_estimators=n,\n",
    "                max_depth=1,\n",
    "                verbosity=0\n",
    "            )\n",
    "    \n",
    "    print(\"n_estimators = {}, mean nDCG on cv = {}\".format(n, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.001, lambda = 0.001, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 0.001, lambda = 0.01, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 0.001, lambda = 0.1, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 0.001, lambda = 1, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 0.01, lambda = 0.001, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 0.01, lambda = 0.01, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 0.01, lambda = 0.1, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 0.01, lambda = 1, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 0.1, lambda = 0.001, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 0.1, lambda = 0.01, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 0.1, lambda = 0.1, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 0.1, lambda = 1, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 1, lambda = 0.001, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 1, lambda = 0.01, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 1, lambda = 0.1, mean nDCG on cv = 0.9060168475669513\n",
      "alpha = 1, lambda = 1, mean nDCG on cv = 0.9060168475669513\n"
     ]
    }
   ],
   "source": [
    "#Регуляризация\n",
    "reg_alpha = [1e-3, 1e-2, 1e-1, 1] # for L1 regularization\n",
    "reg_lambda = [1e-3, 1e-2, 1e-1, 1] # for L2 regularization\n",
    "for alpha in reg_alpha:\n",
    "    for lamb in reg_lambda:\n",
    "        model = xgb.XGBRanker(\n",
    "                    objective='rank:ndcg',\n",
    "                    reg_alpha=alpha,\n",
    "                    reg_lambda=lamb,\n",
    "                    verbosity=0\n",
    "                )\n",
    "        \n",
    "        print(\"alpha = {}, lambda = {}, mean nDCG on cv = {}\".format(alpha, lamb, np.mean(cross_val_scores(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG score for XGBoost with rank:map: 0.9113383867102114\n"
     ]
    }
   ],
   "source": [
    "xgb_ndcg = xgb.XGBRanker(\n",
    "                objective='rank:ndcg'\n",
    "            )\n",
    "\n",
    "xgb_ndcg.fit(X_train.loc[:, ~X_train.columns.isin(['query_id'])],\n",
    "            y_train.relevance,\n",
    "            group=X_train.groupby('query_id').size().to_frame('size')['size'].to_numpy()\n",
    "            )\n",
    "\n",
    "predictions = (X_test.groupby('query_id').apply(lambda x: predict(xgb_ndcg, x)))\n",
    "xgb_ndcg_ndcg = nDCG_query(y_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions)\n",
    "print('nDCG score for XGBoost with rank:map:', xgb_ndcg_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost 🐈 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YetiRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_scores_cat(model):\n",
    "    ndcg_score = []\n",
    "    for i in range(n_folds):\n",
    "        (X_val_train, y_val_train), (X_val_test, y_val_test) = get_i_fold(new_train_data, i)\n",
    "        \n",
    "        train = cat.Pool(\n",
    "            data=X_val_train.loc[:, ~X_val_train.columns.isin(['query_id'])],\n",
    "            label=y_val_train.relevance,\n",
    "            group_id=X_val_train['query_id']\n",
    "        )\n",
    "        \n",
    "        model.fit(train, silent=True)\n",
    "\n",
    "        predictions = (X_val_test.groupby('query_id').apply(lambda x: np.clip(predict(model, x), 0., 1.)))\n",
    "        ndcg_score.append(nDCG_query(y_val_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions))\n",
    "    \n",
    "    return ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1, mean nDCG on cv = 0.7766081494867103\n",
      "max_depth = 2, mean nDCG on cv = 0.7870632479608026\n",
      "max_depth = 3, mean nDCG on cv = 0.784871556681154\n",
      "max_depth = 4, mean nDCG on cv = 0.7765367455361624\n",
      "max_depth = 5, mean nDCG on cv = 0.7698203441960811\n",
      "max_depth = 6, mean nDCG on cv = 0.7578711393202677\n",
      "max_depth = 7, mean nDCG on cv = 0.7468182137727795\n",
      "max_depth = 8, mean nDCG on cv = 0.7309169702117039\n",
      "max_depth = 9, mean nDCG on cv = 0.7259089057770216\n",
      "max_depth = 10, mean nDCG on cv = 0.7188063032484985\n"
     ]
    }
   ],
   "source": [
    "#Максимальная глубина\n",
    "max_depths = [1,2,3,4,5,6,7,8,9,10]\n",
    "for depth in max_depths:\n",
    "    model = cat.CatBoostRanker(\n",
    "                loss_function='YetiRank',\n",
    "                depth=depth\n",
    "            )\n",
    "    \n",
    "    print(\"max_depth = {}, mean nDCG on cv = {}\".format(depth, np.mean(cross_val_scores_cat(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.001, mean nDCG on cv = 0.7505595131221626\n",
      "lr = 0.01, mean nDCG on cv = 0.7752885545231284\n",
      "lr = 0.1, mean nDCG on cv = 0.7876547151056061\n",
      "lr = 1, mean nDCG on cv = 0.7693628323613971\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "#Скорость обучения\n",
    "lrs = [1e-3, 1e-2, 1e-1, 1]\n",
    "for lr in lrs:\n",
    "    model = cat.CatBoostRanker(\n",
    "                loss_function='YetiRank',\n",
    "                learning_rate=lr,\n",
    "                depth=2\n",
    "            )\n",
    "    \n",
    "    print(\"lr = {}, mean nDCG on cv = {}\".format(lr, np.mean(cross_val_scores_cat(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 1, mean nDCG on cv = 0.8108161822289202\n",
      "n_estimators = 2, mean nDCG on cv = 0.797531444301578\n",
      "n_estimators = 3, mean nDCG on cv = 0.7754764982880058\n",
      "n_estimators = 5, mean nDCG on cv = 0.7675406346888096\n",
      "n_estimators = 10, mean nDCG on cv = 0.7618506824539405\n",
      "n_estimators = 25, mean nDCG on cv = 0.7609130029414737\n",
      "n_estimators = 50, mean nDCG on cv = 0.7724389032749455\n",
      "n_estimators = 75, mean nDCG on cv = 0.7732299844771097\n",
      "n_estimators = 100, mean nDCG on cv = 0.7786225470175856\n"
     ]
    }
   ],
   "source": [
    "#Число деревьев\n",
    "n_estimators = [1, 2, 3, 5, 10, 25, 50, 75, 100]\n",
    "for n in n_estimators:\n",
    "    model = cat.CatBoostRanker(\n",
    "                loss_function='YetiRank',\n",
    "                n_estimators=n,\n",
    "                learning_rate=0.1,\n",
    "                depth=2\n",
    "            )\n",
    "    \n",
    "    print(\"n_estimators = {}, mean nDCG on cv = {}\".format(n, np.mean(cross_val_scores_cat(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.001, mean nDCG on cv = 0.8108161822289202\n",
      "lambda = 0.01, mean nDCG on cv = 0.8108161822289202\n",
      "lambda = 0.1, mean nDCG on cv = 0.8108161822289202\n",
      "lambda = 1, mean nDCG on cv = 0.8108161822289202\n"
     ]
    }
   ],
   "source": [
    "#Регуляризация\n",
    "reg_lambda = [1e-3, 1e-2, 1e-1, 1]\n",
    "for lamb in reg_lambda:\n",
    "    model = cat.CatBoostRanker(\n",
    "                loss_function='YetiRank',\n",
    "                n_estimators=1,\n",
    "                learning_rate=0.1,\n",
    "                depth=2,\n",
    "                reg_lambda=lamb\n",
    "            )\n",
    "        \n",
    "    print(\"lambda = {}, mean nDCG on cv = {}\".format(lamb, np.mean(cross_val_scores_cat(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG score for CatBoost with YetiRank: 0.8012822139582864\n"
     ]
    }
   ],
   "source": [
    "cat_yetirank = cat.CatBoostRanker(\n",
    "                    loss_function='YetiRank',\n",
    "                    n_estimators=1,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=2\n",
    "                )\n",
    "\n",
    "train = cat.Pool(\n",
    "            data=X_train.loc[:, ~X_train.columns.isin(['query_id'])],\n",
    "            label=y_train.relevance,\n",
    "            group_id=X_train['query_id']\n",
    "        )\n",
    "        \n",
    "cat_yetirank.fit(train, silent=True)\n",
    "\n",
    "predictions = (X_test.groupby('query_id').apply(lambda x: np.clip(predict(cat_yetirank, x), 0., 1.)))\n",
    "cat_yetirank_ndcg = nDCG_query(y_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions)\n",
    "print('nDCG score for CatBoost with YetiRank:', cat_yetirank_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nDCG на контроле 👇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB with linear: 0.9113383867102114\n",
      "XGB with pairwise: 0.831457281077564\n",
      "XGB with map: 0.8562445567109971\n",
      "XGB with ndcg: 0.9113383867102114\n"
     ]
    }
   ],
   "source": [
    "print(\"XGB with linear:\", xgb_linear_ndcg)\n",
    "print(\"XGB with pairwise:\", xgb_pairwise_ndcg)\n",
    "print(\"XGB with map:\", xgb_map_ndcg)\n",
    "print(\"XGB with ndcg:\", xgb_ndcg_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost with YetiRank: 0.8012822139582864\n"
     ]
    }
   ],
   "source": [
    "print('CatBoost with YetiRank:', cat_yetirank_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопросы:**\n",
    "  - какая модель работает лучше всего для данной задачи? \n",
    "  - в чем достоинства/недостатки каждой? \n",
    "  - сравните модели между собой: \n",
    "   - получается ли сравнимое качество линейного pointwise подхода с остальными моделями? \n",
    "   - заметна ли разница в качестве при использовании бустинга с разными функциями потерь?\n",
    "  - Для оценивания качества моделей используйте метрику nDCG на контроле.\n",
    "  \n",
    "**Выводы:**  \n",
    "- Для данной задачи лучше всего подошел XGBoost c reg:linear и rank:ndcg функциями потерь. Для каждой функции потерь были подобраны гиперпараметры (n_estimators, learning_rate, max_depth, reg_alpha). Также я пыталась подобрать гиперпараметр reg_lambda, но это не помогло улучшить скор моделей :( Качество каждой полученной модели на контрольной выборке выписано выше ☝️  \n",
    "- По полученным nDCG можно сделать вывод, что pointwise подход для данной задачи позволяет получить наилучшее качество нашей ранжирующей системы  \n",
    "- Разница при использовании различных функций потерь очевидна невооруженным взглядом: nDCG изменяется от 0.801 до 0.911  \n",
    "\n",
    "**XGB with linear**\n",
    "- Достоинства: получилась модель с хорошим скором, довольно быстро посчиталось\n",
    "- Недостатки: в pointwise подходе строится регрессия: для каждой отдельной пары запрос-документ необходимо предсказать её оценку. Почему это минус? Потому что мы не сравниваем релевантность документов относительно друг друга для запроса\n",
    "\n",
    "**XGB with pairwise**\n",
    "- Достоинства: довольно быстро обучилась моделька, функция потерь штрафует за то, что пара объектов неправильно упорядочена (плюс относительно первой модели с reg:linear)\n",
    "- Недостатки: Получилось не самое лучшее качество :(\n",
    "\n",
    "**XGB with map**\n",
    "- Достоинства: listwise подход позволяет построить модель, на вход которой поступают сразу все документы, соответствующие запросу, а на выходе получается их перестановка\n",
    "- Недостатки: подбор числа деревьев и реугляризации не позволил изменить nDCG\n",
    "\n",
    "**XGB with ndcg**\n",
    "- Достоинства: также позволяет на выходе получить перестановку документов для данного запроса\n",
    "- Недостатки: подбор гиперпараметров не позволил изменить nDCG\n",
    "\n",
    "**CatBoost with YetiRank**\n",
    "- Достоинства: в 3 задании я добавила категориальные признаки (катбуст может работать с ними из коробки), это позволило повысить nDCG\n",
    "- Недостатки: обучался дольше XGBoost, подбор параметров регуляризации не позволил изменить nDCG. Также я пыталась обучить катбуст с YetiRankPairwise, но модель обучалась оооочень долго и я не включила это в отчет\n",
    "\n",
    "\n",
    "\n",
    "rank:map, rank:ndcg — реализация LambdaRank для двух метрик: MAP и nDCG. Известно, что для того, чтобы оптимизировать негладкий функционал, такой как nDCG, нужно домножить градиент функционала  𝑂𝑏𝑗(𝑎)  на значение  Δ𝑁𝐷𝐶𝐺𝑖𝑗  — изменение значения функционала качества при замене  𝑥𝑖  на  𝑥𝑗 . Поскольку для вычисления метрик необходимы все объекты выборки, то эти две ранжирующие функции потерь являются представителями класса listwise моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**(1 балл) Задание 3.** Одним из основных преимуществ CatBoost'a является обработка категориальных факторов «из коробки». Добавьте в датасет различные категориальные факторы из данных и обучите заново CatBoost модели. Улучшилось ли качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language(x):\n",
    "    try:\n",
    "        language = langdetect.detect(x)\n",
    "    except:\n",
    "        language = \"unknown\"\n",
    "    return language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_langs = np.unique(train_data['query'].apply(lambda x: get_language(x)))\n",
    "org_name_langs = np.unique(train_data['org_name'].apply(lambda x: get_language(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['af', 'bg', 'ca', 'cs', 'cy', 'da', 'de', 'en', 'es', 'et', 'fi',\n",
       "       'fr', 'hr', 'hu', 'id', 'it', 'lt', 'lv', 'mk', 'nl', 'no', 'pl',\n",
       "       'pt', 'ro', 'ru', 'sk', 'sl', 'so', 'sv', 'sw', 'tl', 'tr', 'uk',\n",
       "       'vi', 'af', 'bg', 'ca', 'cs', 'cy', 'da', 'de', 'en', 'es', 'et',\n",
       "       'fi', 'fr', 'hr', 'hu', 'id', 'it', 'lt', 'lv', 'mk', 'nl', 'no',\n",
       "       'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'so', 'sq', 'sv', 'sw', 'tl',\n",
       "       'tr', 'uk', 'unknown', 'vi'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = np.concatenate((query_langs, org_name_langs))\n",
    "langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "qlang2id = {lang: idx for idx, lang in enumerate(np.unique(langs))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['query_id'] = train_data['query_id']\n",
    "df['query_words_count'] = train_data['query'].apply(lambda query: len(getWordsFromString(query)))\n",
    "df['org_name_words_count'] = train_data['org_name'].apply(lambda name: len(getWordsFromString(name)))\n",
    "df['intersection_words_count'] = train_data[['query', 'org_name']].apply(getIntersectionWordsCount, axis=1)\n",
    "df['jaccard_score'] = df['intersection_words_count'] / (df['query_words_count'] + df['org_name_words_count'] - df['intersection_words_count'])\n",
    "df['synonymous_names_count'] = train_data['org_id'].apply(getSynonymousNamesCount)\n",
    "\n",
    "df['rubrics_count'] = train_data['org_id'].apply(getRubricsCount)\n",
    "df['worktime'] = train_data['org_id'].apply(getWorkTime)\n",
    "df['workdays_count'] = train_data['org_id'].apply(getDaysCount)\n",
    "\n",
    "df['query_lang'] = train_data['query'].apply(lambda x: qlang2id[get_language(x)]) #categorical\n",
    "df['org_name_lang'] = train_data['org_name'].apply(lambda x: qlang2id[get_language(x)]) #categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lang_match'] = train_data[['query', 'org_name']].apply(lambda x: int(x[0] == x[1]), axis=1) #1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_org_geo_id(org_id) -> str:\n",
    "    node = train_org_json.get(str(org_id))\n",
    "    if node is not None:\n",
    "        return str(node['address']['geo_id'])\n",
    "    return 0\n",
    "\n",
    "df['org_id_match'] = train_data[['org_id', 'region']].apply(lambda x: int(str(get_org_geo_id(x[0])) == str(x[1])), axis=1) #1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist1(x1, x2) -> float:\n",
    "    return abs(x1[0] - x2[0]) + abs(x1[1] - x2[1])\n",
    "\n",
    "def dist2(x1, x2) -> float:\n",
    "    return np.sqrt((x1[0] - x2[0]) ** 2 + (x1[1] - x2[1]) ** 2)\n",
    "\n",
    "def get_org_geo_coord(org_id):\n",
    "    node = train_org_json.get(str(org_id))\n",
    "    if node is not None:\n",
    "        return node['address']['pos']['coordinates']\n",
    "    return [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dist1'] = train_data[['window_center', 'org_id']].apply(lambda x: dist1(get_org_geo_coord(x[1]), list(map(float, x[0].split(',')))), axis=1)\n",
    "df['dist2'] = train_data[['window_center', 'org_id']].apply(lambda x: dist2(get_org_geo_coord(x[1]), list(map(float, x[0].split(',')))), axis=1) #1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_words_count</th>\n",
       "      <th>org_name_words_count</th>\n",
       "      <th>intersection_words_count</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>synonymous_names_count</th>\n",
       "      <th>rubrics_count</th>\n",
       "      <th>worktime</th>\n",
       "      <th>workdays_count</th>\n",
       "      <th>query_lang</th>\n",
       "      <th>org_name_lang</th>\n",
       "      <th>lang_match</th>\n",
       "      <th>org_id_match</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490343</td>\n",
       "      <td>0.443272</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469583</td>\n",
       "      <td>0.399923</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>480.0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476728</td>\n",
       "      <td>0.435877</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432932</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490446</td>\n",
       "      <td>0.443338</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  query_words_count  org_name_words_count  \\\n",
       "0        11                  7                     7   \n",
       "1        11                  7                     7   \n",
       "2        11                  7                     4   \n",
       "3        11                  7                     4   \n",
       "4        11                  7                     2   \n",
       "\n",
       "   intersection_words_count  jaccard_score  synonymous_names_count  \\\n",
       "0                         1       0.076923                       5   \n",
       "1                         1       0.076923                       5   \n",
       "2                         1       0.100000                       7   \n",
       "3                         1       0.100000                       7   \n",
       "4                         1       0.125000                       3   \n",
       "\n",
       "   rubrics_count  worktime  workdays_count  query_lang  org_name_lang  \\\n",
       "0              1     240.0               1          24             33   \n",
       "1              1     540.0               5          24             33   \n",
       "2              1     480.0               5          24             33   \n",
       "3              1     240.0               1          24             33   \n",
       "4              1     540.0               5          24             24   \n",
       "\n",
       "   lang_match  org_id_match     dist1     dist2  relevance  \n",
       "0           0             0  0.490343  0.443272        0.0  \n",
       "1           0             0  0.469583  0.399923        0.0  \n",
       "2           0             0  0.476728  0.435877        0.0  \n",
       "3           0             0  0.432932  0.397661        0.0  \n",
       "4           0             0  0.490446  0.443338        0.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['relevance'] = train_data['relevance']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['query_lang', 'org_name_lang', 'lang_match', 'org_id_match']\n",
    "\n",
    "df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = df.iloc[X_train_inds]\n",
    "X_train = new_train_data.loc[:, ~new_train_data.columns.isin(['relevance'])]\n",
    "y_train = new_train_data.loc[:, new_train_data.columns.isin(['query_id', 'relevance'])]\n",
    "\n",
    "new_test_data = df.iloc[X_test_inds]\n",
    "\n",
    "X_test = new_test_data.loc[:, ~new_test_data.columns.isin(['relevance'])]\n",
    "y_test = new_test_data.loc[:, new_test_data.columns.isin(['query_id', 'relevance'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_words_count</th>\n",
       "      <th>org_name_words_count</th>\n",
       "      <th>intersection_words_count</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>synonymous_names_count</th>\n",
       "      <th>rubrics_count</th>\n",
       "      <th>worktime</th>\n",
       "      <th>workdays_count</th>\n",
       "      <th>query_lang</th>\n",
       "      <th>org_name_lang</th>\n",
       "      <th>lang_match</th>\n",
       "      <th>org_id_match</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490343</td>\n",
       "      <td>0.443272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469583</td>\n",
       "      <td>0.399923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>480.0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476728</td>\n",
       "      <td>0.435877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432932</td>\n",
       "      <td>0.397661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490446</td>\n",
       "      <td>0.443338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  query_words_count  org_name_words_count  \\\n",
       "0        11                  7                     7   \n",
       "1        11                  7                     7   \n",
       "2        11                  7                     4   \n",
       "3        11                  7                     4   \n",
       "4        11                  7                     2   \n",
       "\n",
       "   intersection_words_count  jaccard_score  synonymous_names_count  \\\n",
       "0                         1       0.076923                       5   \n",
       "1                         1       0.076923                       5   \n",
       "2                         1       0.100000                       7   \n",
       "3                         1       0.100000                       7   \n",
       "4                         1       0.125000                       3   \n",
       "\n",
       "   rubrics_count  worktime  workdays_count  query_lang  org_name_lang  \\\n",
       "0              1     240.0               1          24             33   \n",
       "1              1     540.0               5          24             33   \n",
       "2              1     480.0               5          24             33   \n",
       "3              1     240.0               1          24             33   \n",
       "4              1     540.0               5          24             24   \n",
       "\n",
       "   lang_match  org_id_match     dist1     dist2  \n",
       "0           0             0  0.490343  0.443272  \n",
       "1           0             0  0.469583  0.399923  \n",
       "2           0             0  0.476728  0.435877  \n",
       "3           0             0  0.432932  0.397661  \n",
       "4           0             0  0.490446  0.443338  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше я добавила категориальные признаки, теперь попробуем обучить катбуст на старых + новодобавленных признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1, mean nDCG on cv = 0.7870646088773717\n",
      "max_depth = 2, mean nDCG on cv = 0.790459199858747\n",
      "max_depth = 3, mean nDCG on cv = 0.7913356727218813\n",
      "max_depth = 4, mean nDCG on cv = 0.7883086670742416\n",
      "max_depth = 5, mean nDCG on cv = 0.7836831507673894\n",
      "max_depth = 6, mean nDCG on cv = 0.7779308865421689\n",
      "max_depth = 7, mean nDCG on cv = 0.7730753617898072\n",
      "max_depth = 8, mean nDCG on cv = 0.7697731767406019\n",
      "max_depth = 9, mean nDCG on cv = 0.7682415446781499\n",
      "max_depth = 10, mean nDCG on cv = 0.7638110560199193\n"
     ]
    }
   ],
   "source": [
    "#Максимальная глубина\n",
    "max_depths = [1,2,3,4,5,6,7,8,9,10]\n",
    "for depth in max_depths:\n",
    "    model = cat.CatBoostRanker(\n",
    "        loss_function='YetiRank',\n",
    "        depth=depth\n",
    "    )\n",
    "    \n",
    "    print(\"max_depth = {}, mean nDCG on cv = {}\".format(depth, np.mean(cross_val_scores_cat(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 1, mean nDCG on cv = 0.7866286448369745\n",
      "n_estimators = 2, mean nDCG on cv = 0.7656187760885793\n",
      "n_estimators = 3, mean nDCG on cv = 0.773063916342781\n",
      "n_estimators = 5, mean nDCG on cv = 0.7613294414586772\n",
      "n_estimators = 10, mean nDCG on cv = 0.7578869217727137\n",
      "n_estimators = 25, mean nDCG on cv = 0.7541979460006166\n",
      "n_estimators = 50, mean nDCG on cv = 0.7577001355228449\n",
      "n_estimators = 75, mean nDCG on cv = 0.7659831059723373\n",
      "n_estimators = 100, mean nDCG on cv = 0.7716402705348906\n"
     ]
    }
   ],
   "source": [
    "#Число деревьев\n",
    "n_estimators = [1, 2, 3, 5, 10, 25, 50, 75, 100]\n",
    "for n in n_estimators:\n",
    "    model = cat.CatBoostRanker(\n",
    "        loss_function='YetiRank',\n",
    "        n_estimators=n,\n",
    "        depth=3\n",
    "    )\n",
    "    \n",
    "    print(\"n_estimators = {}, mean nDCG on cv = {}\".format(n, np.mean(cross_val_scores_cat(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.001, mean nDCG on cv = 0.8090345830021708\n",
      "lambda = 0.01, mean nDCG on cv = 0.8090345830021708\n",
      "lambda = 0.1, mean nDCG on cv = 0.8090345830021708\n",
      "lambda = 1, mean nDCG on cv = 0.8090345830021708\n"
     ]
    }
   ],
   "source": [
    "#Регуляризация\n",
    "reg_lambda = [1e-3, 1e-2, 1e-1, 1]\n",
    "for lamb in reg_lambda:\n",
    "    model = cat.CatBoostRanker(\n",
    "        loss_function='YetiRank',\n",
    "        n_estimators=1,\n",
    "        depth=2,\n",
    "        reg_lambda=lamb\n",
    "    )\n",
    "        \n",
    "    print(\"lambda = {}, mean nDCG on cv = {}\".format(lamb, np.mean(cross_val_scores_cat(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1, n_estimators = 1, mean nDCG on cv = 0.8359569802215141\n",
      "max_depth = 1, n_estimators = 2, mean nDCG on cv = 0.8289812056174763\n",
      "max_depth = 1, n_estimators = 3, mean nDCG on cv = 0.8147529098037755\n",
      "max_depth = 1, n_estimators = 5, mean nDCG on cv = 0.8069605294541523\n",
      "max_depth = 1, n_estimators = 10, mean nDCG on cv = 0.7991514774378332\n",
      "max_depth = 1, n_estimators = 25, mean nDCG on cv = 0.7919795622042478\n",
      "max_depth = 1, n_estimators = 50, mean nDCG on cv = 0.7752708864378409\n",
      "max_depth = 1, n_estimators = 75, mean nDCG on cv = 0.7683336527584208\n",
      "max_depth = 1, n_estimators = 100, mean nDCG on cv = 0.7665664139192264\n",
      "max_depth = 2, n_estimators = 1, mean nDCG on cv = 0.8090345830021708\n",
      "max_depth = 2, n_estimators = 2, mean nDCG on cv = 0.8044876196909293\n",
      "max_depth = 2, n_estimators = 3, mean nDCG on cv = 0.7933973796415991\n",
      "max_depth = 2, n_estimators = 5, mean nDCG on cv = 0.7938736845689196\n",
      "max_depth = 2, n_estimators = 10, mean nDCG on cv = 0.7784434480176519\n",
      "max_depth = 2, n_estimators = 25, mean nDCG on cv = 0.7572576765993431\n",
      "max_depth = 2, n_estimators = 50, mean nDCG on cv = 0.753305283621019\n",
      "max_depth = 2, n_estimators = 75, mean nDCG on cv = 0.7620200553460886\n",
      "max_depth = 2, n_estimators = 100, mean nDCG on cv = 0.7669002664117464\n",
      "max_depth = 3, n_estimators = 1, mean nDCG on cv = 0.7871289314237492\n",
      "max_depth = 3, n_estimators = 2, mean nDCG on cv = 0.7649615042672556\n",
      "max_depth = 3, n_estimators = 3, mean nDCG on cv = 0.7671899537158582\n",
      "max_depth = 3, n_estimators = 5, mean nDCG on cv = 0.7603783945519919\n",
      "max_depth = 3, n_estimators = 10, mean nDCG on cv = 0.7590464975967655\n",
      "max_depth = 3, n_estimators = 25, mean nDCG on cv = 0.754186715955699\n",
      "max_depth = 3, n_estimators = 50, mean nDCG on cv = 0.7574500589887447\n",
      "max_depth = 3, n_estimators = 75, mean nDCG on cv = 0.7636487483664994\n",
      "max_depth = 3, n_estimators = 100, mean nDCG on cv = 0.7702893318764777\n",
      "max_depth = 4, n_estimators = 1, mean nDCG on cv = 0.7720890235920945\n",
      "max_depth = 4, n_estimators = 2, mean nDCG on cv = 0.7571750244849451\n",
      "max_depth = 4, n_estimators = 3, mean nDCG on cv = 0.7600232697933658\n",
      "max_depth = 4, n_estimators = 5, mean nDCG on cv = 0.754334328133565\n",
      "max_depth = 4, n_estimators = 10, mean nDCG on cv = 0.7521540769149885\n",
      "max_depth = 4, n_estimators = 25, mean nDCG on cv = 0.7550639466452771\n",
      "max_depth = 4, n_estimators = 50, mean nDCG on cv = 0.7623619151392015\n",
      "max_depth = 4, n_estimators = 75, mean nDCG on cv = 0.7677203475851984\n",
      "max_depth = 4, n_estimators = 100, mean nDCG on cv = 0.7714195636489727\n",
      "max_depth = 5, n_estimators = 1, mean nDCG on cv = 0.7649225982436562\n",
      "max_depth = 5, n_estimators = 2, mean nDCG on cv = 0.7611205586125365\n",
      "max_depth = 5, n_estimators = 3, mean nDCG on cv = 0.7628908036246265\n",
      "max_depth = 5, n_estimators = 5, mean nDCG on cv = 0.7578242022754769\n",
      "max_depth = 5, n_estimators = 10, mean nDCG on cv = 0.7497694722126081\n",
      "max_depth = 5, n_estimators = 25, mean nDCG on cv = 0.7564654914638168\n",
      "max_depth = 5, n_estimators = 50, mean nDCG on cv = 0.7589649437718238\n",
      "max_depth = 5, n_estimators = 75, mean nDCG on cv = 0.7664661774068066\n",
      "max_depth = 5, n_estimators = 100, mean nDCG on cv = 0.7701342068763125\n",
      "max_depth = 6, n_estimators = 1, mean nDCG on cv = 0.762610606627735\n",
      "max_depth = 6, n_estimators = 2, mean nDCG on cv = 0.7554962533108185\n",
      "max_depth = 6, n_estimators = 3, mean nDCG on cv = 0.7542491059374784\n",
      "max_depth = 6, n_estimators = 5, mean nDCG on cv = 0.7515812967492701\n",
      "max_depth = 6, n_estimators = 10, mean nDCG on cv = 0.7476605758106181\n",
      "max_depth = 6, n_estimators = 25, mean nDCG on cv = 0.7504933830475916\n",
      "max_depth = 6, n_estimators = 50, mean nDCG on cv = 0.7556230751717086\n",
      "max_depth = 6, n_estimators = 75, mean nDCG on cv = 0.7620003430426665\n",
      "max_depth = 6, n_estimators = 100, mean nDCG on cv = 0.7681609772054749\n",
      "max_depth = 7, n_estimators = 1, mean nDCG on cv = 0.7599611809286925\n",
      "max_depth = 7, n_estimators = 2, mean nDCG on cv = 0.760294106824851\n",
      "max_depth = 7, n_estimators = 3, mean nDCG on cv = 0.7536093814638801\n",
      "max_depth = 7, n_estimators = 5, mean nDCG on cv = 0.7451870177136537\n",
      "max_depth = 7, n_estimators = 10, mean nDCG on cv = 0.7451130963931101\n",
      "max_depth = 7, n_estimators = 25, mean nDCG on cv = 0.7473924719069569\n",
      "max_depth = 7, n_estimators = 50, mean nDCG on cv = 0.7548176052842035\n",
      "max_depth = 7, n_estimators = 75, mean nDCG on cv = 0.7611040814817865\n",
      "max_depth = 7, n_estimators = 100, mean nDCG on cv = 0.7673396689628923\n",
      "max_depth = 8, n_estimators = 1, mean nDCG on cv = 0.7585557480524899\n",
      "max_depth = 8, n_estimators = 2, mean nDCG on cv = 0.74194910237624\n",
      "max_depth = 8, n_estimators = 3, mean nDCG on cv = 0.742817609434503\n",
      "max_depth = 8, n_estimators = 5, mean nDCG on cv = 0.7473887023246126\n",
      "max_depth = 8, n_estimators = 10, mean nDCG on cv = 0.7426050749913327\n",
      "max_depth = 8, n_estimators = 25, mean nDCG on cv = 0.7436619113638125\n",
      "max_depth = 8, n_estimators = 50, mean nDCG on cv = 0.7468846080616729\n",
      "max_depth = 8, n_estimators = 75, mean nDCG on cv = 0.7552456562746757\n",
      "max_depth = 8, n_estimators = 100, mean nDCG on cv = 0.7599708388766445\n",
      "max_depth = 9, n_estimators = 1, mean nDCG on cv = 0.7390797376564803\n",
      "max_depth = 9, n_estimators = 2, mean nDCG on cv = 0.7367748164241241\n",
      "max_depth = 9, n_estimators = 3, mean nDCG on cv = 0.7379215950257229\n",
      "max_depth = 9, n_estimators = 5, mean nDCG on cv = 0.7364057668557032\n",
      "max_depth = 9, n_estimators = 10, mean nDCG on cv = 0.7367479888024666\n",
      "max_depth = 9, n_estimators = 25, mean nDCG on cv = 0.7416217762594015\n",
      "max_depth = 9, n_estimators = 50, mean nDCG on cv = 0.7461359241298824\n",
      "max_depth = 9, n_estimators = 75, mean nDCG on cv = 0.7477994115590332\n",
      "max_depth = 9, n_estimators = 100, mean nDCG on cv = 0.7544505699202201\n",
      "max_depth = 10, n_estimators = 1, mean nDCG on cv = 0.7234982127560856\n",
      "max_depth = 10, n_estimators = 2, mean nDCG on cv = 0.7252450881287822\n",
      "max_depth = 10, n_estimators = 3, mean nDCG on cv = 0.7220714478164085\n",
      "max_depth = 10, n_estimators = 5, mean nDCG on cv = 0.7310341031667112\n",
      "max_depth = 10, n_estimators = 10, mean nDCG on cv = 0.7301275337671854\n",
      "max_depth = 10, n_estimators = 25, mean nDCG on cv = 0.735205777506782\n",
      "max_depth = 10, n_estimators = 50, mean nDCG on cv = 0.7386853364466514\n",
      "max_depth = 10, n_estimators = 75, mean nDCG on cv = 0.7450688094906565\n",
      "max_depth = 10, n_estimators = 100, mean nDCG on cv = 0.7479765588442048\n"
     ]
    }
   ],
   "source": [
    "#Максимальная глубина\n",
    "max_depths = [1,2,3,4,5,6,7,8,9,10]\n",
    "#Число деревьев\n",
    "n_estimators = [1, 2, 3, 5, 10, 25, 50, 75, 100]\n",
    "\n",
    "for depth in max_depths:\n",
    "    for n in n_estimators:\n",
    "        model = cat.CatBoostRanker(\n",
    "                    loss_function='YetiRank',\n",
    "                    n_estimators=n,\n",
    "                    depth=depth,\n",
    "                    reg_lambda=0.1\n",
    "                )\n",
    "    \n",
    "        print(\"max_depth = {}, n_estimators = {}, mean nDCG on cv = {}\".format(depth, n, np.mean(cross_val_scores_cat(model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG score for CatBoost with YetiRank with categorical features: 0.8338838386543777\n"
     ]
    }
   ],
   "source": [
    "cat_yetirank_with_categorical = cat.CatBoostRanker(\n",
    "        loss_function='YetiRank',\n",
    "        n_estimators=1,\n",
    "        depth=1,\n",
    "        reg_lambda=0.1\n",
    "    )\n",
    "\n",
    "train = cat.Pool(\n",
    "            data=X_train.loc[:, ~X_train.columns.isin(['query_id'])],\n",
    "            label=y_train.relevance,\n",
    "            group_id=X_train['query_id']\n",
    "        )\n",
    "        \n",
    "cat_yetirank_with_categorical.fit(train, silent=True)\n",
    "\n",
    "predictions = (X_test.groupby('query_id').apply(lambda x: np.clip(predict(cat_yetirank_with_categorical, x), 0., 1.)))\n",
    "cat_yetirank_ndcg = nDCG_query(y_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions)\n",
    "\n",
    "print('nDCG score for CatBoost with YetiRank with categorical features:', cat_yetirank_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление категориальных фичей в катбуст позволило повысить nDCG с 0.8013 до 0.834. Возможно, стоит добавить ещё категориальных фичей или погенерить другие, чтобы увеличить nDCG ещё."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пользовательская функция потерь\n",
    "\n",
    "Библиотека XGBoost позволяет использовать пользовательские функции потерь. Для этого необходимо реализовать функцию, принимающую на вход вектор предсказанных значений и обучающую выборку, и возвращающую градиент и гессиан, посчитанный по входным данным.\n",
    "\n",
    "Важно отметить, что XGBoost использует диагональную аппроксимацию гессиана, таким образом все недиагональные элементы считаются малозначимыми и приравниваются нулю, поэтому и градиент, и гессиан являются векторами длины размера обучающей выборки.\n",
    "\n",
    "**(1 балла) Задание 4.** Реализуйте экспоненциальную функцию потерь для XGBoost:\n",
    "$$ Obj = \\sum_{i \\prec j} \\mathcal{L}\\left(a(x_j) - a(x_i)\\right) \\rightarrow min $$ $$ \\mathcal{L}(M) = e^{-M} $$\n",
    "\n",
    "Обучите модель с помощью данной функции потерь, настройте параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарии к реализации**\n",
    "\n",
    "В случае ранжирования XGBoost'у необходимо знать о разбиении всех объектов на группы. В нашем случае в одну группу будут входить документы, соответствующие одному запросу. Функция, считающая градиент и гессиан по данным, должна знать данное разбиение датасета. Однако питоновский интерфейс класса *DMatrix* (в котором хранится датасет) не дает возможности получить это разбиение. В этом случае нужно реализовать функцию потерь в качестве функтора, конструктор которого принимает разбиение на группы в качестве параметра.\n",
    "\n",
    "Пример реализации своей функции потерь можно найти [в официальной справке](https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html#customized-objective-function) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialPairwiseLoss(object):\n",
    "    def __init__(self, groups):\n",
    "        self.groups = groups\n",
    "                        \n",
    "    def __call__(self, pred, dtrain):\n",
    "        start_group_idx = np.concatenate(([0], np.cumsum(self.groups)))\n",
    "        grad = np.zeros_like(pred)\n",
    "        hess = np.zeros_like(pred)\n",
    "        \n",
    "        for gr_idx, group in enumerate(self.groups):\n",
    "            for i in range(start_group_idx[gr_idx], start_group_idx[gr_idx + 1]):\n",
    "                for j in range(i + 1, start_group_idx[gr_idx + 1]):\n",
    "                    value = 0\n",
    "                    if dtrain[i] < dtrain[j]:\n",
    "                        value = np.exp(pred[i] - pred[j])\n",
    "                        grad[i] += value\n",
    "                        grad[j] -= value\n",
    "                    elif dtrain[i] > dtrain[j]:\n",
    "                        value = np.exp(pred[j] - pred[i])\n",
    "                        grad[j] += value\n",
    "                        grad[i] -= value\n",
    "                    hess[i] += value\n",
    "                    hess[j] += value\n",
    "\n",
    "        return grad, hess  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG score for XGBoost with reg:linear: 0.7103656969905512\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(objective='reg:linear', verbosity=0)\n",
    "\n",
    "model.fit(X_train.loc[:, ~X_train.columns.isin(['query_id'])], y_train.relevance)\n",
    "\n",
    "predictions = (X_test.groupby('query_id').apply(lambda x: predict(model, x)))\n",
    "xgb_ndcg = nDCG_query(y_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions)\n",
    "print('nDCG score for XGBoost with reg:linear:', xgb_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG score for XGBoost with ExponentialPairwiseLoss: 0.9113383867102114\n"
     ]
    }
   ],
   "source": [
    "groups = X_train.groupby('query_id').size().to_frame('size')['size'].to_numpy()\n",
    "\n",
    "model = xgb.XGBRegressor(objective=ExponentialPairwiseLoss(groups))\n",
    "\n",
    "model.fit(X_train.loc[:, ~X_train.columns.isin(['query_id'])], y_train.relevance, verbose=0)\n",
    "\n",
    "predictions = (X_test.groupby('query_id').apply(lambda x: predict(model, x)))\n",
    "xgb_ndcg = nDCG_query(y_test.groupby('query_id').apply(lambda x: list(x.relevance)), predictions)\n",
    "print('nDCG score for XGBoost with ExponentialPairwiseLoss:', xgb_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExponentialPairwiseLoss увеличивает nDCG по сравнению с reg:linear"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекуррентные языковые модели (4 балла)\n",
    "\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSj85jp-W-V-Bz8ZBjFJYIkV1TTxQxTMh4iqls_rRt8O-sraL08PA)\n",
    "\n",
    "В этой части домашней работы мы создадим языковую модель на рекуррентных нейросетях (RNN) и заставим её придумывать имена.\n",
    "\n",
    "__Языковая модель__, если вкратце, это модель, которая умеет как предсказывать вероятность некоторого текста, так и генерировать текст в соответствии с предсказанными вероятностями. Задание будет заключаться в том, чтобы суметь скормить модели 8к имён, после чего она могла бы генерировать новые.\n",
    "\n",
    "В данном случае в качестве входных данных мы будет работать со строками, которые можно рассматривать как последовательности _символов_: $\\{x_0, x_1, x_2, ..., x_n\\}$. \n",
    "\n",
    "Наша основная задача — научиться предсказывать вероятность следующего символа:\n",
    "$$ p(x_0, x_1, x_2, ..., x_n) = \\prod_t p(x_t | x_0, ... x_{t - 1}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные\n",
    "\n",
    "Мы будем строить языковую модель по ~8k человеческих имён на латинице. Если когда-нибудь вам нужно будет дать имя своему ребёнку, у вас будет для этого генеративная нейросетевая модель.\n",
    "\n",
    "А теперь загрузите данные и постройте диаграмму распределения длины имен. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "start_token = \" \"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    lines = f.read()[:-1].split('\\n')\n",
    "    lines = [start_token + name for name in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples =  7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print ('n samples = ',len(lines))\n",
    "for x in lines[::1000]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, lines))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, lines)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Словари\n",
    "\n",
    "В начале нам будет необходимо построить \"словарь\" — упорядоченное множество уникальных символов, которые сеть может породить. Это нужно, чтобы уметь сопоставить каждому символу свой номер. Перед отправкой в сеть все символы будут кодироваться их номерами в словаре.\n",
    "\n",
    "Также необходимо добавить в словарь пробельный символ, который будет использоваться в качестве специального токена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  55\n"
     ]
    }
   ],
   "source": [
    "# соберите все уникальные символы из lines\n",
    "tokens = tokens = {l for line in lines for l in line}\n",
    "tokens.add(' ')\n",
    "\n",
    "tokens = sorted(list(tokens))\n",
    "\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens = ',n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь построим обратный словарь: для каждой буквы посчитаем её номер в списке токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь {символ -> его индекс в tokens}\n",
    "\n",
    "token_to_id = {symbol: idx for idx, symbol in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кажется заработало...\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"число токенов должно совпадать\"\n",
    "\n",
    "for i in range(n_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"словарь должен указывать на индекс буквы в tokens\"\n",
    "\n",
    "print(\"Кажется заработало...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имея построенное соответствие, можно преобразовать батч входных данных в матрицу int32 номеров токенов. Так как в батче все строки должны быть одной длины, слишком короткие строки в батче нужно будет дополнить пробелами (паддинг)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(lines, max_len=None, pad=token_to_id[' '], dtype='int32'):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    max_len = max_len or max(map(len, lines))\n",
    "    lines_ix = np.zeros([len(lines), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.get, lines[i]))\n",
    "        lines_ix[i, :len(line_ix)] = line_ix\n",
    "\n",
    "    return lines_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[ 0  3 30 29 35 29 33 40  0]\n",
      " [ 0  9 40 43 46 53  0  0  0]\n",
      " [ 0 18 46 37 47 47 37 33  0]\n",
      " [ 0  9 37 43 50 29 42 42 33]]\n"
     ]
    }
   ],
   "source": [
    "# example: cast 4 random names to matrices, pad with zeros\n",
    "print('\\n'.join(lines[::2000]))\n",
    "print(to_matrix(lines[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Один RNN\n",
    "\n",
    "Рекуррентная нейронная сеть (RNN) — это такая сеть с <s>блокнотом</s>состоянием $h$, в который она умеет писать то, что видела.\n",
    "\n",
    "Сеть начинает с пустого $h_0 = \\vec 0$, после чего текст обрабатывается по одному символу:\n",
    "* $x_t$ — очередной символ, $h_t$ — предыдущее состояние\n",
    "* $h_{t+1} = \\text{get_h_next}(h_t, x_t)$ — новое состояние\n",
    "* $p(x_{t+1} | h_{t+1}) = \\text{get_probs}(h_{t+1})$ — вероятность следующего символа\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/8l4qFF0.png\" width=480>\n",
    "\n",
    "Поскольку $x_t$ это индекс символа в словаре (=натуральное число), то ему можно сопоставить некоторый обучаемый вектор (*embedding*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as L\n",
    "print('TF version:', tf.__version__)\n",
    "\n",
    "\n",
    "class CharRNN(keras.models.Model):\n",
    "    \n",
    "    def __init__(self, emb_size=16, hid_size=64):\n",
    "        self.emb_size, self.hid_size = emb_size, hid_size\n",
    "        super().__init__()\n",
    "        \n",
    "        # слой, который сопоставляет каждому из n_tokens входов свой обучаемый вектор\n",
    "        self.emb = L.Embedding(n_tokens, emb_size)\n",
    "\n",
    "        # слой, вычисляющий следующее состояния [emb(x_t), h_t] -> h_{t+1}\n",
    "        self.rnn_update = L.Dense(hid_size, activation='tanh')\n",
    "\n",
    "        # слой, предсказывающий вероятности h_{t+1} -> P(x_{t+1}|h_{t+1})\n",
    "        self.rnn_to_probs = L.Dense(n_tokens, activation='softmax')\n",
    "        \n",
    "    def __call__(self, x_t, h_t):\n",
    "        \"\"\"\n",
    "        Perform rnn step, return next rnn state and probabilities for next token\n",
    "        :param h_t: previous rnn state, float32 [batch_size, rnn_size]\n",
    "        :param x_t: token indices for current step, int32 [batch_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ваша задача: реализовать 1 шаг рекуррентной сети\n",
    "        # замените номер символа на его вектор (embedding)\n",
    "        # сконкатенируйте вектор входа и предыдущее состояние\n",
    "        # вычислите следующее состояние сети\n",
    "        # предскажите вероятности для языковой модели P(x_next | h_next)        \n",
    "        \n",
    "        x_t_embedding = self.emb(x_t)\n",
    "        #print(h_t)\n",
    "        print(x_t_embedding)\n",
    "        x_and_h = np.concatenate([x_t_embedding, h_t], axis=1)\n",
    "        h_next = self.rnn_update(x_and_h)\n",
    "        output_probs = self.rnn_to_probs(h_next)\n",
    "        \n",
    "        return h_next, output_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharRNN()\n",
    "\n",
    "# test: rnn one step\n",
    "sequences = tf.convert_to_tensor(to_matrix(lines[:3]))\n",
    "h0 = tf.zeros([len(sequences), model.hid_size])\n",
    "\n",
    "h1, p_y1 = model(sequences[:, 0], h0)\n",
    "\n",
    "assert h1.shape == (len(sequences), model.hid_size)\n",
    "assert tf.reduce_all(tf.math.is_finite(h1))\n",
    "assert np.allclose(tf.reduce_sum(p_y1, axis=1), tf.ones(len(sequences)))\n",
    "assert tf.reduce_min(p_y1) >= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Много шагов RNN\n",
    "\n",
    "После того как был реализован один шаг нейросети, самое время сделать этих шагов побольше. Самый простой способ это сделать — написать цикл для фиксированного числа шагов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# начальное состояние (\"блокнот\") из нулей\n",
    "h_prev = tf.zeros([len(sequences), model.hid_size])\n",
    "predicted_probs = []\n",
    "\n",
    "for t in range(sequences.shape[1]):\n",
    "    x_t = sequences[:, t]\n",
    "        \n",
    "    # Задача: вычислите следующее состояние rnn и пре\n",
    "    # YOUR CODE: задайте h_next и probs_next\n",
    "    \n",
    "    h_next, probs_next = <...>\n",
    "    \n",
    "    # END OF YOUR CODE\n",
    "    \n",
    "    predicted_probs.append(probs_next)\n",
    "    h_prev = h_next\n",
    "    \n",
    "predicted_probs = tf.stack(predicted_probs, axis=1)\n",
    "\n",
    "print(\"Predicted probs (subset): \\n\", predicted_probs[:1, :2, :3])\n",
    "\n",
    "assert predicted_probs.shape == (sequences.shape[0], sequences.shape[1], n_tokens)\n",
    "assert h_prev.shape.as_list() == h0.shape.as_list()\n",
    "assert np.allclose(tf.reduce_sum(predicted_probs, -1), tf.ones_like(predicted_probs[:, :, 0]))\n",
    "assert not np.allclose(predicted_probs[:, 1, :] , predicted_probs[:, 2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение RNN\n",
    "\n",
    "Как и любую вероятностную модель, RNN можно обучить методом максимизации log-правдоподобия по всей выборке $D$:\n",
    "\n",
    "$$ \\theta = \\underset \\theta {argmax} \\log P(D) $$\n",
    "\n",
    "где\n",
    "$$ \\log P(D) = \\underset {\\vec x \\in D} \\sum \\log P(\\vec x) = \\underset {\\vec x \\in D} \\sum \\underset {x_t \\in \\vec x} \\sum \\log P(x_t | x_0, ..., x_{t+1})$$\n",
    "\n",
    "C тем же успехом мы можем __минимизировать__ кроссэнтропию — то же самое, но минусом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(sequences):\n",
    "    \"\"\" Примените нейросеть на батче данных и вычислите функцию потерь \"\"\"\n",
    "    \n",
    "    # 1. примените RNN в цикле по токенам в sequences\n",
    "    # Для этого достаточно скопировать ваш код из предыдущего задания\n",
    "    \n",
    "    <YOUR CODE>\n",
    "    \n",
    "    predicted_probs = <...>\n",
    "    \n",
    "    \n",
    "    # 2. вычислите функцию потерь - кроссэнтропию (минус средняя лог-вероятность правильного ответа)\n",
    "    # Правильный ответ для i-го примера на t-той позиции == буква на {t+1}-ой позиции того же примера\n",
    "    # hint: в самом конце тетрадки есть подсказка\n",
    "    \n",
    "    <YOUR CODE>\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert compute_loss(sequences).shape == (), \"loss must be scalar\"\n",
    "assert compute_loss(sequences) > 0, \"loss must be non-negative\"\n",
    "assert compute_loss(sequences) <= 10, \"loss must be a averaged over all tokens\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цикл обучения\n",
    "\n",
    "Здесь не будет ничего сложного: \n",
    "1. выбираем батч;\n",
    "2. делаем шаг обучения;\n",
    "3. что-нибудь печатаем на некоторых итерациях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "optimizer = keras.optimizers.Adam()\n",
    "model = CharRNN()\n",
    "\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2500):\n",
    "    # sample a mini-batch of sequences and evaluate loss\n",
    "    sequences = to_matrix(sample(lines, 32), max_len=MAX_LENGTH)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_i = compute_loss(sequences)\n",
    "    \n",
    "    # compute gradients for all model.trainable_variables\n",
    "    grads = <YOUR CODE>\n",
    "    \n",
    "    # update weights with optimizer\n",
    "    <YOUR CODE>\n",
    "    \n",
    "    \n",
    "    history.append(loss_i.numpy())\n",
    "    if (i+1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сэмплирование из RNN\n",
    "\n",
    "Только что у нас обучилась модель, которая предсказывает вероятности следующего символа. Осталось заставить её генерировать имена.\n",
    "\n",
    "\n",
    "Теперь давайте применим её к строке из одного пробела. Получим вероятности первой буквы имени. После чего сделаем в цикле:\n",
    "* $x_t \\sim P(x_t | h_t)$ — выберем букву пропорционально вероятностям.\n",
    "* $h_{t+1}, p(x_{t+1}|...) = \\text{model}(h_t, x_t)$ — присоединим букву к имени и прогоним через RNN\n",
    "\n",
    "Таким нехитрым образом вы можете генерировать имена, выбирая по одной букве на каждой итерации цикла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=' ', max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    h = tf.zeros([1, model.hid_size])\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for x_t in x_sequence[:-1]:\n",
    "        h, _ = model(tf.reshape(x_t, [1]), h)\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        h, x_probs = model(tf.reshape(x_sequence[-1], [1]), h)\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0].numpy()))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что теперь?\n",
    "\n",
    "Если вам наскучит решать повседневные задачи или вам нужны новые идеи, вы теперь всегда можете воспользоваться RNN чтобы сгенерировать что-то новое. Вот несколько задач, от которых можно отталкиваться:\n",
    "* названия статей по глубинному обучению;\n",
    "* названия карт Magic The Gathering;\n",
    "* [имена покемонов](https://github.com/cervoise/pentest-scripts/blob/master/password-cracking/wordlists/pokemon-list-en.txt);\n",
    "* clickbait заголовки;\n",
    "* молекулы в формате [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system);\n",
    "* ваша фантазия, с ограничениями которой вы уже должны были понять как бороться.\n",
    "\n",
    "Если возьмётесь за эту задачу, то вот несколько полезных советов:\n",
    "* Сейчас модель обучается на коротких строчках. Если у вас роман, его придётся порезать на кускочки.\n",
    "* Если длина строк сильно варьируется, можно поставить параметр MAX_LENGTH так, чтобы он покрывал 90%. Это обычно дает ускорение примерно в 2 раза.\n",
    "* Для более сложных задач требуется больше нейронов (rnn_size). Кроме того, можно эксперементировать и со составляющими сети (см. ниже).\n",
    "\n",
    "### Ещё почитать\n",
    "\n",
    "* [Подборка советов](https://danijar.com/tips-for-training-recurrent-neural-networks/) по обучению RNN. Чуть более полезная, чем обычно.\n",
    "* Отличный блог-пост от Andrej Karpathy про языковые модели на rnn, их применение и визуализацию — [Unreasonable Effectiveness of RNN](http://karpathy.github.io/2015/05/21/rnn-effectiveness/).\n",
    "* Большой список статей, постов, реализаций и прочих полезностей по RNN - [awesome rnn](https://github.com/kjw0612/awesome-rnn).\n",
    "* [Зоопарк](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) готовых рекуррентных ячеек (LSTM, GRU) в TF. И ещё одна реализация [в карасе](https://keras.io/layers/recurrent/).\n",
    "* Сейчас мы выбираем количество итераций динамически. Если вы хотите написать то же самое на tf 1.0, милости просим в [tf.while_loop](https://www.tensorflow.org/api_docs/python/tf/while_loop) или [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan).\n",
    "* А ещё рекуррентные сети можно аугментировать механизмом внимания или долговременной памятью. Вот тут есть [хорошая статья](https://distill.pub/2016/augmented-rnns/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spoilers!** подсказка для вычисления функции потерь\n",
    "\n",
    "Проще всего вычислить функцию потерь с использованием slices, например\n",
    "\n",
    "```xent_probs, xent_targets = predicted_probs[:, :-1], sequences[:, 1:]```\n",
    "\n",
    "Таким образом, в i-той строчке на j-том столбце в `xent_probs` содержатся предсказания, а в `targets` - соответствующие им же правильные \"следующие буквы\". Чтобы вычислить функцию потерь с этими переменными, можно воспользоваться `tf.one_hot` чтобы привести `targets` к размеру `xent_probs`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

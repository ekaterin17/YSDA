{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторно-конкурсная работа 2. Композиции алгоритмов. Ранжирование.\n",
    "\n",
    "Данная работа состоит из двух этапов: лабораторного и конкурсного. Для обоих используется один и тот же набор данных, который вы можете найти в описании первого конкурсного задания на kaggle.\n",
    "\n",
    "Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете так же должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n",
    "\n",
    "Наиболее предпочтительный подход к решению «лабоконкурса» - проделать предлагаемые лабораторные задания, а затем приступить к участию в конкурсном этапе. Это позволит вам перед участием в конкурсе познакомиться с представленными данными, освоить полезные приемы для улучшения качества, получить бейзлайн решение и глубже вникнуть в суть темы. \n",
    "\n",
    "Однако, мы не запрещаем вам выполнить только один из двух этапов: вы можете проделать лабораторные исследования и не участвовать в конкурсе или же пропустить лабораторную часть и сразу заняться соревновательной.\n",
    "\n",
    "Мы не предоставляем код бейзлайн решения конкурса. Идеи для бейзлайна вы можете почерпнуть из заданий лабораторной части.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 15 баллов. Сдавать задание после указанного срока сдачи нельзя. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, нам необходима ссылка на источник).\n",
    "\n",
    "Преодоление medium baseline на kaggle дает вам 5 баллов за конкурс. Если вы выполните задания из лабораторной, то пробить medium baseline для вас не составит труда.\n",
    "\n",
    "### Правила сдачи\n",
    "Выполненную работу следует отправить в систему Anytask. Более подробно о системе можно почитать на странице курса. Название отправляемого файла должно иметь следующий формат: Surname_Name_Group_NN.ipynb, где NN — номер лабораторной работы. Например, Kozlova_Anna_CS_02.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 балла) Задание 1.** Загрузите данные о запросах и их релевантности (*train.csv*, *test.csv*), а также информацию об организациях (*train_org_information.json*, *test_org_information.json*) и рубриках (*train_rubric_information.json*, *test_rubric_information.json*)\n",
    "\n",
    "Для дальнейших экспериментов необходимо посчитать небольшой набор базовых факторов. С использованием информации о запросах и организациях, посчитайте факторы, которые на ваш взгляд будут полезными для предсказания релевантности.\n",
    "\n",
    "Примерами текстовых факторов могут служить:\n",
    " - кол-во слов в запросе и названии организации;\n",
    " - пословные/N-граммные пересечения слов запроса и названия организации (также можно использовать синонимы названия организации и адрес организации): кол-во слов в пересечении, [мера Жаккара](https://en.wikipedia.org/wiki/Jaccard_index) и пр.;\n",
    " - кол-во различных синонимичных названий организации (поле *names* в описании организации);\n",
    " - One-hot-encoded язык запроса.\n",
    " \n",
    "По информации о географическом положении:\n",
    " - факт совпадения региона, где задавался запрос и региона организации;\n",
    " - координаты показанной области;\n",
    " - размеры показанной области;\n",
    " - меры, характеризующие близость координат организации к показанному окну: расстояние до центра области и другие.\n",
    " \n",
    "Факторы, описывающие организацию:\n",
    " - one-hot-encoding фактор cтраны или региона организации (важно: не используйте one-hot-encoding факторы, в которых больше 10 значений; если в факторе слишком много значений, ограничьтесь, например, только самыми популярными категориями)\n",
    " - кол-во рабочих дней в неделе и общая продолжительность работы (поле *work_intervals* в описании организации)\n",
    " - кол-во рубрик (поле *rubrics* в описании организации)\n",
    " \n",
    "![](https://miro.medium.com/max/1500/0*FwubnnoNlt6Coo9j.png)\n",
    "\n",
    "В этом задании не нужно использовать многомерные представления текстовой информации (tfidf и прочие embeddings) и информацию о кликах (*train_clicks_information.json*, *test_clicks_information.json*). Придумывать сверхсложные факторы тоже необязательно.\n",
    "\n",
    "Вы можете реализовать описанные выше факторы и/или придумать свои. Для экспериментов в лабораторной - достаточно реализовать предложенное, для победы в конкурсе - вряд ли. Но зачастую такие простые признаки могут приносить наибольшую пользу.\n",
    "\n",
    "В итоге у вас должно получиться от 15 до 50 факторов, характеризующих запрос и организацию и покрывающих основные источники данных (кроме кликов). Это наш основной датасет, который будет использоваться в экспериментах.\n",
    "\n",
    "**Важно**: До раздела *«Ранжирование»* будем считать, **что решается задача *регрессии* (предсказываем абсолютное значение релевантности)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import langdetect\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>region</th>\n",
       "      <th>org_name</th>\n",
       "      <th>org_id</th>\n",
       "      <th>window_center</th>\n",
       "      <th>window_size</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>суд, Украина, Днепропетровская область, Днепро...</td>\n",
       "      <td>21775</td>\n",
       "      <td>Суд Жовтневого району міста Дніпропетровськ</td>\n",
       "      <td>1021049127</td>\n",
       "      <td>34.613119,48.506531</td>\n",
       "      <td>0.025928,0.017380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>суд, Украина, Днепропетровская область, Днепро...</td>\n",
       "      <td>21775</td>\n",
       "      <td>Дніпропетровський окружний адміністративний суд</td>\n",
       "      <td>1602348889</td>\n",
       "      <td>34.613119,48.506531</td>\n",
       "      <td>0.025928,0.017380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>суд, Украина, Днепропетровская область, Днепро...</td>\n",
       "      <td>21775</td>\n",
       "      <td>Бабушкінський районний суд</td>\n",
       "      <td>1105837793</td>\n",
       "      <td>34.613119,48.506531</td>\n",
       "      <td>0.025928,0.017380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>суд, Украина, Днепропетровская область, Днепро...</td>\n",
       "      <td>21775</td>\n",
       "      <td>Красногвардійський районний суд</td>\n",
       "      <td>1066267658</td>\n",
       "      <td>34.613119,48.506531</td>\n",
       "      <td>0.025928,0.017380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>суд, Украина, Днепропетровская область, Днепро...</td>\n",
       "      <td>21775</td>\n",
       "      <td>Жовтневий суд</td>\n",
       "      <td>1661586235</td>\n",
       "      <td>34.613119,48.506531</td>\n",
       "      <td>0.025928,0.017380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                              query  region  \\\n",
       "0        11  суд, Украина, Днепропетровская область, Днепро...   21775   \n",
       "1        11  суд, Украина, Днепропетровская область, Днепро...   21775   \n",
       "2        11  суд, Украина, Днепропетровская область, Днепро...   21775   \n",
       "3        11  суд, Украина, Днепропетровская область, Днепро...   21775   \n",
       "4        11  суд, Украина, Днепропетровская область, Днепро...   21775   \n",
       "\n",
       "                                          org_name      org_id  \\\n",
       "0      Суд Жовтневого району міста Дніпропетровськ  1021049127   \n",
       "1  Дніпропетровський окружний адміністративний суд  1602348889   \n",
       "2                       Бабушкінський районний суд  1105837793   \n",
       "3                  Красногвардійський районний суд  1066267658   \n",
       "4                                    Жовтневий суд  1661586235   \n",
       "\n",
       "         window_center        window_size  relevance  \n",
       "0  34.613119,48.506531  0.025928,0.017380        0.0  \n",
       "1  34.613119,48.506531  0.025928,0.017380        0.0  \n",
       "2  34.613119,48.506531  0.025928,0.017380        0.0  \n",
       "3  34.613119,48.506531  0.025928,0.017380        0.0  \n",
       "4  34.613119,48.506531  0.025928,0.017380        0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('competition-2-shad-fall-2018/train.csv')\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('competition-2-shad-fall-2018/train_org_information.json', 'r') as read_file:\n",
    "    train_org_json = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordsFromString(x) -> str:\n",
    "    return re.sub(r\"[^A-Za-zА-Яа-я]+\", ' ', x).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIntersectionWordsCount(x) -> int:\n",
    "    return len(set(getWordsFromString(x[0])) & set(getWordsFromString(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSynonymousNamesCount(x) -> int:\n",
    "    node = train_org_json.get(str(x))\n",
    "    if node is not None:\n",
    "        return len(node[\"names\"])\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEncodedLangs():\n",
    "    langs = train_data['query'].apply(lambda x: langdetect.detect(x))\n",
    "    sortedLangs = [lang for lang, _ in Counter(langs).most_common()]\n",
    "    langsEncoder = OneHotEncoder(sparse=False).fit(langs.values.reshape(-1,1))\n",
    "    encodedLangs = langsEncoder.transform(langs.values.reshape(-1,1))\n",
    "    langsIdx = [np.where(langsEncoder.categories_[0] == lang)[0][0] for lang in sortedLangs[:10]]\n",
    "    \n",
    "    newEncodedLangs = np.zeros((encodedLangs.shape[0], 11))\n",
    "    for i, idx in enumerate(langsIdx):\n",
    "        newEncodedLangs[:, i] = encodedLangs[:, idx]\n",
    "    for row in newEncodedLangs:\n",
    "        if row.sum() == 0:\n",
    "            row[-1] = 1\n",
    "    return newEncodedLangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRubricsCount(x) -> int:\n",
    "    node = train_org_json.get(str(x))\n",
    "    if node is not None:\n",
    "        return len(node[\"rubrics\"])\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWorkTime(x) -> int:\n",
    "    node = train_org_json.get(str(x))\n",
    "    if node is not None:\n",
    "        work_interval_sum = 0\n",
    "        for work_interval in node[\"work_intervals\"]:\n",
    "            work_interval_sum += work_interval[\"time_minutes_end\"] - work_interval[\"time_minutes_begin\"]\n",
    "        if len(node[\"work_intervals\"]) != 0:\n",
    "            return work_interval_sum / len(node[\"work_intervals\"])\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDaysCount(x):\n",
    "    node = train_org_json.get(str(x))\n",
    "    if node is not None:\n",
    "        daysCount = 0\n",
    "        for work_interval in node[\"work_intervals\"]:\n",
    "            day = work_interval[\"day\"]\n",
    "            if day == \"everyday\":\n",
    "                daysCount = max(daysCount, 7)\n",
    "            elif day == \"weekdays\":\n",
    "                daysCount = max(daysCount, 5)\n",
    "            elif day == \"weekend\":\n",
    "                daysCount = max(daysCount, 2)\n",
    "            elif day in [\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\"]:\n",
    "                daysCount = 1\n",
    "            else:\n",
    "                daysCount = 0\n",
    "        return daysCount\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRegionCode(x) -> str:\n",
    "    node = train_org_json.get(str(x))\n",
    "    if node is not None:\n",
    "        return node[\"address\"][\"region_code\"]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEncodedRegionCode():\n",
    "    regionCodes = train_data[\"org_id\"].apply(getRegionCode).values\n",
    "    sortedRegionCodes = [code for code, _ in Counter(regionCodes).most_common()[:10]]\n",
    "    codesEncoder = OneHotEncoder(sparse=False).fit(regionCodes.reshape(-1,1))\n",
    "    encodedCodes = codesEncoder.transform(regionCodes.reshape(-1,1))\n",
    "    codesIdx = [np.where(codesEncoder.categories_[0] == code)[0][0] for code in sortedRegionCodes[:10]]\n",
    "    \n",
    "    newEncodedCodes = np.zeros((encodedCodes.shape[0], 11))\n",
    "    for i, idx in enumerate(codesIdx):\n",
    "        newEncodedCodes[:, i] = encodedCodes[:, idx]\n",
    "    for row in newEncodedCodes:\n",
    "        if row.sum() == 0:\n",
    "            row[-1] = 1\n",
    "    return newEncodedCodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = pd.DataFrame()\n",
    "\n",
    "new_train_data['query_words_count'] = train_data['query'].apply(lambda query: len(getWordsFromString(query)))\n",
    "new_train_data['org_name_words_count'] = train_data['org_name'].apply(lambda name: len(getWordsFromString(name)))\n",
    "new_train_data['intersection_words_count'] = train_data[['query', 'org_name']].apply(getIntersectionWordsCount, axis=1)\n",
    "new_train_data['jaccard_score'] = new_train_data['intersection_words_count'] / (new_train_data['query_words_count'] + new_train_data['org_name_words_count'] - new_train_data['intersection_words_count'])\n",
    "new_train_data['synonymous_names_count'] = train_data['org_id'].apply(getSynonymousNamesCount)\n",
    "\n",
    "encodedLangs = getEncodedLangs()\n",
    "new_train_data = pd.concat([new_train_data, pd.DataFrame(encodedLangs)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data['window_center1'] = train_data['window_center'].apply(lambda x: x.split(',')[0]).values\n",
    "new_train_data['window_center2'] = train_data['window_center'].apply(lambda x: x.split(',')[1]).values\n",
    "new_train_data['window_size1'] = train_data['window_size'].apply(lambda x: x.split(',')[0]).values\n",
    "new_train_data['window_size2'] = train_data['window_size'].apply(lambda x: x.split(',')[1]).values\n",
    "new_train_data['rubrics_count'] = train_data['org_id'].apply(getRubricsCount)\n",
    "new_train_data['worktime'] = train_data['org_id'].apply(getWorkTime)\n",
    "new_train_data['workdays_count'] = train_data['org_id'].apply(getDaysCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedCodes = getEncodedRegionCode()\n",
    "new_train_data = pd.concat([new_train_data, pd.DataFrame(encodedCodes, columns=list(range(11,22)))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data[\"relevance\"] = train_data[\"relevance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance decomposition. Композиции алгоритмов\n",
    "\n",
    "![](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png)\n",
    "\n",
    "Рассмотрим задачу регрессии со среднеквадратичной функцией потерь, а также некоторый алгоритм $a$. Тогда качество алгоритма $a$ может быть записано следующим образом:\n",
    "\n",
    "$$Q(a) = \\mathbb{E}_{X^l} \\mathbb{E}_{x,y}(a(x) - y)^2,$$\n",
    "\n",
    "где первое матожидание вычисляется по всевозможным обучающим выборкам $X^l$ размера $l$. К сожалению, на реальных данных эта формула неприменима из-за невозможности сгенерировать необходимые для оценки данные. Поэтому проведем приближенный численный эксперимент с эмпирическими оценками матожиданий.\n",
    "\n",
    "С помощью бутстраппинга можно просемплировать из обучающей выборки $N$ новых выборок того же размера, тем самым \"имитируя\" пространство всевозможных обучающих выборок, после чего обучить на каждой выбранный алгоритм. Обозначим вектор истинных меток тестовой выборки за $y \\in \\mathbb{R}^{m}$. Векторы прогнозов для объектов из тестовой выборки для каждой модели обозначим за $\\hat{y}_i \\in \\mathbb{R}^{m}, i \\in \\{1, .., N\\}$. Тогда средний квадрат ошибки по всем моделям на тестовой выборке запишется как\n",
    "\n",
    "$$error=\\frac{1}{N}\\sum_{i=1}^{N}MSE(y,\\hat{y}_i).$$\n",
    "\n",
    "Обозначим среднее предсказание за $$\\overline{y} = \\frac{1}{N}\\sum_{i=1}^{N} \\hat{y}_i.$$\n",
    "\n",
    "Тогда квадрат отклонения среднего предсказания и разброс прогнозов относительно среднего предсказания всех моделей на тестовой выборке от истинных меток запишутся следующим образом, соответственно:\n",
    "\n",
    "$$bias^2 = MSE(y, \\overline y),$$\n",
    "\n",
    "$$variance = \\frac{1}{N}\\sum_{i=1}^N MSE(\\hat{y}_i, \\overline y).$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала рассмотрим в качестве алгоритма решающее дерево. Как известно, при увеличении высоты дерева алгоритм может быть сильно чувствителен к составу обучающей выборки. Чтобы подтвердить эти предположения, проведите следующие эксперименты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Разбейте обучающий пул с факторами на обучающую и тестовую выборки в пропорциях 1 к 4 соответственно. Обратите внимание, что обучающая выборка меньше тестовой. Такая большая тестовая выборка позволит сделать измерение качества моделей достаточно достоверным. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splited, test_splited = train_test_split(new_train_data.values, train_size=1/5)\n",
    "train_splited.shape[0] / test_splited.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splited_size = train_splited.shape[0]\n",
    "train_splited_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splited_size = test_splited.shape[0]\n",
    "test_splited_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**(1 балл) Задание 2.** Постройте графики зависимости $error$, $bias^2$ и $variance$ от глубины решающего дерева (от 1 до 15 включительно) для $N=200$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = list(range(1,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "boots_trains_idx = np.random.choice(list(range(train_splited_size)), (train_splited_size, N), replace=True)\n",
    "boots_trains_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boots_trains = []\n",
    "for train_idx in np.transpose(boots_trains_idx):\n",
    "    boots_trains.append(train_splited[train_idx])\n",
    "boots_trains = np.array(boots_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boots_trains.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "bias2s = []\n",
    "variances = []\n",
    "\n",
    "X_test = test_splited[:, :-1]\n",
    "y_test = test_splited[:, -1]\n",
    "\n",
    "for depth in depths:\n",
    "    mean_y_pred = np.zeros(test_splited_size)\n",
    "    mse_sum = 0\n",
    "    y_preds = []\n",
    "    for train in boots_trains:\n",
    "        X_train = train[:, :-1]\n",
    "        y_train = train[:, -1]\n",
    "        decision_tree_regressor = DecisionTreeRegressor(max_depth=depth).fit(X_train, y_train)\n",
    "        y_pred = np.array(decision_tree_regressor.predict(X_test))\n",
    "        y_preds.append(y_pred)\n",
    "        mse_sum += mean_squared_error(y_test, y_pred)\n",
    "        mean_y_pred += y_pred\n",
    "    mean_y_pred /= N\n",
    "    errors.append(mse_sum / N)\n",
    "    bias2s.append(mean_squared_error(y_test, mean_y_pred))\n",
    "    \n",
    "    var = 0\n",
    "    for y in y_preds:\n",
    "        var += mean_squared_error(y, mean_y_pred)\n",
    "    variances.append(var / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(depths, errors, label=\"$Error$\")\n",
    "plt.plot(depths, bias2s, label=\"$Bias^2$\")\n",
    "plt.plot(depths, variances, label=\"$Variance$\")\n",
    "plt.xlabel('depth')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 балла) Задание 3.** Являются ли какие-то из полученных графиков монотонными? А должны ли они быть монотонными, если бы гипотетически эксперименты были проведены на всевозможных выборках? Почему? Убедитесь численно, что верно bias-variance разложение ошибки: $$error = bias^2 + variance$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(errors) - (np.array(bias2s) + np.array(variances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**  \n",
    "- $bias^2$ и $variance$ являются монотонными.  \n",
    "- разность между ошибкой и суммой смещения и разброса отличаются на $10^{-18}$, поэтому разложение верно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Композиции алгоритмов\n",
    "\n",
    "Несмотря на описанный выше недостаток решающих деревьев, объединение их в композиции позволяет существенно улучшить качество предсказания. Рассмотрим несколько способов построения композиций.\n",
    "\n",
    "### Bagging + RSM\n",
    "\n",
    "![](https://sites.google.com/site/rajhansgondane2506/_/rsrc/1467898300734/publications/rrftrain.jpg?height=215&width=320)\n",
    "\n",
    "Один из способов объединения алгоритмов в композиции — обучение каждого отдельного алгоритма на некоторой подвыборке из исходной выборки ([bagging](https://en.wikipedia.org/wiki/Bootstrap_aggregating)) и подмножестве исходных признаков ([RSM](https://en.wikipedia.org/wiki/Random_subspace_method)). В sklearn этот тип композиции реализован в классе [BaggingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html) (для случая регресии). Подобный подход также есть в реализации [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг\n",
    "\n",
    "В случае бустинга композиция алгоритмов строится последовательно. Каждый следующий базовый алгоритм акцентируется на тех объектах, на которых обученная ранее композиция допускала ошибку.\n",
    "\n",
    "Туториал по работе с известными реализациями градиентного бустинга XGBoost и CatBoost можно найти на вики-странице курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл) Задание 4.** Проведите аналогичный эксперимент с bias-variance разложением для *градиентного бустинга*, а также для *случайного леса*, варьируя количество базовых алгоритмов (рассмотрите 1, 5, 10, 25, 50, 100 решающих деревьев).\n",
    "\n",
    "Используйте модели градиентного бустанга XGBoost или CatBoost. Random Forest возьмите из пакета sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [1, 5, 10, 25, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorsXGB = []\n",
    "bias2sXGB = []\n",
    "variancesXGB = []\n",
    "\n",
    "X_test = test_splited[:, :-1]\n",
    "y_test = test_splited[:, -1]\n",
    "\n",
    "for estimator in estimators:\n",
    "    mean_y_pred = np.zeros(test_splited_size)\n",
    "    mse_sum = 0\n",
    "    y_preds = []\n",
    "    for train in boots_trains:\n",
    "        X_train = train[:, :-1]\n",
    "        y_train = train[:, -1]\n",
    "        xgbRegressor = xgboost.XGBRegressor(n_estimators=estimator).fit(X_train, y_train)\n",
    "        y_pred = np.array(xgbRegressor.predict(X_test))\n",
    "        y_preds.append(y_pred)\n",
    "        mse_sum += mean_squared_error(y_test, y_pred)\n",
    "        mean_y_pred += y_pred\n",
    "    mean_y_pred /= N\n",
    "    errorsXGB.append(mse_sum / N)\n",
    "    bias2sXGB.append(mean_squared_error(y_test, mean_y_pred))\n",
    "    \n",
    "    var = 0\n",
    "    for y in y_preds:\n",
    "        var += mean_squared_error(y, mean_y_pred)\n",
    "    variancesXGB.append(var / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(estimators, errorsXGB, label=\"$Error$\")\n",
    "plt.plot(estimators, bias2sXGB, label=\"$Bias^2$\")\n",
    "plt.plot(estimators, variancesXGB, label=\"$Variance$\")\n",
    "plt.xlabel('estimators')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorsRF = []\n",
    "bias2sRF = []\n",
    "variancesRF = []\n",
    "\n",
    "X_test = test_splited[:, :-1]\n",
    "y_test = test_splited[:, -1]\n",
    "\n",
    "for estimator in estimators:\n",
    "    mean_y_pred = np.zeros(test_splited_size)\n",
    "    mse_sum = 0\n",
    "    y_preds = []\n",
    "    for train in boots_trains:\n",
    "        X_train = train[:, :-1]\n",
    "        y_train = train[:, -1]\n",
    "        random_forest_regressor = RandomForestRegressor(n_estimators=estimator).fit(X_train, y_train)\n",
    "        y_pred = np.array(random_forest_regressor.predict(X_test))\n",
    "        y_preds.append(y_pred)\n",
    "        mse_sum += mean_squared_error(y_test, y_pred)\n",
    "        mean_y_pred += y_pred\n",
    "    mean_y_pred /= N\n",
    "    errorsRF.append(mse_sum / N)\n",
    "    bias2sRF.append(mean_squared_error(y_test, mean_y_pred))\n",
    "    \n",
    "    var = 0\n",
    "    for y in y_preds:\n",
    "        var += mean_squared_error(y, mean_y_pred)\n",
    "    variancesRF.append(var / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(estimators, errorsRF, label=\"$Error$\")\n",
    "plt.plot(estimators, bias2sRF, label=\"$Bias^2$\")\n",
    "plt.plot(estimators, variancesRF, label=\"$Variance$\")\n",
    "plt.xlabel('estimators')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 балла) Задание 5.** Отличаются ли графики в рассмотренных моделях (градиентный бустинг, случайный лес)  между собой? На какую компоненту из разложения ошибки влияет объединение алгоритмов в рассмотренный тип композиции? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Рассмотренные модели строят последовательно алгоритмы, каждый из которых будет уменьшать ошибку предыдущего, то есть он последовательно старается уменьшить смещение и дисперсию. На графиках можно увидеть, что на ошибку больше всего влияет смещение. Однако, XGBoost справляется с данной задачей намного лучше (с точки зрения уменьшения смещения) по сравнению со случайным лесом. В случайном лесе же лучше уменьшается дисперсия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стекинг\n",
    "![](https://4.bp.blogspot.com/-hCxAb57kzDQ/VuMgHy3hAhI/AAAAAAAAAVk/djmL9IHv5QkLWeudjE50qDoCTbiUrTetA/s1600/Stacking.jpg)\n",
    "\n",
    "[Stacking](https://en.wikipedia.org/wiki/Ensemble_learning#Stacking) — еще один способ объединить несколько алгоритмов в один, который часто используется как в решении реальных задач из промышленной сферы, так и в конкурсах на платформах вроде Kaggle. Подход использует понятие *базовых классификаторов*, каждый из которых независимо обучается на некотором (возможно одном и том же) множестве признаков, а также *мета-классификатора*, использующего предсказания базовых классификаторов как факторы. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл) Задание 6.** Использование мета-классификатора подразумевает получение предсказаний от базовых классификаторов для тех объектов обучающей выборки, на которых мета-классификатор будет обучаться. В свою очередь базовые классификаторы тоже должны быть обучены на некоторой выборке. Чтобы избежать переобучения, обучающее множество делится на $n$ фолдов, $(n-1)$ из которых используются для обучения базовых классификаторов, а $n$-ый — для предсказания (вычисления значений мета-фактора).\n",
    "\n",
    "Для получения мета-факторов для тестовых данных базовые классификаторы могут быть обучены на всем обучающем множестве, поскольку проблема переобучения здесь не возникает. Другими словами, если мы хотим посчитать факторы для тестового множества, мы можем спокойно использовать обучающее множество для тренировки базовых классификаторов. Если же мы хотим посчитать факторы для обучающего множества, то необходимо следить, чтобы классификатор не предсказывал для тех объектов, на которых обучался.\n",
    "\n",
    "Мета-классификатор может быть обучен как на множестве исходных факторов, дополненным мета-факторами, так и исключительно на множестве мета-факторов. Выбор зависит от решаемой задачи.\n",
    "\n",
    "Напишите функцию, которая получает на вход классификатор, обучающую и тестовые выборки, а также параметры [кросс-валидатора](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) и возвращающую значения мета-фактора для обучающего и тестового множеств."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meta_feature(clf, X_train, X_test, y_train, cv, args, kwargs):\n",
    "    testMetaFeature = clf.fit(X_train, y_train).predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    trainMetaFeature = np.zeros(y_train.shape)\n",
    "    kfold = KFold(*args, **kwargs)\n",
    "    for trainIdx, testIdx in kfold.split(X_train):\n",
    "        X = X_train[trainIdx]\n",
    "        y = y_train[trainIdx]\n",
    "        trainMetaFeature[testIdx] = clf.fit(X, y).predict_proba(X_train[testIdx])[:, 1]\n",
    "        \n",
    "    return testMetaFeature.reshape(-1,1), trainMetaFeature.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл) Задание 7.** Обучите различные известные вам модели машинного обучения и сделайте из них стекинг-композицию. \n",
    "  \n",
    "  Базовые алгоритмы могут отличаться друг от друга:\n",
    "    - моделью машинного обучения,\n",
    "    - гиперпараметрами (например, различные функции потерь или глубины деревьев),\n",
    "    - набором факторов,\n",
    "    - целевой переменной: исходного целевую переменную y можно заменить на функцию от него (sqr(y), sqrt(y), log(y + 1), ...), бинаризовать по порогу ([y>y0]) или произвести другое преобразование.\n",
    "  \n",
    "  Обратите внимание, что бинарные мета-факторы дают меньше полезного сигнала мета-классификатору, чем числовые, поэтому базовым классификаторам лучше возвращать вероятность/числовую функцию, чем метки классов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf, y_clf = make_classification(n_samples=10000, n_features=10, n_informative=4, random_state=541)\n",
    "train_clf = np.hstack((X_clf, y_clf.reshape(-1,1)))\n",
    "train_clf, test_clf = train_test_split(train_clf, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_clf[:, :-1]\n",
    "y_train = train_clf[:, -1]\n",
    "\n",
    "X_test = test_clf[:, :-1]\n",
    "y_test = test_clf[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetaFeatures(clfs, X_train, X_test, y_train, args, kwargs):\n",
    "    metaFeature = compute_meta_feature(clfs[0], X_train, X_test, y_train, _, args, kwargs)\n",
    "    testMeta = metaFeature[0]\n",
    "    trainMeta = metaFeature[1]\n",
    "    for clf in clfs[1:]:\n",
    "        metaFeature = compute_meta_feature(clf, X_train, X_test, y_train, _, args, kwargs)\n",
    "        testMeta = np.hstack((testMeta, metaFeature[0]))\n",
    "        trainMeta = np.hstack((trainMeta, metaFeature[1]))\n",
    "    return testMeta, trainMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackingOnTestMetaFeature(clfs, metaClf, X_train, X_test, y_train, y_test, args, kwargs): \n",
    "    X, _ = getMetaFeatures(clfs, X_train, X_test, y_train, args, kwargs)\n",
    "    metaClf.fit(X, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackingOnTrainMetaFeature(clfs, metaClf, X_train, X_test, y_train, y_test, args, kwargs): \n",
    "    _, X = getMetaFeatures(clfs, X_train, X_test, y_train, args, kwargs)\n",
    "    metaClf.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [LogisticRegression(solver=\"sag\"), RandomForestClassifier(n_estimators=70)]\n",
    "metaClf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackingOnTestMetaFeature(clfs, metaClf, X_train, X_test, y_train, y_test.reshape(-1,1), (6,), {\"random_state\": 789})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = getMetaFeatures(clfs, X_train ,X_test, y_train, (6,), {\"random_state\": 500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"score on test: {}\".format(metaClf.score(X[0], y_test.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"score on train: {}\".format(metaClf.score(X[1], y_train.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [DecisionTreeClassifier(max_depth=4), DecisionTreeClassifier(max_depth=20), DecisionTreeClassifier(max_depth=30)]\n",
    "metaClf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackingOnTestMetaFeature(clfs, metaClf, X_train, X_test, y_train, y_test.reshape(-1,1), (6,), {\"random_state\": 523})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = getMetaFeatures(clfs, X_train ,X_test, y_train, (6,), {\"random_state\": 423})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"score on test: {}\".format(metaClf.score(X[0], y_test.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"score on train: {}\".format(metaClf.score(X[1], y_train.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [DecisionTreeClassifier(max_depth=4), DecisionTreeClassifier(max_depth=20), DecisionTreeClassifier(max_depth=30)]\n",
    "metaClf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackingOnTrainMetaFeature(clfs, metaClf, X_train, X_test, y_train, y_test.reshape(-1,1), (6,), {\"random_state\": 523})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = getMetaFeatures(clfs, X_train ,X_test, y_train, (6,), {\"random_state\": 423})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"score on test: {}\".format(metaClf.score(X[0], y_test.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"score on train: {}\".format(metaClf.score(X[1], y_train.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл) Задание 8.** В этом задании мы попробуем обучить стекинг композицию градиентного бустинга и линейной модели на данных различной природы.\n",
    "\n",
    "Загрузите данные по кликам (*train_clicks_information.json, test_clicks_information.json*). Используя текстовые информацию из данных о кликах, организациях, рубриках и запросах, постройте bag-of-words представление с помощью TfidfVectorizer.\n",
    "\n",
    "После этого у вас будет два набора факторов: базовые факторы (*base*), реализованные ранее, и разреженная матрица признаков, полученная применением TfidfVectorizer'а (*tfidf*).\n",
    "\n",
    "Обучите различные модели и замерьте качество на тестовой выборке по метрике MSE:\n",
    "\n",
    " 1. Линейная модель на tfidf факторах;\n",
    " \n",
    " 2. Линейная модель на tfidf + base факторах;\n",
    "\n",
    " 3. Градиентный бустинг на base факторах;\n",
    "\n",
    " 4. Градиентный бустинг на tfidf + base факторах (здесь можно сократить размерность tfidf, если данные не умещаются в памяти)\n",
    " \n",
    " 5. Градиентный бустинг на base факторах + мета-факторе «предсказание модели из п.1»\n",
    " \n",
    "\n",
    "Можете воспользоваться любой из двух реализаций градиентного бустинга: XGBoost или CatBoost.\n",
    "\n",
    "Для тренировки tfidf модели можно использовать и обучающие, и тестовые данные, поскольку она не зависит от целевой переменной.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('competition-2-shad-fall-2018/train_clicks_information.json', 'r') as read_file:\n",
    "    train_clicks_json = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('competition-2-shad-fall-2018/train_rubric_information.json', 'r') as read_file:\n",
    "    train_rubric_json = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClicks(x)->str:\n",
    "    node = train_clicks_json.get(str(x))\n",
    "    if node is not None:\n",
    "        return \" \".join(node)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOrgData(x)->str:\n",
    "    node = train_org_json.get(str(x))\n",
    "    if node is not None:\n",
    "        names = \"\"\n",
    "        for d in node[\"names\"]:\n",
    "            names += d[\"value\"][\"value\"] + \" \"\n",
    "        \n",
    "        rubrics = \"\"\n",
    "        for rubric in node[\"rubrics\"]:\n",
    "            rubrics += getRubricData(rubric) + \" \"\n",
    "        \n",
    "        address = node[\"address\"][\"formatted\"][\"value\"]\n",
    "        return names + rubrics + address\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRubricData(x):\n",
    "    node = train_rubric_json.get(str(x))\n",
    "    if node is not None:\n",
    "        keywords = \"\"\n",
    "        for value in node[\"keywords\"]:\n",
    "            keywords += value[\"value\"] + \" \"\n",
    "        \n",
    "        phrases = \"\"\n",
    "        for phrase in node[\"phrases\"]:\n",
    "            phrases += phrase[\"value\"] + \" \"\n",
    "        \n",
    "        descriptions = \"\"\n",
    "        for d in node[\"descriptions\"]:\n",
    "            descriptions += d[\"value\"][\"value\"] + \" \"\n",
    "        \n",
    "        names = \"\"\n",
    "        for d in node[\"names\"]:\n",
    "            names += d[\"value\"] + \" \"\n",
    "        \n",
    "        return keywords + phrases + descriptions + names\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWords(row) -> str:\n",
    "    query = row[0]\n",
    "    org_name = row[1]\n",
    "    clicks_data = getClicks(row[2])\n",
    "    org_data = getOrgData(row[2])\n",
    "    return query + \" \" + org_name + \" \" + clicks_data + \" \" + org_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_data[['query', 'org_name', 'org_id']].apply(getWords, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"суд, Украина, Днепропетровская область, Днепродзержинский городской совет Суд Жовтневого району міста Дніпропетровськ суд кіровського району дніпропетровська суды г днепропетровска заводской суд г днепродзержинска жовтневій суд днепропетровск украина днепропетровск суд суд на паторжинского днепропетровск жовтневий суд м дніпропетровська улица поторжинского суд жовтневого района г днепропетровска официальный сайт суд г днепр жовтневый районный суд жовтневый районный суд днепр Sud Zhovtnevogo rayona goroda Dnepropetrovsk Суд Жовтневого района города Днепропетровск Суд Жовтневого району Суд Жовтневого району міста Дніпропетровськ Суд Октябрского района hukuki, adliye, adliyeler, işlemler, islemler, sarayı, adalet, mahkeme, sarayları, mahkemeler Суды Amtsgericht Courthouses Gericht Gerichtsbehörde Gerichtshof Justice Courts Mahkemeler Palais de Justice Rechtsprechung Richter Tribunal adalet sarayı adliye adliye sarayları adliyeler autorité judiciaire autorités judiciaires cour de justice court court complex courts hukuki islemler hukuki işlemler juridiction de jugement mahkeme tribunal суд суд судебные органы судебный участок суди суди м судова дільниця судові органи суды суды г Genel ve özel yargı alanlarında çalışan devlet adliyeleri: örneğin, hakem, iş ihtilafı alanında çalışan, askeri, idari mahkemeler v.b. Sulh hakimleri de bu kategoride. Avukatlar ve hukukçular bu kategoriye eklenemez. Государственные органы правосудия общей юрисдикции и специализированные: арбитражные, по трудовым спорам, военные, административные и т.п. Мировые судьи также в этой рубрике. В рубрике недопустимо размещение адвокатов и юристов.\\n\\n Государственные органы правосудия общей юрисдикции и специализированные: арбитражные, по трудовым спорам, военные, административные и т.п. Размещение адвокатов и юристов в этой рубрике не допускается. Adliyeler Court Gericht Giudizio Tribunal d'instance Сот Суд Суд Суд Դատարան دادگاه  Днепропетровская обл., Днепр г., ул. Паторжинского, 18а\",\n",
       "       \"суд, Украина, Днепропетровская область, Днепродзержинский городской совет Дніпропетровський окружний адміністративний суд дніпропетровський окружний адміністративний суд украина днепропетровск купянская улица 4 суд янгеля административный суд днепропетровска административный суд адміністративні суди україни суд днепр дніпропетровський адміністративний суд административный окружной суд днепропетровска украина днепр административный суд суды днепропетровска Dnepropetrovsky okruzhnoy administrativny sud Днепропетровский окружной административный суд Дніпропетровський окружний адміністративний суд Окружний адміністративний суд Окружной административный суд hukuki, adliye, adliyeler, işlemler, islemler, sarayı, adalet, mahkeme, sarayları, mahkemeler Суды Amtsgericht Courthouses Gericht Gerichtsbehörde Gerichtshof Justice Courts Mahkemeler Palais de Justice Rechtsprechung Richter Tribunal adalet sarayı adliye adliye sarayları adliyeler autorité judiciaire autorités judiciaires cour de justice court court complex courts hukuki islemler hukuki işlemler juridiction de jugement mahkeme tribunal суд суд судебные органы судебный участок суди суди м судова дільниця судові органи суды суды г Genel ve özel yargı alanlarında çalışan devlet adliyeleri: örneğin, hakem, iş ihtilafı alanında çalışan, askeri, idari mahkemeler v.b. Sulh hakimleri de bu kategoride. Avukatlar ve hukukçular bu kategoriye eklenemez. Государственные органы правосудия общей юрисдикции и специализированные: арбитражные, по трудовым спорам, военные, административные и т.п. Мировые судьи также в этой рубрике. В рубрике недопустимо размещение адвокатов и юристов.\\n\\n Государственные органы правосудия общей юрисдикции и специализированные: арбитражные, по трудовым спорам, военные, административные и т.п. Размещение адвокатов и юристов в этой рубрике не допускается. Adliyeler Court Gericht Giudizio Tribunal d'instance Сот Суд Суд Суд Դատարան دادگاه  Украина, Днепр, улица Академика Янгеля, 4\",\n",
       "       \"суд, Украина, Днепропетровская область, Днепродзержинский городской совет Бабушкінський районний суд бабушкинский суд г днепропетровск украина днепр бабушкинский районный суд украина днепропетровск районный суд бабушкинский портал судової влади бабушкінський суд м дніпропетровська днепр бабушкинский районнный суд амур нижнеднепровский районный суд суд бабушкинского района днепропетровска днепр как доехать в бабушкинский райсуд суды днепропетровска empty www autotak com ua днепропетровск суді днепр Babushkinsky rayonny sud Babushkinsky rayony sud g. Dnepropetrovska Бабушкинский районный суд Бабушкинский районый суд г. Днепропетровска Бабушкінський районний суд Бабушкінський районний суд Бабушкінський районый суд м. Дніпропетровська hukuki, adliye, adliyeler, işlemler, islemler, sarayı, adalet, mahkeme, sarayları, mahkemeler Суды Amtsgericht Courthouses Gericht Gerichtsbehörde Gerichtshof Justice Courts Mahkemeler Palais de Justice Rechtsprechung Richter Tribunal adalet sarayı adliye adliye sarayları adliyeler autorité judiciaire autorités judiciaires cour de justice court court complex courts hukuki islemler hukuki işlemler juridiction de jugement mahkeme tribunal суд суд судебные органы судебный участок суди суди м судова дільниця судові органи суды суды г Genel ve özel yargı alanlarında çalışan devlet adliyeleri: örneğin, hakem, iş ihtilafı alanında çalışan, askeri, idari mahkemeler v.b. Sulh hakimleri de bu kategoride. Avukatlar ve hukukçular bu kategoriye eklenemez. Государственные органы правосудия общей юрисдикции и специализированные: арбитражные, по трудовым спорам, военные, административные и т.п. Мировые судьи также в этой рубрике. В рубрике недопустимо размещение адвокатов и юристов.\\n\\n Государственные органы правосудия общей юрисдикции и специализированные: арбитражные, по трудовым спорам, военные, административные и т.п. Размещение адвокатов и юристов в этой рубрике не допускается. Adliyeler Court Gericht Giudizio Tribunal d'instance Сот Суд Суд Суд Դատարան دادگاه  Дніпропетровська обл., Дніпро, просп. Дмитра Яворницького, 57\",\n",
       "       ...,\n",
       "       \"• Кафедральный собор Кафедральный Собор, офис россия калининград магила канта кёнигсбергский собор карта калининграда с достопримечательностями музеи в калининграде музеи калининграда на карте кафедральный собор калининград официальный сайт кенигсберский собор кафедральный собор калиниград собор канта кафедральный собор россия калининград остров кант музей канта калининград собор быдгощ Kafedralny Sobor ГАУ Ко Кафедральный Собор Кафедральный Собор Кафедральный Собор, офис gayrimenkul yonetim, firmaları Управляющие компании Yonetim firmaları gestion d'actifs gestion de l'organisation management companies management organizations société de gestion société gérante sociétés de gestion sociétés gérantes trust management доверительное управление довірче управління керуюча організація керуючі компанії управляющая организация управляющие компании Türlü işlerin yönetimi: fitness kulüpleri, restoranlar, ticaret kurumları v.s. Ayrıca başkalarının mallarının, açık uçlu fonların ve özel emeklilik fonlarının güvenli yönetimi yapan kurumlar. Ev yönetim kurumları Konut servisleri kuruluşları ve Ev sahipleri derneği kategorilerinde.\\n\\nBenzer kategoriler: Konut servisleri kuruluşları, Ev sahipleri derneği. У рубриці розміщуються компанії, які здійснюють довірче управління майном інших осіб, ПІФами та недержавними пенсійними фондами. Управление разными бизнесами: фитнес-клубами, ресторанами, торговлей и пр. Также компании, осуществляющее доверительное управление имуществом других лиц,  ПИФами и негосударственными пенсионными фондами. Домовые управляющие компании - в рубриках Коммунальная служба и ТСЖ. Управление разными бизнесами: фитнес-клубами, ресторанами, торговлей и пр. Также компании, осуществляющее доверительное управление имуществом других лиц,  ПИФами и негосударственными пенсионными фондами. Домовые управляющие компании - в рубриках Коммунальная служба и ТСЖ.\\n\\nПохожие рубрики: Коммунальная служба, ТСЖ. Management company Società di gestione Société gérante Verwaltungsgesellschaft İşletme Басқарушы компания Бошқарув компанияси Керівна компанія Управляющая компания Կառավարման ընկերություն شرکت مدیریت  Россия, Калининград, Нарвская улица, 56\",\n",
       "       \"• Кафедральный собор Кафедральный собор Христа Спасителя церковь в багратионовске калининградской области храм христа спасителя калининград официальный сайт калининград как доехать от северного вокзала до кафедрального собора достопримечсельности калининграда храмы калининграда адреса достопричательности калининград православные храмы храмы калининграда на карте когда проходят беседы перед крещением в храме на площади калининград собор кафедральный православные церкви в калининграде на карте россия калининград храмы храм калининград время работы кафедральны собор светлогорск церковь Kafedralny sobor Khrista Spasitelya Sobor Rozhdestva Khristova Кафедральный собор Христа Спасителя Собор Рождества Христова Собор Христа Спасителя Hiristiyanlık Kathedrale Kirche Orthodox cathedral Orthodox church Orthodoxe Kirche Othodox church cathedral Rum attractions bazilika cathedral cathédrales de l'église orthodoxe church church cathedral churches and museums curiosités katedral kilise l'église orthodoxe la cathédrale orthodoxe les musées et les temples les temples de l'église les temples et les musées lieu de culte museums and churches müze ortodoks kilisesi ortodoksluk patrikhane patrikhanesi patriklik patrikliği religious buildings tarihi eser tarihi mekan temples de l'église orthodoxe églises orthodoxes şapel визначні місця достопримечательности музеи и храмы музеї і храми пам'ятки православна церква православная церковь православний собор православний храм православный собор православный храм регигиозные сооружения регігіозние споруди собор собор собори православної церкви соборы православной церкви храм храм храм собор церква храм собор церковь храми православної церкви храми церкви храми і музеї храмы и музеи храмы православной церкви храмы церкви церква церковь Kiliseler, katedraller, şapeller. Ayrıca ayrı kategoriler de mevcutur: Katolik Kilisesi, Sinagog, Cami. Diğer inançlara dair ibadet evleri - Kiliseler ve diğer ibadet mekanları kategorisinde.  Православные храмы, соборы, церкви, часовни. Также есть отдельные рубрики: Католический храм, Пагода, Синагога, Мечеть. Молитвенные дома прочих вероисповеданий - в рубрике Церкви и дома молитвы разных конфессий. Религиозные общины, управления и прочие религиозные организации - в рубрике Религиозное объединение. Православные храмы, соборы, церкви, часовни. Также есть отдельные рубрики: Католический храм, Пагода, Синагога, Мечеть. Молитвенные дома прочих вероисповеданий - в рубрике Церкви и дома молитвы разных конфессий. Религиозные общины, управления и прочие религиозные организации - в рубрике Религиозное объединение.\\n Православні храми, собори, церкви, монастирі, каплиці. Є окремі рубрики для мечетей, синагог і католицьких храмів. Молитовні будинки інших віросповідань - у рубриці Релігійні об'єднання. Chiesa ortodossa Orthodox church Orthodoxe Kirche Ortodoks kiliseleri Église orthodoxe Православ ғибадатханасы Православлар ибодатхонаси Православний храм Православный храм Ուղղափառ եկեղեցի کلیسای ارتدوکس  Калининград, пл. Победы, 2\",\n",
       "       '• Кафедральный собор Кафедральный собор музей канта в калининграде кафедральный собор в калининграде карта калининград кафедральный собор кёнигсберга музей парк скульптуры калининград кафедральный собор как доехать кафедральный собор кенигсберга в калининграде музей на портовой калининград органные концерты в калининграде кафедральный собор калининград магила канта кафедральный собор калининград ул канта 1 достопремечательности карта калининграда с улицами и достопримечательностями калининград кофедральные собор россия калининград кафедральный калининград музей кафедральный собор в калининграде 2017 все гос учреждения калининграда калининград концертный зал органа сабор калининград калининград кафедральный сабор кафедральный собор кафедральный собор калинингград калининград достопримеч калининград на карте достопримечательности собора канта калининград калининград россия кафедральный собор кафедральный собор где находится собор кафедральный калининград концертные залы питера орган в калининграде кафедральный собор кенигсберга карта церковь на острове канта карта калининград кафедральный собор остров кантакалининград кафедральный собор россия калининград ул канта учрежденияrfkbybuhflcrjq области от улицы киевская калининград достопримечательности о канта кёнигсбергский кафедральный собор калининград бфу и канта концерты органной музыки в калининграде кафедральный собор музей канта музеи города калининграда карта калининград кафедральный собор россия калининград кафедральный соор та калининграда с достопримечательностями россия калининград могила канта кафедральный собор в калининграде как доехать калининград достопремечательности остров канта в калининграде официальный сайт собора кенигсберга россия калининград кафедральный собор россия калининград остров канта калининград карта с достопримечательностями россия калининград с доспромечательностями калининград храмы могила канта в калининграде фото бранденбургские ворота калининград музей режим работы кафедральный собор калининград на карте кант кафедральный собор в калининграде режим работы rkbybyuhfl rfatlhfkmysq cj jh россия калининград музей курганская улица 3 калининград достопримечательности рядом как работают музеи и соборы в калининграде на новый год г калининград органный концерт лютеранский собор церкви в калининграде музеи калиннграда о канта россия собор достопримечательности г калининграда соборы россии россия калининград кафед россия калининград кафедральный собо адрес кафедральный собор калининград калининград замок канта касимовский кафедральный собор время работы кафедрального собора в калининграде федеральный собор в калининграде орган в калининграде кафедральный собор россия калининград музеи ул генерала соммера д 8 ljcnjghbvtxfntkmyjcvnb Kafedralny sobor Кафедральный собор Органный комплекс Кафедральный Собор Собор kültür, merkezi, merkezleri, alanlar, sanat, halk, kultur, kültürel, kulturel Культурные центры Freizeitzentrum Kultur merkezleri Kulturverein Kulturzentrum centre culturel centre de la culture centres culturels centres de la culture cultural center cultural centers halk kültür merkezi halk kültür merkezleri kultur merkezi kulturel alanlar kültür merkezi kültür merkezleri kültür sanat merkezi kültür sanat merkezleri kültürel alanlar культурные центры культурні центри центр культури центр культуры Topluma kültür ve sanat değerlerini tanıtan kurumlar, binalar veya mimarlık kompleksleri. Birkaç kültür veya sanat türlerini kapsayan büyük çok fonksiyonlu kompleksler olabilir. Bir ulusal, dini, sosyal veya başka bir gruba yönelik kültür kurumları olabilir (büyükelçilikler veya ülkelerin başka temsilcilikleri, dinsel kurumlar, sosyal birliklere ait olabilir). Kültür merkezinin amacı, sadece belirli grubun iç ihtiyaçlarının karşılanması değil topluma kendi kültürünün tanıtılması. Kültür evinden farkı şu: kültür evine kültüre dokunmak ve dinlenmek için gelinir; kültür merkezi, topluma kültürü tanıtmak için çalışır.\\n\\nBenzer kategori: Kültür merkezleri. Организации, здания или комплексы зданий, которые продвигают в общество ценности культуры и искусства. М.б. крупные многофункциональные комплексы, охватывающие несколько видов искусства или культуры. М.б. учреждения культуры, имеющие национальную, конфессиональную, социальную или иную групповую ориентацию (иногда при посольствах или иных представительствах стран, религиозных организаций, общественных объединений). КЦ ставят перед собой задачи не только обслуживания внутренних интересов своей группы, но и знакомят со своей культурой окружающее общество. Отличие от дома культуры: ДК - место проведения культурного досуга, КЦ - центр продвижения культуры в общество.\\n\\nПохожая рубрика: Дом культуры. Centre culturel Centro culturale Cultural center Kulturzentrum Kültür merkezleri Культурний центр Культурный центр Маданий марказ Мәдениет орталығы Մշակութային կենտրոն مرکز فرهنگی  Калининград, ул. Канта, 1'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(corpus.values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29274, 203321)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = PCA(n_components=1000).fit_transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance = train_data['relevance'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У меня модель не обучается на полном tfidf, поэтому оставлю только 2000 рандомных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Idx = np.random.choice(tfidf.shape[1], size=2000, replace=False)\n",
    "Idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Линейная модель на tfidf факторах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, SGDRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf[:, Idx], relevance[:, Idx], train_size=1/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Линейная модель на tfidf + base факторах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Градиентный бустинг на base факторах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Градиентный бустинг на tfidf + base факторах (здесь можно сократить размерность tfidf, если данные не умещаются в памяти)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Градиентный бустинг на base факторах + мета-факторе «предсказание модели из п.1»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл) Задание 9.**\n",
    "Проанализируйте результаты, полученные в предыдущем задании. Сравните модели с точки зрения полученного качества, времени обучения и затрат по памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалось ли улучшить качество предсказания с помощью стекинга?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему реализованная в п.5 стекинг композиция может работать лучше, чем градиентный бустинг, обученный на всем множестве факторов (п.4)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помогло ли добавление базовых факторов в линейную модель (модель из п.2 против модели из п.1)? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ранжирование\n",
    "\n",
    "![](http://i.imgur.com/2QnD2nF.jpg)\n",
    "\n",
    "Задачу поискового ранжирования можно описать следующим образом: имеется множество документов $d \\in D$ и множество запросов $q \\in Q$. Требуется оценить *степень релевантности* документа по отношению к запросу: $(q, d) \\mapsto r$, относительно которой будет производиться ранжирование. Для восстановления этой зависимости используются методы машинного обучения. Обычно используется три типа:\n",
    " - признаки запроса $q$, например: мешок слов текста запроса, его длина, ...\n",
    " - документа $d$, например: значение PageRank, мешок слов, доменное имя, ...\n",
    " - пары $(q, d)$, например: число вхождений фразы из запроса $q$ в документе $d$, ...\n",
    "\n",
    "Одна из отличительных особенностей задачи ранжирования от классических задач машинного обучения заключается в том, что качество результата зависит не от предсказанных оценок релевантности, а от порядка следования документов в рамках конкретного запроса, т.е. важно не абсолютное значение релевантности (его достаточно трудно формализовать в виде числа), а то, более или менее релевантен документ, относительно других документов.\n",
    "### Подходы к решению задачи ранжирования\n",
    "Существуют 3 основных подхода, различие между которыми в используемой функции потерь:\n",
    "  \n",
    "1. **Pointwise подход**. В этом случае рассматривается *один объект* (в случае поискового ранжирования - конкретный документ) и функция потерь считается только по нему. Любой стандартный классификатор или регрессор может решать pointwise задачу ранжирования, обучившись предсказывать значение таргета. Итоговое ранжирование получается после сортировки документов к одному запросу по предсказанию такой модели.\n",
    "2. **Pairwise подход**. В рамках данной модели функция потерь вычисляется по *паре объектов*. Другими словами, функция потерь штрафует модель, если отражированная этой моделью пара документов оказалась в неправильном порядке.\n",
    "3. **Listwise подход**. Этот подход использует все объекты для вычисления функции потерь, стараясь явно оптимизировать правильный порядок.\n",
    "\n",
    "### Оценка качества\n",
    "\n",
    "Для оценивания качества ранжирования найденных документов в поиске используются асессорские оценки. Само оценивание происходит на скрытых от обучения запросах $Queries$. Для этого традиционно используется метрика *DCG* ([Discounted Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)) и ее нормализованный вариант — *nDCG*, всегда принимающий значения от 0 до 1.\n",
    "Для одного запроса DCG считается следующим образом:\n",
    "$$ DCG = \\sum_{i=1}^P\\frac{(2^{rel_i} - 1)}{\\log_2(i+1)}, $$\n",
    "\n",
    "где $P$ — число документов в поисковой выдаче, $rel_i$ — релевантность (асессорская оценка) документа, находящегося на i-той позиции.\n",
    "\n",
    "*IDCG* — идеальное (наибольшее из возможных) значение *DCG*, может быть получено путем ранжирования документов по убыванию асессорских оценок.\n",
    "\n",
    "Итоговая формула для расчета *nDCG*:\n",
    "\n",
    "$$nDCG = \\frac{DCG}{IDCG} \\in [0, 1].$$\n",
    "\n",
    "Чтобы оценить значение *nDCG* на выборке $Queries$ ($nDCG_{Queries}$) размера $N$, необходимо усреднить значение *nDCG* по всем запросам  выборки:\n",
    "$$nDCG_{Queries} = \\frac{1}{N}\\sum_{q \\in Queries}nDCG(q).$$\n",
    "\n",
    "Пример реализации метрик ранжирование на python можно найти [здесь](https://gist.github.com/mblondel/7337391)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках нашей задачи «документом» будет являться организация.\n",
    "\n",
    "Разбейте обучающую выборку на обучение и контроль в соотношении 70 / 30. Обратите внимание, что разбивать необходимо множество запросов, а не строчки датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Далее рассмотрим несколько подходов предсказания релевантности. Для оценивания качества моделей используйте метрику nDCG на контроле. В случае подбора гиперпараметров используйте кросс-валидацию по 5 блокам, где разбиение должно быть по запросам, а не строчкам датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ранжируем с XGBoost и CatBoost\n",
    "\n",
    "XGBoost имеет несколько функций потерь для решения задачи ранжирования:\n",
    "1. **reg:linear** — данную функцию потерь можно использовать для решения задачи ранжирование *pointwise* подходом.\n",
    "2. **rank:pairwise** — в качестве *pairwise* модели в XGBoost реализован [RankNet](http://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf), в котором минимизируется гладкий функционал качества ранжирования: $$ Obj = \\sum_{i \\prec j} \\mathcal{L}\\left(a(x_j) - a(x_i)\\right) \\rightarrow min $$ $$ \\mathcal{L}(M) = log(1 + e^{-M}), $$ где $ a(x) $ - функция ранжирования. Суммирование ведется по всем парам объектов, для которых определено отношение порядка, например, для пар документов, показанных по одному запросу. Таким образом функция потерь штрафует за то, что пара объектов неправильно упорядочена.\n",
    "3. **rank:map, rank:ndcg** — реализация [LambdaRank](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf) для двух метрик: [MAP](https://en.wikipedia.org/wiki/Information_retrieval#Mean_average_precision) и **nDCG**. Известно, что для того, чтобы оптимизировать негладкий функционал, такой как **nDCG**,  нужно домножить градиент функционала $ Obj(a) $ на значение $\\Delta NDCG_{ij} $ — изменение значения функционала качества при замене $x_i$ на $ x_j$.  Поскольку для вычисления метрик необходимы все объекты выборки, то эти две ранжирующие функции потерь являются представителями класса *listwise* моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализованные в CatBoost ранжирующие функции потерь можной найти [здесь](https://catboost.ai/docs/concepts/loss-functions-ranking.html#groupwise-metrics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 балла) Задание 10.** Попробуйте различные функции потерь (регрессионные и ранжирующие) для моделей XGBoost и CatBoost. Настройте основные параметры моделей (глубина, кол-во деревьев, глубина, скорость обучения, регуляризация).  \n",
    "Сравните построенные модели с точки зрения метрики nDCG на контроле и проанализируйте полученные результаты:\n",
    "  - какая модель работает лучше всего для данной задачи? \n",
    "  - в чем достоинства/недостатки каждой? \n",
    "  - сравните модели между собой: \n",
    "   - получается ли сравнимое качество линейного pointwise подхода с остальными моделями? \n",
    "   - заметна ли разница в качестве при использовании бустинга с разными функциями потерь?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**(1 балл) Задание 11.** Одним из основных преимуществ CatBoost'a является обработка категориальных факторов «из коробки». Добавьте в датасет различные категориальные факторы из данных и обучите заново CatBoost модели. Улучшилось ли качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пользовательская функция потерь\n",
    "\n",
    "Библиотека XGBoost позволяет использовать пользовательские функции потерь. Для этого необходимо реализовать функцию, принимающую на вход вектор предсказанных значений и обучающую выборку, и возвращающую градиент и гессиан, посчитанный по входным данным.\n",
    "\n",
    "Важно отметить, что XGBoost использует диагональную аппроксимацию гессиана, таким образом все недиагональные элементы считаются малозначимыми и приравниваются нулю, поэтому и градиент, и гессиан являются векторами длины размера обучающей выборки.\n",
    "\n",
    "**(3 балла) Задание 12.** Реализуйте экспоненциальную функцию потерь для XGBoost:\n",
    "$$ Obj = \\sum_{i \\prec j} \\mathcal{L}\\left(a(x_j) - a(x_i)\\right) \\rightarrow min $$ $$ \\mathcal{L}(M) = e^{-M} $$\n",
    "\n",
    "Обучите модель с помощью данной функции потерь, настройте параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарии к реализации**\n",
    "\n",
    "В случае ранжирования XGBoost'у необходимо знать о разбиении всех объектов на группы. В нашем случае в одну группу будут входить документы, соответствующие одному запросу. Функция, считающая градиент и гессиан по данным, должна знать данное разбиение датасета. Однако питоновский интерфейс класса *DMatrix* (в котором хранится датасет) не дает возможности получить это разбиение. В этом случае нужно реализовать функцию потерь в качестве функтора, конструктор которого принимает разбиение на группы в качестве параметра.\n",
    "\n",
    "Пример реализации своей функции потерь можно найти на соответствующем семинаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialPairwiseLoss(object):\n",
    "    def __init__(self, groups):\n",
    "        self.groups = groups\n",
    "                        \n",
    "    def __call__(self, preds, dtrain):\n",
    "        # your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 13.** С помощью наилучшей из получившихся в ходе лабораторной работы моделей сделайте предсказания для тестовой части выборки и отправьте их на kaggle. В отдельной ячейке выпишите получившийся результат (NDCG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом лабораторная часть задания закончена. Далее - конкурсная часть. Вы можете решать его прямо здесь или в отдельном ноутбуке. Эта часть работы проверяется только у решений, попавших в топ в лидерборде.\n",
    "Если решать конкурс в отдельном ноутбуке удобнее, можете выложить его в энитаск рядом с решением лабораторной.\n",
    "\n",
    "Удачи!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кратко опишите, как вы добились такого результата. Расскажите, что успели попробовать и что из этого сработало."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого, можете оставить отзыв о лабораторно-конкурсном задании :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

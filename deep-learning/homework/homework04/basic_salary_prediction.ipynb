{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","version":"3.7.7","file_extension":".py"},"colab":{"name":"homework_salary_prediction.ipynb","provenance":[],"collapsed_sections":["xIQFst_EqvTo","VqeYF-CVqvTy"],"toc_visible":true},"notebookId":"49bddb10-970d-4edb-bc5d-2c7a5ed94f37"},"cells":[{"cell_type":"markdown","source":"# Natural Language Processing with Deep Learning\n\nToday we're gonna apply the newly learned DL tools for sequence processing to the task of predicting job salary.\n\nSpecial thanks to [Oleg Vasilev](https://github.com/Omrigan/) for the assignment core (orignally written for theano/tensorflow).","metadata":{"id":"GzvkKmYmqvR9","cellId":"btz96k4ihks2h94x71n4k"}},{"cell_type":"markdown","source":"","metadata":{"id":"YnkokJInWYDD","cellId":"m9ud368pyqqnrsay9jww"}},{"cell_type":"code","source":"#!g1.1\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"id":"fBxKERcRqvR_","cellId":"gkbvxug5q6tqvcfaelhv4","trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### About the challenge\nFor starters, let's download the data from __[here](https://yadi.sk/d/vVEOWPFY3NruT7)__.\n\nYou can also get it from the competition [page](https://www.kaggle.com/c/job-salary-prediction/data) (in that case, pick `Train_rev1.*`).\n\n\nOur task is to predict one number, __SalaryNormalized__, in the sense of minimizing __Mean Absolute Error__.\n\n<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3342/media/salary%20prediction%20engine%20v2.png\" width=400px>\n\nTo do so, our model ca access a number of features:\n* Free text: __`Title`__ and  __`FullDescription`__\n* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__.\n\n\nYou can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description).","metadata":{"id":"n3hr5GHtqvSD","cellId":"bwrgnpk8k4fnv2ylh4e9k"}},{"cell_type":"code","source":"#!g1.1\n!curl -L https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1 -o Train_rev1.csv.tar.gz\n!tar -xvzf ./Train_rev1.csv.tar.gz","metadata":{"id":"erQ8HlprvRiu","cellId":"q9s2xgtndeg1zyhlte1mrw","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n100  119M  100  119M    0     0  14.1M      0  0:00:08  0:00:08 --:--:-- 19.2M\nTrain_rev1.csv\n"}],"execution_count":2},{"cell_type":"code","source":"#!g1.1\ndata = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\ndata['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n\ntext_columns = [\"Title\", \"FullDescription\"]\ncategorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\ntarget_column = \"Log1pSalary\"\ndata[categorical_columns] = data[categorical_columns].fillna('NaN') # cast nan to string\n\ndata.sample(3)","metadata":{"id":"BX4XbCJTqvSE","cellId":"2xg39cwvtsmf7el90tmwv5","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"              Id                                  Title  \\\n35159   68234257  Chef de Partie  up to ****k  Cheshire   \n123010  69955553           Administrator/Doc Controller   \n169144  71337145      Qualified Social Worker  Adoption   \n\n                                          FullDescription  \\\n35159   Chef de Partie – up to ****k – **** star hotel...   \n123010  Administrator/Doc Controller Admin Possible te...   \n169144  My client is currently recruiting a Adoption S...   \n\n                                            LocationRaw LocationNormalized  \\\n35159                       Chester Cheshire North West            Chester   \n123010                                           Oxford             Oxford   \n169144  South West London, Greater London, South London             London   \n\n       ContractType ContractTime          Company  \\\n35159           NaN          NaN  HTE Recruitment   \n123010    full_time          NaN              NaN   \n169144          NaN          NaN          Synergy   \n\n                           Category  \\\n35159   Hospitality & Catering Jobs   \n123010                   Admin Jobs   \n169144             Social work Jobs   \n\n                                                SalaryRaw  SalaryNormalized  \\\n35159   Up to 17,000 per annum plus tips and cheap liv...             17000   \n123010                     15,000.00 - 20,000.00 per year             17500   \n169144                             23.00 - 26.00 per hour             47040   \n\n                      SourceName  Log1pSalary  \n35159                caterer.com     9.741028  \n123010            Jobcentre Plus     9.770013  \n169144  jobs.communitycare.co.uk    10.758775  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Title</th>\n      <th>FullDescription</th>\n      <th>LocationRaw</th>\n      <th>LocationNormalized</th>\n      <th>ContractType</th>\n      <th>ContractTime</th>\n      <th>Company</th>\n      <th>Category</th>\n      <th>SalaryRaw</th>\n      <th>SalaryNormalized</th>\n      <th>SourceName</th>\n      <th>Log1pSalary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>35159</th>\n      <td>68234257</td>\n      <td>Chef de Partie  up to ****k  Cheshire</td>\n      <td>Chef de Partie – up to ****k – **** star hotel...</td>\n      <td>Chester Cheshire North West</td>\n      <td>Chester</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>HTE Recruitment</td>\n      <td>Hospitality &amp; Catering Jobs</td>\n      <td>Up to 17,000 per annum plus tips and cheap liv...</td>\n      <td>17000</td>\n      <td>caterer.com</td>\n      <td>9.741028</td>\n    </tr>\n    <tr>\n      <th>123010</th>\n      <td>69955553</td>\n      <td>Administrator/Doc Controller</td>\n      <td>Administrator/Doc Controller Admin Possible te...</td>\n      <td>Oxford</td>\n      <td>Oxford</td>\n      <td>full_time</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Admin Jobs</td>\n      <td>15,000.00 - 20,000.00 per year</td>\n      <td>17500</td>\n      <td>Jobcentre Plus</td>\n      <td>9.770013</td>\n    </tr>\n    <tr>\n      <th>169144</th>\n      <td>71337145</td>\n      <td>Qualified Social Worker  Adoption</td>\n      <td>My client is currently recruiting a Adoption S...</td>\n      <td>South West London, Greater London, South London</td>\n      <td>London</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Synergy</td>\n      <td>Social work Jobs</td>\n      <td>23.00 - 26.00 per hour</td>\n      <td>47040</td>\n      <td>jobs.communitycare.co.uk</td>\n      <td>10.758775</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Classic NLP approach (70%)","metadata":{"id":"5oLpavXfWZm0","cellId":"jqa2ml1iwzfja4x4dnvibt"}},{"cell_type":"markdown","source":"### The NLP part\n\nTo even begin training our neural network, we're gonna need to preprocess the text features: tokenize it and build the token vocabularies.\n\nSince it is not an NLP course, we're gonna use simple built-in NLTK tokenization.","metadata":{"id":"nRBrD1Y5qvSI","cellId":"lylvz2ejdgfofsa5h62hc"}},{"cell_type":"code","source":"#!g1.1\nprint(\"Before\")\nprint(data[\"Title\"][::100000])","metadata":{"id":"fIFfYy_qqvSI","cellId":"jl42895fgojijkfbxhjm8s","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Before\n0         engineering systems analyst\n100000                   hr assistant\n200000         senior ec & i engineer\nName: Title, dtype: object\n"}],"execution_count":7},{"cell_type":"code","source":"#!g1.1\nimport nltk\ntokenizer = nltk.tokenize.WordPunctTokenizer()\n\nfor col in text_columns:\n    data[col] = data[col].apply(lambda l: ' '.join(tokenizer.tokenize(str(l).lower())))","metadata":{"id":"wlatIonOqvSL","cellId":"rhaemq5m15agtpe7wwg0er","trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Now we can assume that our text is a space-separated list of tokens:","metadata":{"id":"sipmsYCjqvSP","cellId":"jvp5egxnghjnk2yxtdt0rk"}},{"cell_type":"code","source":"#!g1.1\nprint(\"After\")\nprint(data[\"Title\"][::100000])","metadata":{"id":"aLNAM4WhqvSP","cellId":"b7uqsxtmajp123wahfle6ha","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"After\n0         engineering systems analyst\n100000                   hr assistant\n200000         senior ec & i engineer\nName: Title, dtype: object\n"}],"execution_count":9},{"cell_type":"code","source":"#!g1.1\ndata[\"Title\"][:100]","metadata":{"id":"_1VI-3uAwPRr","cellId":"z93gevtsdobc16pxl9vxgb","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"0                           engineering systems analyst\n1                               stress engineer glasgow\n2                      modelling and simulation analyst\n3     engineering systems analyst / mathematical mod...\n4           pioneer , miser engineering systems analyst\n                            ...                        \n95    chef de parties required nationwide many with ...\n96       chef de partie norfolk live in up to **** tips\n97                      plastic extrusion setter nights\n98    assistant manager suffolk coastal restaurant ****\n99                              cluster revenue manager\nName: Title, Length: 100, dtype: object"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"Not all words are equally useful. Some of them are typos or rare words that are only present a few times. \n\nLet's see how many times is each word present in the data so that we can build a \"white list\" of known words.","metadata":{"id":"kLxwLMIbqvSS","cellId":"cxwp7z14ej98dahn8ch9no"}},{"cell_type":"code","source":"#!g1.1\nfrom collections import Counter\ntoken_counts = Counter()\n\n# Count how many times does each token occur in \"Title\" and \"FullDescription\"\nfor col in text_columns:\n    data[col].apply(lambda x:  token_counts.update(x.split()))","metadata":{"id":"Fl5cF_U4qvST","cellId":"s0cl63vzf4qdkh2me5dk","trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"#!g1.1\nprint(\"Total unique tokens :\", len(token_counts))\nprint('\\n'.join(map(str, token_counts.most_common(n=5))))\nprint('...')\nprint('\\n'.join(map(str, token_counts.most_common()[-3:])))\n\nassert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\nassert len(token_counts) in range(200000, 210000)\nprint('Correct!')","metadata":{"id":"NGcGvrxFqvSX","cellId":"4i4d8zqnj7w7max3c383pu","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Total unique tokens : 202704\n('and', 2657388)\n('.', 2523216)\n(',', 2318606)\n('the', 2080994)\n('to', 2019884)\n...\n('stephanietraveltraderecruitmnt', 1)\n('ruabon', 1)\n('lowehays', 1)\nCorrect!\n"}],"execution_count":12},{"cell_type":"code","source":"#!g1.1\n# Let's see how many words are there for each count\n\n_ = plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\nplt.xlabel(\"Counts\")","metadata":{"id":"jAqKkwaJqvSb","cellId":"cdwo21hlhvja7burklvv0b","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Text(0.5, 0, 'Counts')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}],"execution_count":13},{"cell_type":"markdown","source":"__Task 1.1__ Get a list of all tokens that occur at least 10 times.","metadata":{"id":"GHeZWlBnqvSe","cellId":"va0fa9hvso3wwcnz0a5lg"}},{"cell_type":"code","source":"#!g1.1\nmin_count = 10\n\n# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\ntokens = [token for token, count in token_counts.items() if count >= 10]\n\n# Add a special tokens for unknown and empty words\nUNK, PAD = \"UNK\", \"PAD\"\ntokens = [UNK, PAD] + tokens","metadata":{"id":"zBjh1JC9qvSf","cellId":"71bfvifrm95kenya72gfx","trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"#!g1.1\nprint(\"Tokens left:\", len(tokens))\nassert type(tokens)==list\nassert len(tokens) in range(32000,35000)\nassert 'me' in tokens\nassert UNK in tokens\nprint(\"Correct!\")","metadata":{"id":"DdrV4T5KqvSi","cellId":"1dv3wr8bwhgvpkrwgywae","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Tokens left: 34158\nCorrect!\n"}],"execution_count":22},{"cell_type":"markdown","source":"__Task 1.2__ Build an inverse token index: a dictionary from token(string) to it's index in `tokens` (int)","metadata":{"id":"SNy9AjWkqvSl","cellId":"65za57rry15fak37reoa0k"}},{"cell_type":"code","source":"#!g1.1\ntoken_to_id = {token: idx for idx, token in enumerate(tokens)}","metadata":{"id":"_LIcNamYqvSl","cellId":"zmy89rmvx2juy7xqxzmev","trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"#!g1.1\nassert isinstance(token_to_id, dict)\nassert len(token_to_id) == len(tokens)\nfor tok in tokens:\n    assert tokens[token_to_id[tok]] == tok\n\nprint(\"Correct!\")","metadata":{"id":"wjnCyHxzqvSo","cellId":"8q1ho1hq38f8plydy22ooi","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Correct!\n"}],"execution_count":28},{"cell_type":"markdown","source":"And finally, let's use the vocabulary you've built to map text lines into torch-digestible matrices.","metadata":{"id":"X7Z5IwdnqvSr","cellId":"ixu6rlykcgid3je34o1rm"}},{"cell_type":"code","source":"#!g1.1\nUNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n\ndef as_matrix(sequences, max_len=None):\n    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n    if isinstance(sequences[0], str):\n        sequences = list(map(str.split, sequences))\n        \n    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n    \n    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n    for i,seq in enumerate(sequences):\n        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n        matrix[i, :len(row_ix)] = row_ix\n    \n    return matrix","metadata":{"id":"ftC7VjgGqvSr","cellId":"qn7f8rszfrheh18a2uujya","trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"#!g1.1\n#### print(\"Lines:\")\nprint('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\nprint(\"Matrix:\")\nprint(as_matrix(data[\"Title\"][::100000]))","metadata":{"id":"0BoZ4DEuqvSu","cellId":"dcz3yilgnfj3q2m4kp9s8","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"engineering systems analyst\nhr assistant\nsenior ec & i engineer\n\nMatrix:\n[[   2    3    4    1    1]\n [ 998  176    1    1    1]\n [  18 3472  242   59    6]]\n"}],"execution_count":30},{"cell_type":"markdown","source":"Now let's  encode the categirical data we have.\n\nAs usual, we shall use one-hot encoding for simplicity. Kudos if you implement tf-idf, target averaging or pseudo-counter-based encoding.","metadata":{"id":"Xitpa_noqvSx","cellId":"2855bcmflvnbo93gsgr1gl"}},{"cell_type":"code","source":"#!g1.1\nfrom sklearn.feature_extraction import DictVectorizer\n\n# we only consider top-1k most frequent companies to minimize memory usage\ntop_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\nrecognized_companies = set(top_companies)\ndata[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n\ncategorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\ncategorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))","metadata":{"id":"9JV0wIC0qvSy","cellId":"amtqltb9y0qm9cr9n1u7","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n               sparse=False)"},"metadata":{}}],"execution_count":31},{"cell_type":"markdown","source":"### The data science part\n\nOnce we've learned to tokenize the data, let's design a machine learning experiment.\n\nAs before, we won't focus too much on validation, opting for a simple train-test split.\n\n__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.","metadata":{"id":"6BDrlWJyqvS1","cellId":"9yuw9norcu6g6nuff0tnl"}},{"cell_type":"code","source":"#!g1.1\nfrom sklearn.model_selection import train_test_split\n\ndata_train, data_val = train_test_split(data, test_size=0.1, random_state=42)\n\nprint(\"Train size = \", len(data_train))\nprint(\"Validation size = \", len(data_val))","metadata":{"id":"Na1xwCjBqvS2","cellId":"mzxoxnp87zeq69pq067f9","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Train size =  220291\nValidation size =  24477\n"}],"execution_count":32},{"cell_type":"code","source":"#!g1.1\ndef generate_batch(data, batch_size=None, replace=True, max_len=None):\n    \"\"\"\n    Creates a pytorch-friendly dict from the batch data.\n    :returns: a dict with {'title' : int64[batch, title_max_len]\n    \"\"\"\n    if batch_size is not None:\n        data = data.sample(batch_size, replace=replace)\n    \n    batch = {}\n    for col in text_columns:\n        batch[col] = as_matrix(data[col].values, max_len)\n    \n    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n    \n    if target_column in data.columns:\n        batch[target_column] = data[target_column].values\n    \n    return batch","metadata":{"id":"fr6utl2ZqvS5","cellId":"4cxa5bu3x5elf7ivtstck","trusted":true},"outputs":[],"execution_count":33},{"cell_type":"code","source":"#!g1.1\ngenerate_batch(data_train, 3, max_len=10)","metadata":{"id":"M9xauh7qqvS7","cellId":"6seje7vt3vdorowtw7yn6","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"{'Title': array([[1911, 1937,  418,  176],\n        [1569,   94,    0,  989],\n        [ 998,  101, 1386,    1]], dtype=int32),\n 'FullDescription': array([[ 3199,   558,   944,    73, 11885,    86, 10767,   561,  1491,\n          1394],\n        [ 1569,    94,   160,  2096,    74,    74,  1827,  2977,  3162,\n          3057],\n        [   55,   110,  1433,   971,  1824,  2497,   998,   101,  1386,\n          2133]], dtype=int32),\n 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n 'Log1pSalary': array([ 9.431963,  9.711176, 10.532123], dtype=float32)}"},"metadata":{}}],"execution_count":87},{"cell_type":"markdown","source":"### Finally, let's talk deep learning\n\nOut model consists of three branches:\n* Title encoder\n* Description encoder\n* Categorical features encoder\n\nWe will then feed all 3 branches into one common network that predicts salary.\n\n![scheme](https://github.com/yandexdataschool/Practical_DL/raw/master/homework04/conv_salary_architecture.png)","metadata":{"id":"724cWq4QqvS-","cellId":"rwo80hl4sqczixod4uq6ut"}},{"cell_type":"markdown","source":"By default, both text vectorizers shall use 1d convolutions, followed by global pooling over time.","metadata":{"id":"cGHY01rvqvS_","cellId":"8ih7zr3q2erqrzddnkka9s"}},{"cell_type":"code","source":"#!g1.1\nimport torch, torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nclass GlobalMaxPooling(nn.Module):\n    def __init__(self, dim=-1):\n        super(self.__class__, self).__init__()\n        self.dim = dim\n        \n    def forward(self, x):\n        return x.max(dim=self.dim)[0]","metadata":{"id":"sT28uefUqvS_","cellId":"4ysta7y2j125d306jkeiu","trusted":true},"outputs":[],"execution_count":88},{"cell_type":"code","source":"#!g1.1\nclass TitleEncoder(nn.Module):\n    def __init__(self, n_tokens=len(tokens), out_size=64):\n        \"\"\" \n        A simple sequential encoder for titles.\n        x -> emb -> conv -> global_max -> relu -> dense\n        \"\"\"\n        super(self.__class__, self).__init__()\n        self.emb = nn.Embedding(num_embeddings=n_tokens, embedding_dim=256, padding_idx=PAD_IX)\n        self.conv = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, padding=1)\n        self.global_max = GlobalMaxPooling()\n        self.dense = nn.Linear(128, out_size)\n\n    def forward(self, text_ix):\n        \"\"\"\n        :param text_ix: int64 Variable of shape [batch_size, max_len]\n        :returns: float32 Variable of shape [batch_size, out_size]\n        \"\"\"\n        h = self.emb(text_ix)\n        # we transpose from [batch, time, units] to [batch, units, time] to fit Conv1d dim order\n        h = torch.transpose(h, 1, 2)\n        # Apply the layers as defined above. Add some ReLUs before dense.\n        #YOU CODE HERE\n        h = nn.ReLU()(self.global_max(self.conv(h)))\n        h = self.dense(h)\n        return h","metadata":{"id":"jrFQrz2fqvTC","cellId":"l5h8e1di0hrcib7m4ta9v","trusted":true},"outputs":[],"execution_count":95},{"cell_type":"code","source":"#!g1.1\ntitle_encoder = TitleEncoder(out_size=64)\n\ndummy_x = Variable(torch.LongTensor(generate_batch(data_train, 3)['Title']))\ndummy_v = title_encoder(dummy_x)\n\nassert isinstance(dummy_v, Variable)\nassert tuple(dummy_v.shape) == (dummy_x.shape[0], 64)\n\ndel title_encoder\nprint(\"Seems fine\")","metadata":{"id":"TUk2TXOYqvTE","cellId":"fm59txvo1gi2idta0hgqm","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Seems fine\n"}],"execution_count":96},{"cell_type":"markdown","source":"__Task 2.1__ Create description encoder","metadata":{"id":"hr2vL5lxqvTJ","cellId":"vdv1zn5nqycgwmlh8zlca9"}},{"cell_type":"code","source":"#!g1.1\n# Define an encoder for job descriptions.\n# Use any means you want so long as it's torch.nn.Module.\n# Define an encoder for job descriptions.\n# Use any means you want so long as it's torch.nn.Module.\nclass DescriptionEncoder(nn.Module):\n    def __init__(self, n_tokens=len(tokens), out_size=64):\n        \"\"\" \n        A simple sequential encoder for titles.\n        x -> emb -> conv -> global_max -> relu -> dense\n        \"\"\"\n        super(self.__class__, self).__init__()\n        self.emb = nn.Embedding(num_embeddings=n_tokens, embedding_dim=256, padding_idx=PAD_IX)\n        self.conv = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, padding=1)\n        self.global_max = GlobalMaxPooling()\n        self.dense = nn.Linear(128, out_size)\n\n    def forward(self, text_ix):\n        \"\"\"\n        :param text_ix: int64 Variable of shape [batch_size, max_len]\n        :returns: float32 Variable of shape [batch_size, out_size]\n        \"\"\"\n        #YOU CODE HERE\n        h = self.emb(text_ix)\n        h = torch.transpose(h, 1, 2)\n        h = nn.ReLU()(self.global_max(self.conv(h)))\n        h = self.dense(h)\n        return h","metadata":{"id":"9q133NSaqvTJ","cellId":"xl6ljzki14q4ldj279ke9","trusted":true},"outputs":[],"execution_count":98},{"cell_type":"code","source":"#!g1.1\ndesc_encoder = DescriptionEncoder()\n\ndummy_x = Variable(torch.LongTensor(generate_batch(data_train, 3)['FullDescription']))\ndummy_v = desc_encoder(dummy_x)\n\nassert isinstance(dummy_v, Variable)\nassert tuple(dummy_v.shape) == (dummy_x.shape[0], 64)\ndel desc_encoder\nprint(\"Seems fine too\")","metadata":{"id":"tigZAXWDqvTN","cellId":"ds7d5ojeepecgv4f56u5uh","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Seems fine too\n"}],"execution_count":99},{"cell_type":"markdown","source":"__Task 2.2__ Build one network ~~to rule them all~~","metadata":{"id":"_eQZ5AEBqvTP","cellId":"937wlnl3zu6vego6oo6t3o"}},{"cell_type":"code","source":"#!g1.1\nclass FullNetwork(nn.Module):\n    \"\"\"\n    This class does all the steps from (title, desc, categorical) features -> predicted target\n    It unites title & desc encoders you defined above as long as some layers for head and categorical branch.\n    \"\"\"\n    \n    def __init__(self, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_)):\n        super(self.__class__, self).__init__()\n        \n        self.title_encoder = TitleEncoder(out_size=64)\n        self.desc_encoder = DescriptionEncoder(out_size = 64)\n        \n        self.categ_dense1 = nn.Linear(n_cat_features, 512)\n        self.categ_dense2 = nn.Linear(512, 128)\n        \n        # define \"output\" layers that process depend the three encoded vectors into answer\n        self.dense1 = nn.Linear(256, 128)\n        self.dense2 = nn.Linear(128, 100)\n        self.dense3 = nn.Linear(100, 64)\n        \n        \n        \n    def forward(self, title_ix, desc_ix, cat_features):\n        \"\"\"\n        :param title_ix: int32 Variable [batch, title_len], job titles encoded by as_matrix\n        :param desc_ix:  int32 Variable [batch, desc_len] , job descriptions encoded by as_matrix\n        :param cat_features: float32 Variable [batch, n_cat_features]\n        :returns: float32 Variable 1d [batch], predicted log1p-salary\n        \"\"\"\n        \n        title_h = self.title_encoder(title_ix)\n        desc_h = self.desc_encoder(desc_ix)\n        \n        # apply categorical encoder\n        #YOU CODE HERE\n        cat_h = nn.ReLU()(self.categ_dense1(cat_features))\n        cat_h = nn.ReLU()(self.categ_dense2(cat_h))        \n        \n        # concatenate all vectors together...\n        joint_h = torch.cat([title_h, desc_h, cat_h], dim=1)\n        \n        # ... and stack a few more layers at the top\n        #YOU CODE HERE\n        joint_h = nn.ReLU()(self.dense1(joint_h))\n        joint_h = nn.ReLU()(self.dense2(joint_h))\n        joint_h = nn.ReLU()(self.dense3(joint_h))\n        \n        # Note 1: do not forget to select first columns, [:, 0], to get to 1d outputs\n        # Note 2: please do not use output nonlinearities.\n        \n        return joint_h[:, 0]","metadata":{"id":"hd874RWcqvTQ","cellId":"kcvm2wiwoyuzsob1xkzsb","trusted":true},"outputs":[],"execution_count":122},{"cell_type":"code","source":"#!g1.1\nmodel = FullNetwork()\nopt = torch.optim.Adam(model.parameters(), lr=1e-3)","metadata":{"id":"j7VSR30DqvTS","cellId":"6kqs4rb2mxsuns6gn7q0eo","trusted":true},"outputs":[],"execution_count":123},{"cell_type":"code","source":"#!g1.1\n# test it on one batch\n\nbatch = generate_batch(data_train, 32)\n\ntitle_ix = torch.tensor(batch[\"Title\"], dtype=torch.int64)\ndesc_ix = torch.tensor(batch[\"FullDescription\"], dtype=torch.int64)\ncat_features = torch.tensor(batch[\"Categorical\"], dtype=torch.float32)\nreference = torch.tensor(batch[target_column], dtype=torch.float32)\n\nprediction = model(title_ix, desc_ix, cat_features)\n\nassert len(prediction.shape) == 1 and prediction.shape[0] == title_ix.shape[0]","metadata":{"id":"fm8_aY0dqvTU","cellId":"o65p0c08f5wq2zyh1c2ek","trusted":true},"outputs":[],"execution_count":124},{"cell_type":"code","source":"#!g1.1\ndef compute_loss(reference, prediction):\n    \"\"\"\n    Computes objective for minimization.\n    By deafult we minimize MSE, but you are encouraged to try mix up MSE, MAE, huber loss, etc.\n    \"\"\"\n    return torch.mean((prediction - reference) ** 2)\n\ndef compute_mae(reference, prediction):\n    \"\"\" Compute MAE on actual salary, assuming your model outputs log1p(salary)\"\"\"\n    return torch.abs(torch.exp(reference - 1) - torch.exp(prediction - 1)).mean()","metadata":{"id":"9XIo5kwgqvTX","cellId":"f57frxmndl6ehkyl89qfwg","trusted":true},"outputs":[],"execution_count":125},{"cell_type":"code","source":"#!g1.1\nloss = compute_loss(reference, prediction)\ndummy_grads = torch.autograd.grad(loss, model.parameters(), retain_graph=True)\nfor grad in dummy_grads:\n    assert grad is not None and not (grad == 0).all(), \"Some model parameters received zero grads. \" \\\n                                                       \"Double-check that your model uses all it's layers.\"","metadata":{"id":"GqdVvPTIqvTZ","cellId":"5tslhphgostra504oq0ff","trusted":true},"outputs":[],"execution_count":126},{"cell_type":"markdown","source":"### Let's train it!","metadata":{"id":"dnuL5_VPqvTc","cellId":"8m9c3n21sdsemv8ablxy2j"}},{"cell_type":"code","source":"#!g1.1\nfrom tqdm import tnrange\ndef iterate_minibatches(data, batch_size=32, max_len=None,\n                        max_batches=None, shuffle=True, verbose=True):\n    indices = np.arange(len(data))\n    if shuffle:\n        indices = np.random.permutation(indices)\n    if max_batches is not None:\n        indices = indices[: batch_size * max_batches]\n        \n    irange = tnrange if verbose else range\n    \n    for start in irange(0, len(indices), batch_size):\n        yield generate_batch(data.iloc[indices[start : start + batch_size]], max_len=max_len)","metadata":{"id":"7w-qhITFqvTc","cellId":"5nry5vt2do67oaskg80l0q","trusted":true},"outputs":[],"execution_count":127},{"cell_type":"code","source":"#!g1.1\nnum_epochs = 100\nmax_len = 100\nbatch_size = 32\nbatches_per_epoch = 100","metadata":{"id":"s95CY9_RqvTf","cellId":"flyawt5kdr6q0en5cdtgc9","trusted":true},"outputs":[],"execution_count":128},{"cell_type":"code","source":"#!g1.1\nfor epoch_i in range(num_epochs):\n    \n    print(\"Training:\")\n    train_loss = train_mae = train_batches = 0    \n    model.train(True)\n    \n    for batch in iterate_minibatches(data_train, max_batches=batches_per_epoch):\n        title_ix = torch.tensor(batch[\"Title\"], dtype=torch.int64)\n        desc_ix = torch.tensor(batch[\"FullDescription\"], dtype=torch.int64)\n        cat_features = torch.tensor(batch[\"Categorical\"], dtype=torch.float32)\n        reference = torch.tensor(batch[target_column], dtype=torch.float32)\n\n        prediction = model(title_ix, desc_ix, cat_features)\n#         print(prediction[:3])\n#         print(reference[:3])\n        loss = compute_loss(reference, prediction)\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n\n        train_loss += loss.data.numpy()\n        train_mae += compute_mae(reference, prediction).data.numpy()\n        train_batches += 1\n    \n    print(\"\\tLoss:\\t%.5f\" % (train_loss / train_batches))\n    print(\"\\tMAE:\\t%.5f\" % (train_mae / train_batches))\n    print('\\n\\n')\n    \n    print(\"Validation:\")\n    val_loss = val_mae = val_batches = 0\n    model.train(False)\n    \n    for batch in iterate_minibatches(data_val, shuffle=False):\n        title_ix = torch.tensor(batch[\"Title\"], dtype=torch.int64)\n        desc_ix = torch.tensor(batch[\"FullDescription\"], dtype=torch.int64)\n        cat_features = torch.tensor(batch[\"Categorical\"], dtype=torch.float32)\n        reference = torch.tensor(batch[target_column], dtype=torch.float32)\n        prediction = model(title_ix, desc_ix, cat_features)\n        loss = compute_loss(reference, prediction)\n\n        val_loss += loss.data.numpy()\n        val_mae += compute_mae(reference, prediction).data.numpy()\n        val_batches += 1\n        \n    print(\"\\tLoss:\\t%.5f\" % (val_loss / val_batches))\n    print(\"\\tMAE:\\t%.5f\" % (val_mae / val_batches))\n    print('\\n\\n')","metadata":{"id":"T0s7Mbp8qvTi","execution_id":"04bf712e-19c5-41f6-8a4e-19bf23403983","cellId":"guc5tr0ykvekm4j256r39","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:12: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n  import os\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82cfddbe17dd4e77963d7e5a488530c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e37977fc6e854c91be076e2655b63f10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a34f24d851ee4aacb1cdd5984ef6d75f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d36aae2e937a4d50beeadbaa31752242"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f876b31f25de4ff1b363be93d102c7b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8aaf18e7ab7b4a79858978762c202f41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c5ca8901a69450bb1d8972db8fe5388"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8af0336a30834b0cb437d620027f1cc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4b0d4126da843559dddf19354f890cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c296fb4f4ac4346853e0ea4639c4951"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fa0ef0e67ea40cca17b450ecdcfa59b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"562ccecd256946b19fdf67b061518838"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e01e788bbe14e048f211345e92b12d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6aed8c410d14231bc7d8752ba7baef4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d82a3af9155e4350a816e86971c1be73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03c2e57fc451496ebbc360571328387a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6c977a2064f43d1a049e16aed35cf07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79d0eb25e6bd44f3957d0cd4a2ea08e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee17899713c6431ea8b65ea0643e3c10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61cde76e1b86433fbc23bcbb5dc3309c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5049e2f728245c591e3b62942cefda5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"438201a84fa04146bc13c03776d151f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d135e8336b81479aa1165a37e2e3aeab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fed7c7641f54691bcdcd470a6189ffd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb123944361442d69fbcbe9205700c49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ce58237e294be781b7e295c2104041"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5738821a6124361b1162fd9d66d33db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e80c33a8445d48c9a6b4060a142c1307"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"213d1a9b901f42ff87daa587423a439c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d92e4ea27814a55bdd30952ce415ad3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b422c2faf5a04b348d8223a473a18fa4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e0924a8e43d47028410bf6cc9896e2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d1487d537c243e69951aec8eef6b97b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64f4fee80a3c4bef81beb5dcc6602e00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c7c7395eee948afa2d78d07e2e5a927"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"868196b3a0d445999db1bbd8bd4146a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e14636e61afe4754aba4c52be9fb916c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a14221b1daa84bf1bd5f154f73b30863"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acf8906199e942509c153cea27846b90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f296ecfde27f475f94447ca2f8659187"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8279e87b29d426f868998516ab46eb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac78818766e9433494a96bac06afeaa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ce5ea0bf22041e786ab5dee82100504"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d232ef8ca69e44a899d20fa313ceed88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6fe0af0f7354f05859e768670d5eee5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3fd923be77546739ebb13709d622165"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e92d5ff5c799468d938d9e43ae18fc9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a03056a64b645fd9e9d5c0b62e44d27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f77fc1f720c44d99d65fe4444351139"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b76fc2a1e581491d9acd5ae49380c636"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0187c82897fc438aac8556a0039fc885"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fe0c345405848b983fa5cf2146e2d73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78d8ab63d63644b6b2412bae7631d1cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"001b1e97425d447db6ccfc0355edcb2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bdcc946ce8644639132f2da93bd0b70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"291d06c3cd89496b83ad85928d18d8ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b8039624b5444f984a2f8c375f6efcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37fc6cbac1c440469be3b1afaff14420"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08b23d61d9874ece94ee2fc6cafacc57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce736f2c810245068973bb35d46ffb49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"314e638b5b8946a8ad99d0ab24d24d0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9074a05f6dbd4fc7940cdf419e43b3f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12c6082bcf77430ca10b1e9dbc91906a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00ace59eb8a64109bbb734286611a526"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d09557ec57734e3fae6947112dde3b0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"445101754b6b432ca93278c619e09edd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af340eaf79f482dad7447d04253314a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f2421eb809841849fb8c40a82aa567e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38cde98e69514994bd9e0b9bb228af38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da05638787e94bf68db2c424b823c1a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f7d0c927bad4d08a243857453b9304f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88865198a2e6410494a3574b8f63b1b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fadfa0b99224470a89016d23d906054"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98689efbc9fc47438c6e7579af32ce1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba83f79af3b449e589ba24150b00af46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bec0ffd2bbb440f4b02570f626dce0de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75d47a88c31141eb8b8f88b92917685a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b3e28fa79694ab08756ed0f4ac4c051"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d67728221cb44ff5b6c05a1836b3cf3b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"Training:\n\n\tLoss:\t21.59133\n\tMAE:\t67436.76451\n\n\n\nValidation:\n\n\tLoss:\t0.59571\n\tMAE:\t5941.75549\n\n\n\nTraining:\n\n\tLoss:\t0.42370\n\tMAE:\t5836.97553\n\n\n\nValidation:\n\n\tLoss:\t0.34870\n\tMAE:\t5656.94859\n\n\n\nTraining:\n\n\tLoss:\t0.29217\n\tMAE:\t4907.73334\n\n\n\nValidation:\n\n\tLoss:\t0.29068\n\tMAE:\t5220.50341\n\n\n\nTraining:\n\n\tLoss:\t0.27963\n\tMAE:\t4738.64593\n\n\n\nValidation:\n\n\tLoss:\t0.28924\n\tMAE:\t4375.95423\n\n\n\nTraining:\n\n\tLoss:\t0.25048\n\tMAE:\t4636.85185\n\n\n\nValidation:\n\n\tLoss:\t0.21915\n\tMAE:\t4464.05179\n\n\n\nTraining:\n\n\tLoss:\t0.23194\n\tMAE:\t4418.30160\n\n\n\nValidation:\n\n\tLoss:\t0.20206\n\tMAE:\t4270.59404\n\n\n\nTraining:\n\n\tLoss:\t0.19524\n\tMAE:\t3941.87349\n\n\n\nValidation:\n\n\tLoss:\t0.18311\n\tMAE:\t3816.83471\n\n\n\nTraining:\n\n\tLoss:\t0.19322\n\tMAE:\t4035.42668\n\n\n\nValidation:\n\n\tLoss:\t0.17144\n\tMAE:\t3682.30059\n\n\n\nTraining:\n\n\tLoss:\t0.19457\n\tMAE:\t4049.53688\n\n\n\nValidation:\n\n\tLoss:\t0.21650\n\tMAE:\t5027.98472\n\n\n\nTraining:\n\n\tLoss:\t0.17658\n\tMAE:\t3904.31595\n\n\n\nValidation:\n\n\tLoss:\t0.22910\n\tMAE:\t4134.92998\n\n\n\nTraining:\n\n\tLoss:\t0.17229\n\tMAE:\t3939.02496\n\n\n\nValidation:\n\n\tLoss:\t0.15709\n\tMAE:\t3489.30461\n\n\n\nTraining:\n\n\tLoss:\t0.16047\n\tMAE:\t3727.50420\n\n\n\nValidation:\n\n\tLoss:\t0.15151\n\tMAE:\t3786.34803\n\n\n\nTraining:\n\n\tLoss:\t0.15598\n\tMAE:\t3730.57450\n\n\n\nValidation:\n\n\tLoss:\t0.15501\n\tMAE:\t3934.89303\n\n\n\nTraining:\n\n\tLoss:\t0.15185\n\tMAE:\t3677.28730\n\n\n\nValidation:\n\n\tLoss:\t0.25001\n\tMAE:\t5799.42078\n\n\n\nTraining:\n\n\tLoss:\t0.16482\n\tMAE:\t3918.27708\n\n\n\nValidation:\n\n\tLoss:\t0.14182\n\tMAE:\t3372.05705\n\n\n\nTraining:\n\n\tLoss:\t0.15993\n\tMAE:\t3711.18003\n\n\n\nValidation:\n\n\tLoss:\t0.13622\n\tMAE:\t3313.91535\n\n\n\nTraining:\n\n\tLoss:\t0.12659\n\tMAE:\t3350.63848\n\n\n\nValidation:\n\n\tLoss:\t0.12581\n\tMAE:\t3259.05069\n\n\n\nTraining:\n\n\tLoss:\t0.13238\n\tMAE:\t3331.68615\n\n\n\nValidation:\n\n\tLoss:\t0.12340\n\tMAE:\t3223.08183\n\n\n\nTraining:\n\n\tLoss:\t0.14228\n\tMAE:\t3530.89274\n\n\n\nValidation:\n\n\tLoss:\t0.13689\n\tMAE:\t3318.72709\n\n\n\nTraining:\n\n\tLoss:\t0.14101\n\tMAE:\t3660.90462\n\n\n\nValidation:\n\n\tLoss:\t0.12468\n\tMAE:\t3383.13312\n\n\n\nTraining:\n\n\tLoss:\t0.12830\n\tMAE:\t3426.59760\n\n\n\nValidation:\n\n\tLoss:\t0.11658\n\tMAE:\t3226.62627\n\n\n\nTraining:\n\n\tLoss:\t0.13780\n\tMAE:\t3501.56023\n\n\n\nValidation:\n\n\tLoss:\t0.17918\n\tMAE:\t4587.94944\n\n\n\nTraining:\n\n\tLoss:\t0.15041\n\tMAE:\t3748.85992\n\n\n\nValidation:\n\n\tLoss:\t0.11623\n\tMAE:\t3179.13682\n\n\n\nTraining:\n\n\tLoss:\t0.11672\n\tMAE:\t3211.94330\n\n\n\nValidation:\n\n\tLoss:\t0.11383\n\tMAE:\t3208.62405\n\n\n\nTraining:\n\n\tLoss:\t0.12264\n\tMAE:\t3182.77199\n\n\n\nValidation:\n\n\tLoss:\t0.11169\n\tMAE:\t3105.18343\n\n\n\nTraining:\n\n\tLoss:\t0.13644\n\tMAE:\t3621.29448\n\n\n\nValidation:\n\n\tLoss:\t0.13990\n\tMAE:\t3852.57536\n\n\n\nTraining:\n\n\tLoss:\t0.13166\n\tMAE:\t3481.00857\n\n\n\nValidation:\n\n\tLoss:\t0.10957\n\tMAE:\t3044.92009\n\n\n\nTraining:\n\n\tLoss:\t0.13592\n\tMAE:\t3595.15465\n\n\n\nValidation:\n\n\tLoss:\t0.15228\n\tMAE:\t4099.35210\n\n\n\nTraining:\n\n\tLoss:\t0.12349\n\tMAE:\t3339.48750\n\n\n\nValidation:\n\n\tLoss:\t0.14865\n\tMAE:\t3511.52222\n\n\n\nTraining:\n\n\tLoss:\t0.11011\n\tMAE:\t3069.57792\n\n\n\nValidation:\n\n\tLoss:\t0.10866\n\tMAE:\t3133.24312\n\n\n\nTraining:\n\n\tLoss:\t0.12402\n\tMAE:\t3358.71128\n\n\n\nValidation:\n\n\tLoss:\t0.10355\n\tMAE:\t3017.91668\n\n\n\nTraining:\n\n\tLoss:\t0.12535\n\tMAE:\t3396.37219\n\n\n\nValidation:\n\n\tLoss:\t0.10698\n\tMAE:\t3163.06790\n\n\n\nTraining:\n\n\tLoss:\t0.14108\n\tMAE:\t3644.00071\n\n\n\nValidation:\n\n\tLoss:\t0.12126\n\tMAE:\t3159.89324\n\n\n\nTraining:\n\n\tLoss:\t0.11455\n\tMAE:\t3277.85987\n\n\n\nValidation:\n\n\tLoss:\t0.13605\n\tMAE:\t3862.23536\n\n\n\nTraining:\n\n\tLoss:\t0.12680\n\tMAE:\t3354.60456\n\n\n\nValidation:\n\n\tLoss:\t0.21134\n\tMAE:\t5462.18888\n\n\n\nTraining:\n\n\tLoss:\t0.10477\n\tMAE:\t3051.00231\n\n\n\nValidation:\n\n\tLoss:\t0.11967\n\tMAE:\t3540.66576\n\n\n\nTraining:\n\n\tLoss:\t0.11495\n\tMAE:\t3257.91640\n\n\n\nValidation:\n\n\tLoss:\t0.09884\n\tMAE:\t2920.06568\n\n\n\nTraining:\n\n\tLoss:\t0.12078\n\tMAE:\t3336.54837\n\n\n\nValidation:\n\n\tLoss:\t0.10073\n\tMAE:\t2924.07761\n\n\n\nTraining:\n\n\tLoss:\t0.10912\n\tMAE:\t3104.46571\n\n\n\nValidation:\n\n\tLoss:\t0.11650\n\tMAE:\t3131.65289\n\n\n\nTraining:\n\n\tLoss:\t0.11169\n\tMAE:\t3234.39042\n\n\n\nValidation:\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37114638674e45dd9f63d403e1c31459"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\tLoss:\t0.09911\n\tMAE:\t2900.75312\n\n\n\nTraining:\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa3759be8a81464b9c33f6d9ad6fdf03"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\tLoss:\t0.10367\n\tMAE:\t3107.93588\n\n\n\nValidation:\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73998c7399314a5aa6b9390f3fb962e9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\tLoss:\t0.12080\n\tMAE:\t3175.49011\n\n\n\nTraining:\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dd8c8da000848a9ae4368b036fa3ebf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\tLoss:\t0.11639\n\tMAE:\t3284.26886\n\n\n\nValidation:\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ab7a3ec42cb451299dcbf7fc9af8e08"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\tLoss:\t0.09791\n\tMAE:\t2974.31432\n\n\n\nTraining:\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e76f02f5f8a0427eb6b04835c9a817fd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\tLoss:\t0.10527\n\tMAE:\t3139.15747\n\n\n\nValidation:\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02b4f5c935b1467188a6da8b3f1c12c7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\tLoss:\t0.11597\n\tMAE:\t3136.21436\n\n\n\nTraining:\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1e958783676411ea7bac7637e752cc5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\tLoss:\t0.10538\n\tMAE:\t3104.19102\n\n\n\nValidation:\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bbc743b1a314601877c14c386a9d76d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\tLoss:\t0.09718\n\tMAE:\t3024.74099\n\n\n\nTraining:\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c51fa11dbac9401b8ebd074150c9fa9d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\tLoss:\t0.11118\n\tMAE:\t3238.60521\n\n\n\nValidation:\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=765.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0dc2500a3864e9e93dbfe599214e6c9"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nprint(\"Final eval:\")\nval_loss = val_mae = val_batches = 0\n\nfor batch in iterate_minibatches(data_val, shuffle=False):\n    title_ix = torch.tensor(batch[\"Title\"], dtype=torch.int64)\n    desc_ix = torch.tensor(batch[\"FullDescription\"], dtype=torch.int64)\n    cat_features = torch.tensor(batch[\"Categorical\"], dtype=torch.float32)\n    reference = torch.tensor(batch[target_column], dtype=torch.float32)\n\n    prediction = model(title_ix, desc_ix, cat_features)\n    loss = compute_loss(reference, prediction)\n\n    val_loss += loss.data.numpy()\n    val_mae += compute_mae(reference, prediction).data.numpy()\n    val_batches += 1\n\nprint(\"\\tLoss:\\t%.5f\" % (val_loss / val_batches))\nprint(\"\\tMAE:\\t%.5f\" % (val_mae / val_batches))\nprint('\\n\\n')","metadata":{"id":"QCAU26r3qvTm","cellId":"fo1uzxvoybveqxu7fo0csm"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Task 3: explaining network predictions (optional)\n\nIt's usually a good idea to understand what your model does before you let it make actual decisions. It's simple for linear models: just see which words learned positive or negative weights. However, its much harder for neural networks that learn complex nonlinear dependencies.\n\nThere are, however, some ways to look inside the black box:\n* Seeing how model responds to input perturbations\n* Finding inputs that maximize/minimize activation of some chosen neurons (_read more [on distill.pub](https://distill.pub/2018/building-blocks/)_)\n* Building local linear approximations to your neural network: [article](https://arxiv.org/abs/1602.04938), [eli5 library](https://github.com/TeamHG-Memex/eli5/tree/master/eli5/formatters)\n\nToday we gonna try the first method just because it's the simplest one.\n\n__Your task__ is to measure how does model prediction change if you replace certain tokens with UNKs. The core idea is that if dropping a word from text causes model to predict lower log-salary, than this word probably has positive contribution to salary (and vice versa).","metadata":{"id":"xIQFst_EqvTo","cellId":"jr2fwb12btrbrq0wsju96n"}},{"cell_type":"code","source":"#!g1.1\ndef explain(model, sample, col_name='Title'):\n    \"\"\" Computes the effect each word had on model predictions \"\"\"\n\n    sample = dict(sample)\n    sample_col_tokens = [tokens[token_to_id.get(tok, 0)] for tok in sample[col_name].split()]\n    data_drop_one_token = pd.DataFrame([sample] * (len(sample_col_tokens) + 1))\n\n    for drop_i in range(len(sample_col_tokens)):\n        data_drop_one_token.loc[drop_i, col_name] = ' '.join(UNK if i == drop_i else tok\n                                                   for i, tok in enumerate(sample_col_tokens)) \n    batch = generate_batch(data_drop_one_token)\n    title_ix = torch.tensor(batch[\"Title\"], dtype=torch.int64)\n    desc_ix = torch.tensor(batch[\"FullDescription\"], dtype=torch.int64)\n    cat_features = torch.tensor(batch[\"Categorical\"], dtype=torch.float32)\n\n    *predictions_drop_one_token, baseline_pred = model.cpu()(title_ix, desc_ix, cat_features).data.numpy()\n    diffs = baseline_pred - predictions_drop_one_token\n    return list(zip(sample_col_tokens, diffs))\n    \n    # compute model prediction on sample (scalar float log-salary)\n    # baseline_pred = <YOUR CODE>\n    \n    # for each i-th token in :col_name:, compute predictions on a copy of data\n    # where i-th token is dropped (UNK)\n    # predictions_without_word = <YOUR CODE>\n    \n    # score_differences = [\n       # prediction - baseline_pred for prediction in predictions_without_word\n    #]\n    \n    # return a list of pairs: [(token, score_difference)]\n\n    #return <YOUR CODE>","metadata":{"id":"kR9MyS9SqvTo","cellId":"cpbpe0squrm1iyljgpvqnp"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\n# debugging area\nsample = data.loc[np.random.randint(len(data))]\nprint(\"Input:\", sample)\n\ntokens_and_weights = explain(model, sample, \"Title\")\nprint(tokens_and_weights)","metadata":{"id":"H_HlaorVqvTq","cellId":"mp3q67gkd1l7dqaydch6q"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nfrom IPython.display import HTML, display_html\n\ndef draw_html(tokens_and_weights, cmap=plt.get_cmap(\"bwr\"), display=True,\n              token_template=\"\"\"<span style=\"background-color: {color_hex}\">{token}</span>\"\"\",\n              font_style=\"font-size:14px;\"\n             ):\n    \n    def get_color_hex(weight):\n        rgba = cmap(1. / (1 + np.exp(weight)), bytes=True)\n        return '#%02X%02X%02X' % rgba[:3]\n    \n    tokens_html = [\n        token_template.format(token=token, color_hex=get_color_hex(weight))\n        for token, weight in tokens_and_weights\n    ]\n    \n    \n    raw_html = \"\"\"<p style=\"{}\">{}</p>\"\"\".format(font_style, ' '.join(tokens_html))\n    if display:\n        display_html(HTML(raw_html))\n        \n    return raw_html\n    ","metadata":{"id":"pykb8bXbqvTt","cellId":"old0vm75s7u8jvydhzix"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\ni = np.random.randint(len(data))\nsample = data.loc[i]\nprint(\"Index:\", i)\n\n# predict salary on sample\nprint(\"Salary (gbp):\", <YOUR CODE>)\n\ntokens_and_weights = explain(model, sample, \"Title\")\ndraw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n\ntokens_and_weights = explain(model, sample, \"FullDescription\")\ndraw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);","metadata":{"id":"OecRithEqvTv","cellId":"7xfuoqxfpuwe455h4vhy3"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Task 4: Actually make it work: try more architectures\n\nYour main task is to use some of the tricks you've learned on the network and analyze if you can improve __validation MAE__.\n\nTry __at least 3 options__ from the list below for a passing grade. If you're into \n\n#### A) CNN architecture\n\nAll the tricks you know about dense and convolutional neural networks apply here as well.\n* Dropout. Nuff said.\n* Batch Norm. This time it's `nn.BatchNorm1d`\n* Parallel convolution layers. The idea is that you apply several nn.Conv1d to the same embeddings and concatenate output channels.\n* More layers, more neurons, ya know...\n\n\n#### B) Play with pooling\n\nThere's more than one way to do max pooling:\n* Max over time - our `GlobalMaxPooling`\n* Average over time (excluding PAD)\n* Softmax-pooling:\n$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot {{e ^ {h_{i, t}}} \\over \\sum_\\tau e ^ {h_{j, \\tau}} } }$$\n\n* Attentive pooling\n$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot Attn(h_t)}$$\n\n, where $$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \\over \\sum_\\tau e ^ {NN_{attn}(h_\\tau)}}  $$\nand $NN_{attn}$ is a small neural network\n\n\nThe optimal score is usually achieved by concatenating several different poolings, including several attentive pooling with different $NN_{attn}$\n\n#### C) Fun with embeddings\n\nIt's not always a good idea to train embeddings from scratch. Here's a few tricks:\n\n* Use a pre-trained word2vec from [here](http://ahogrammer.com/2017/01/20/the-list-of-pretrained-word-embeddings/) or [here](http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/).\n* Start with pre-trained embeddings, then fine-tune them with gradient descent\n* Use the same embedding matrix in title and desc vectorizer\n\n#### D) Going recurrent\n\nWe've already learned that recurrent networks can do cool stuff in sequence modelling. Turns out, they're not useless for classification as well. With some tricks of course..\n\n* Like convolutional layers, LSTM should be pooled into a fixed-size vector with some of the poolings.\n  * Please bear in mind that while convolution uses [batch, units, time] dim order, \n    recurrent units are built for [batch, time, unit]. You may need to `torch.transpose`.\n\n* Since you know all the text in advance, use bidirectional RNN\n  * Run one LSTM from left to right\n  * Run another in parallel from right to left \n  * Concatenate their output sequences along unit axis (dim=-1)\n\n* It might be good idea to mix convolutions and recurrent layers differently for title and description\n\n\n#### E) Optimizing seriously\n\n* You don't necessarily need 100 epochs. Use early stopping. If you've never done this before, take a look at [keras](https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L461) for inspiration.\n  * In short, train until you notice that validation\n  * Maintain the best-on-validation snapshot via `model.state_dict`\n  * Plotting learning curves is usually a good idea","metadata":{"id":"VqeYF-CVqvTy","cellId":"vbivmwsm5zbzpngj1myyuo"}},{"cell_type":"markdown","source":"# Regression with BERT (Pre-training of Deep Bidirectional Transformers for Language Understanding)","metadata":{"id":"RS-Z8f2uWxlk","cellId":"ju2fibjmzvk2jsw9n2rnq8"}},{"cell_type":"markdown","source":"<img src=\"https://chernobrovov.ru/assets/images/bert0.png\" width=500px>","metadata":{"id":"Kjz_9-8I_Xa_","cellId":"joyawtacwadhw5bqtrytu4"}},{"cell_type":"markdown","source":"BERT (Bidirectional Encoder Representations from Transformers) is a recent paper published by researchers at Google AI Language. It has caused a stir in the Machine Learning community by presenting state-of-the-art results in a wide variety of NLP tasks, including Question Answering (SQuAD v1.1), Natural Language Inference (MNLI), and others.\nBERT’s key technical innovation is applying the bidirectional training of Transformer, a popular attention model, to language modelling. This is in contrast to previous efforts which looked at a text sequence either from left to right or combined left-to-right and right-to-left training. The paper’s results show that a language model which is bidirectionally trained can have a deeper sense of language context and flow than single-direction language models. In the paper, the researchers detail a novel technique named Masked LM (MLM) which allows bidirectional training in models in which it was previously impossible.\n\nYou can find more information in in https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270 or directly from paper: https://arxiv.org/abs/1810.04805","metadata":{"id":"AJFXHPZmDYQy","cellId":"j0r6m7l5l9sqvrkgsjlbxh"}},{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"ljv9kRTrXAv-","cellId":"7958xlwxhk5yj4u0p2xk4e"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To do:\n\n* Create a proper dataset\n* Select and load proper tokenizer from https://huggingface.co/transformers/fast_tokenizers.html\n\nDealing with Hugginface is possible in 2 ways: Hard and Effective.\n\n<img src=\"https://i.pinimg.com/564x/21/29/6a/21296a88cdae259e0507a2e63174b1e7.jpg\" width=300px>\n\n> ### Take Ring to Mordor by Fellowship campaine (Hard):\n* Select a model class from https://huggingface.co/transformers/task_summary.html\n* Create Bert object from one of the available pre-trained configurations.\n* Add several layers (head) in the top of model's output to transform output to regression logits.\n* Note, in the general case, for smoothly training a Bert with a head, either a very good schedule or different learning rates for parameters in Bert part and for head.\n\n\n\n> ### Take Ring to Mordor by Eagles (Effective):\n* Select a model class from https://huggingface.co/transformers/task_summary.html with parameters that allow to train linear regression\n* Create Bert object from one of the available pre-trained configurations\n* Train it by hand-written training loop or Trainer (https://huggingface.co/transformers/main_classes/trainer.html#transformers Trainer)\n\n**Note**: any transformer-based model is weighty and tremendous, and there may not be enough memory in your laptop or collab to work with it.\n\nWe do not recommend loading and using models with the prefix 'large'. If, nevertheless, we obtain a **lack of memory**, you can:\n* reduce the salary dataset to $50*10^3$\n* reduce batch size\n* reduce number of objects involved in the train (for example, abandon Train() in favor of regular training loop)\n\n","metadata":{"id":"EsPTIS351oIJ","cellId":"mobwqg54xao2g6baag3kg"}},{"cell_type":"code","source":"#!g1.1\nmodel_checkpoint = \"bert-base-uncased\"\nbatch_size = 16","metadata":{"id":"k9EtwzGba3K6","cellId":"32itz9ij1cxgl4xlzk9ud8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nfrom transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)","metadata":{"id":"MONEX1UCan_d","cellId":"nbwdnqi3buocd0p7qjbwk"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\ndef compute_loss(reference, prediction):\n    \"\"\"\n    Computes objective for minimization.\n    By deafult we minimize MSE, but you are encouraged to try mix up MSE, MAE, huber loss, etc.\n    \"\"\"\n    return torch.mean((prediction - reference) ** 2)\n\ndef compute_mae(reference, prediction):\n    \"\"\" Compute MAE on actual salary, assuming your model outputs log1p(salary)\"\"\"\n    return torch.abs(torch.exp(reference - 1) - torch.exp(prediction - 1)).mean()","metadata":{"id":"Z5iHnzs-R_vS","cellId":"82jej03on2b2dvavd8mfi"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset: ","metadata":{"id":"UNPR3Gjuz4r3","cellId":"tlx3m3njxej294jd2tcmm"}},{"cell_type":"code","source":"#!g1.1\ndef read_text_labels_from_df(salary_df):\n    texts = []\n    labels = []\n    for ind, elem in enumerate(salary_df[\"Title\"]):\n        try:\n          text = elem + salary_df[\"FullDescription\"][ind]\n          label = salary_df[\"Log1pSalary\"][ind]\n          texts.append(text)\n          labels.append([label])\n        except:\n          print (\"smth went wrong\")\n\n    return texts, labels\n","metadata":{"id":"FUN_suxcCHIE","cellId":"oehsbasf3siln3wdvdkicf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nfrom sklearn.model_selection import train_test_split\ntexts, labels = read_text_labels_from_df(data)\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(texts[:5000], labels[:5000], test_size=.2)","metadata":{"id":"hmMHkRLvAw7i","cellId":"dyykuyddm9b17ial3uba26"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\ntrain_encodings = #YOU_CODE_HERE\ntest_encodings = #YOU_CODE_HERE","metadata":{"id":"sYUejpMBA3Gh","cellId":"ch69lzhtcalf5x315o1x0h"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nfrom torch.utils.data import DataLoader\nfrom transformers import DistilBertForSequenceClassification, AdamW\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n#YOU_CODE_HERE","metadata":{"id":"wYDd5Vp68KqS","cellId":"f2a2xo29sakfx8zf9qhv1u"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nfrom transformers import Trainer\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nmodel = #YOU_CODE_HERE\nmodel.to(device)\nmodel.train()\n\ntraining_args = #YOU_CODE_HERE\n\noptim = #YOU_CODE_HERE\n\n#and then only YOU_CODE_HERE. Feel free!","metadata":{"id":"8Cbf3SZc8yyu","cellId":"j01tf2u3unata5rqz04rs"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# A short report\n\nPlease tell us what you did and how did it work for classical NLP task and for BERT.\n\n`<YOUR_TEXT_HERE>`, i guess...","metadata":{"id":"UuLk0ZcyqvTy","cellId":"75ji1tnyuf5wk2zl4xl9ys"}},{"cell_type":"code","source":"","metadata":{"id":"1ijwq7FpqvTy","cellId":"9e99cwpocodixxpmtj5z7s"},"outputs":[],"execution_count":null}]}